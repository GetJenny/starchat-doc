{
    "docs": [
        {
            "location": "/",
            "text": "Welcome!\n\n\nThis is the official repository for StarChat, a scalable conversational engine for B2B applications.\n\n\nHow to contribute\n\n\nTo contribute to StarChat, please send us a \npull request\n  from your fork of this repository.\n\n\nOur concise \ncontribution guideline\n contains the bare\nminumum requirements of the code contributions.\n\n\nBefore contributing (or opening issues), you might want send us an email at starchat@getjenny.com.\n\n\nQuick Start\n\n\nRequirements\n\n\nThe easiest way is to install StarChat using two docker images. You only need:\n\n\n\n\nsbt\n\n\ndocker\n\n\ndocker compose\n\n\n\n\nIn this way, you will put all the indices in the Elasticsearch (version 5.4) image, and StarChat itself in the Java (8) image.\n\n\nIf you do not use docker\n you therefore need on your machine:\n\n\n\n\nScala 12.2\n\n\nElasticsearch 5.4\n\n\n\n\nSetup with Docker (recommended)\n\n\n1. Launch docker-compose\n\n\nGenerate a packet distribution:\n\n\nsbt dist\n\n\n\n\nEnter the directory docker-starchat:\n\n\ncd  docker-starchat\n\n\n\n\nYou will get a message like \nYour package is ready in ...../target/universal/starchat-4ee.... .zip\n.  Extract the packet into the docker-starchat folder:\n\n\nunzip ../target/universal/starchat-4eee.....zip\nln -s starchat-4ee..../  starchat\n\n\n\n\nThe zip packet contains:\n\n\n\n\na set of scripts to test the endpoints and as a complement for the documentation: \nstarchat/scripts/api_test/\n\n\na set of command line programs \nstarchat/bin\n to run starchat and other tools.\n\n\ndelete-decision-table: application to delete items from the decision table\n\n\nindex-corpus-on-knowledge-base: application to index a corpus on knowledge base as hidden (to improve the language model)\n\n\nindex-decision-table: application to index data on the decision table from a csv\n\n\nindex-knowledge-base: application to index data into the knowledge base\n\n\nindex-terms: application to index terms vectors\n\n\nstarchat: start starchat\n\n\n\n\nReview the configuration files \nstarchat/config/application.conf\n and configure the language if needed (by default you have \nindex_language = \"english\"\n)\n\n\n(If you are re-installing StarChat, and want to start from scratch see \nstart from scratch\n.)\n\n\nStart both startchat and elasticsearch:\n\n\ndocker-compose up -d\n\n\n\n\n(Problems like \nelastisearch exited with code 78\n? have a look at \ntroubleshooting\n!)\n\n\n2. Create Elasticsearch indices\n\n\nRun from a terminal:\n\n\n# create the indices in Elasticsearch\ncurl -v -H \"Content-Type: application/json\" -X POST \"http://localhost:8888/index_management/create\"\n\n\n\n\n3. Load the configuration file\n\n\nNow you have to load the configuration file for the actual chat, aka \ndecision table\n. We have provided an example csv in English, therefore:\n\n\ncd $STARCHAT_DIR  # or cd .. \nsbt \"run-main com.getjenny.command.IndexDecisionTable --inputfile doc/decision_table_starchat_doc.csv --skiplines 1\"\n\n\n\n\nand then (you need to index the analyzer):\n\n\n./docker-starchat/starchat/bin/index-decision-table --inputfile doc/decision_table_starchat_doc.csv \n\n\n\n\nThis command deletes all the states it finds on the first column in the inputfile:\n\n\nsbt \"run-main com.getjenny.command.DeleteDecisionTable --inputfile doc/decision_table_starchat_doc.csv\"\n\n\n\n\nNB This means that if you create a state in the CSV file, index it, then delete it in the CSV and run \nDeleteDecisionTable\n, it won't be deleted!\n\n\n4. Load external corpus (optional)\n\n\nTo have a good words' statistics, and consequent improved matching, you might want to index a corpus which is hidden from results. For instance, you can index various sentences as hidden using the \nPOST /knowledgebase\n endpoint with \ndoctype: \"hidden\"\n.\n\n\n5. Index the FAQs (optional)\n\n\nTODO: You might want to activate the \nknowledge base\n for simple Question and Anwer. \n\n\nInstall without Docker\n\n\nNote: we do not support this installation.\n\n Clone the repository and enter the starchat directory.\n\n Initialize the Elasticsearch instance (see above for Docker)\n* Run the service: \nsbt compile run\n\n\nThe service binds on the port 8888 by default.\n\n\nTest the installation\n\n\nIs the service working?\n\n\ncurl -X GET localhost:8888 | python -mjson.tool\n\n\nGet the \ntest_state\n\n\ncurl  -H \"Content-Type: application/json\" -X POST http://localhost:8888/get_next_response -d '{\n \"conversation_id\": \"1234\",\n  \"user_input\": { \"text\": \"Please send me the test state\" },\n  \"values\": {\n      \"return_value\": \"\",\n      \"data\": {}\n       }\n  }'\n\n\n\n\nYou should get:\n\n\n[\n   {\n      \"score\" : 1,\n      \"action\" : \"\",\n      \"max_state_count\" : 0,\n      \"data\" : {},\n      \"bubble\" : \"This is the test state\",\n      \"failure_value\" : \"\",\n      \"traversed_states\" : [\n         \"test_state\"\n      ],\n      \"analyzer\" : \"booleanAnd(booleanNot(booleanOr(keyword(\\\"dont\\\"),keyword(\\\"don't\\\"))), keyword(\\\"test\\\"), booleanOr(keyword(\\\"send\\\"), keyword(\\\"get\\\")))\",\n      \"state_data\" : {},\n      \"action_input\" : {},\n      \"success_value\" : \"\",\n      \"conversation_id\" : \"1234\",\n      \"state\" : \"test_state\"\n   }\n]\n\n\n\n\nIf you look at the \n\"analyzer\"\n field, you'll see that this state is triggered when\nthe user types the \ntest\n and either \nget\n or \nsend\n. Try with \n\"text\": \"Please dont send me the test state\"\n\n and StarChat will send an empty message.\n\n\nConfiguration of the chatbot (Decision Table)\n\n\nWith StarChat's Decision Table you can easily implement workflow-based chatbots. After the installation (see above)\nyou only have to configure a conversation flow and eventually a front-end client.\n\n\nNLP processing\n\n\nNLP processing is of course the core of any chatbot. As you have noted in the  \nCSV provided in the doc/ directory\n there are two fields defining when StarChat should trigger a state -\nanalyzer\n and \nqueries\n.\n\n\nQueries\n\n\nIf the \nanalyzer\n field is empty, StarChat will query Elasticsearch for the state containing the most similar sentence in the field \nqueries\n. We have carefully configured Elasticsearch in order to provide good answers (e.g. boosting results where the same words appear etc), and results are... acceptable. But you are encouraged to use the \nanalyzer\n field, documented below.\n\n\nAnalyzer\n\n\nThrough the \nanalyzer\ns, you can easily leverage on various NLP algorithms included in StarChat, together with NLP capabilities of Elasticsearch. You can also combine the result of those algorithms. The best way is to look at the simple example included in the  \nCSV provided in the doc/ directory\n for the state \nforgot_password\n:\n\n\nand(or(keyword(\"reset\"),keyword(\"forgot\")),keyword(\"password\"))\n\n\nThe \nexpression\n \nand\n and \nor\n are called the \noperators\n, while \nkeyword\n is an \natom\n \n\n\nExpressions: Atoms\n\n\nPresently, the \nkeyword(\"reset\")\n in the example provides a very simple score: occurrence of the word \nreset\n in the user's query divided by the total number of words. If evaluated agains the sentence \"Want to reset my password\", \nkeyword(\"reset\")\n will currently return 0.2.  \nNB\n This is just a temporary score used while our NLP library \nmanaus\n is not integrated into StarChat.\n\n\nThese are currently the expression you can use to evaluate the goodness of a query (see \nDefaultFactoryAtomic\n and \nStarchatFactoryAtomic\n:\n\n\n\n\nkeyword(\"word\")\n: as explained above, normalized\n\n\nregex\n: evaluate a regular expression, not normalized\n\n\nsearch(state_name)\n: takes a state name as argument, queries elastic search and returns the score of the most similar query in the field  \nqueries\n of the argument's state. In other words, it does what it would do without any analyzer, only with a normalized score -e.g. \nsearch(\"lost_password_state\")\n \n\n\nsynonym(\"word\")\n: gives a normalized cosine distance between the argument and the closest word in the user's sentence. We use word2vec, to have an idea of two words distance you can use this \nword2vec demo\n by \nTurku University\n\n\nsimilar(\"a whole sentence\")\n:  gives a normalized cosine distance between the argument and the closest word in the user's sentence (word2vec)\n\n\nsimilarState(state_name)\n:  same as above, but for the sentences in the field \"queries\" of the state in the argument.\n\n\nsimilarEucEmd(\"a whole sentence\")\n: gives a non-normalized euclidean distance (calculated using the earth movers distance algorithm) between the argument and the closest sentence in the user's sentence (word2vec)\n\n\nsimilarEucEmdState(state_name)\n: same as above, but for the sentences in the field \"queries\" of the state in the argument.\n\n\nsimilarCosEmd(\"a whole sentence\")\n: gives a normalized cosine distance (calculated using the earth movers distance algorithm) between the argument and the closest sentence in the user's sentence (word2vec)\n\n\nsimilarCosEmdState(state_name)\n: same as above, but for the sentences in the field \"queries\" of the state in the argument.\n\n\nmatchPatternRegex(regex)\n: A generic pattern extraction analyzer, it extract named patterns matching a given regex e.g. the following will match tree numbers separated by semicolumn: [first,second,third](?:([0-9]+:[0-9]:[0-9]+) if the regex matches it will create the entries into the state variables dictionary e.g.: 10:11:12 will result in Map(\"first.0\" -> \"10\", \"second.0\" -> \"11\", \"third.0\" -> \"12\") the number at the end of the name is an index incremented for multiple occurrences of the pattern in the query\n\n\nmatchDateDDMMYYYY(prefix)\n: parse a date in DDMMYYYY format is built using the matchPatternRegex with the following regex: \"(?:(?:[^0-9]+|\\A)(0[1-9]|[12][0-9]|3[01])(?:[- \\/.])(0[1-9]|1[012])(?:[- \\/.])((?:19|20)\\d\\d)(?:[^0-9]+|$))\"\n\n\nexistsVariable(variable_name)\n: check whether a variable exists or not \n\n\nhasTravState\n(state_name): check if a state_name is present into the history of traversed states\n\n\nlastTravStateIs\n(state_name): check if the last traversed state is state_name\n\n\nprevTravStateIs(state_name)\n: check if the last but one traversed state is state_name\n\n\ndistance(\"keyword1\", ..., \"keyword N\")\n: calculate the cosine distance between the query and the list of keywords, this analyzer can be called using \ncosDistanceKeywords\n\n\n\n\nExpressions: Operators\n\n\nOperators evaluate the output of one or more expression and return a value. Currently, the following operators are implemented (the the \nsource code\n):\n\n\n\n\nboolean or\n:   calles matches of all the exprassions it contains and returns true or false. It can be called using \nbor\n\n\nboolean and\n:  as above, it's called with \nband\n\n\nboolean not\n:  ditto, \nbnot\n\n\nconjunction\n:  if the evaluation of the expressions it contains is normalized, and they can be seen as probabilities of them being true, this is the probability that all the expressions are all true (\nP(A)*P(B)\n)\n\n\ndisjunction\n:  as above, the probability that at least one is true (\n1-(1-P(A))*(1-P(B))\n)\n\n\nmax\n: takes the max score of returned by the expression arguments\n\n\n\n\nTechnical corner: \nexpressions\n\n\nExpressions\n, like \nkeywords\n in the example, are called \natoms\n, and have the following methods/members:\n\n\n\n\ndef evaluate(query: String): Double\n: produce a score. It might be normalized to 1 or not (set \nval isEvaluateNormalized: Boolean\n accordingly)\n\n\nval match_threshold\n This is the threshold above which the expression is considered true when \nmatches\n is called. NB The default value is 0.0, which is normally not ideal.\n\n\ndef matches(query: String): Boolean\n: calles evaluate and check agains the threshold...\n\n\nval rx\n: the name of the atom, as it should be used in the \nanalyzer\n field.\n\n\n\n\nConfiguration of the answer recommender (Knowledge Base)\n\n\nThrough the \n/knowledgebase\n endpoint\nyou can add, edit and remove pairs of question and answers used by StarChat to recommend possible answers when a question arrives.\n\n\nDocuments containing Q&A must be structured like that:\n\n\n{\n    \"id\": \"0\",  // id of the pair\n    \"conversation\": \"id:1000\",   // id of the conversation. This can be useful to external services\n    \"index_in_conversation\": 1,  // when the pair appears inside the conversation, as above\n    \"question\": \"thank you\",  // The question to be matched\n    \"answer\": \"you are welcome!\",  // The answer to be recommended \n    \"question_scored_terms\": [  // A list of keyword and score. You can use your own keyword extractor or our Manaus (see later)\n        [\n            \"thank\", \n            1.9\n        ]\n    ],\n    \"verified\": true,  // A variable used in some call centers\n    \"topics\": \"t1 t2\",  // Eventual topics to be associated\n    \"dclass\": \"\", // Optional field as a searchable class for answer\n    \"doctype\": \"normal\",\n    \"state\": \"\",\n    \"status\": 0\n}\n\n\n\n\nSee \nPOST /knowledgebase\n for an example with \ncurl\n. Other calls (\nGET, DELETE, PUT\n) are used to get the state, delete it or update it. \n\n\nTest the knowledge base\n\n\nJust run the example in \nPOST /knowledgebase_search\n.\n\n\nManaus\n\n\nIn the Q&A pair above you saw the field\n\nquestion_scored_terms\n. Having good keywords improves enormously the\nquality of the answer. You can of course put them by hand, or run a\nsoftware which extracts the keywords from the question. If you prefer\nthe latter, but don't have any, we provide\n\nManaus\n.\n\n\nManaus is still under development, but it's already included in the\nDocker's installation of StarChat. When you launch \ndocker-compose up\n-d\n, you also launch a container with Manaus which analyzes all the\nQ&A in the Knowledge Base, produces keywords and updates the field\nquestion_scored_terms for all documents. The process is repeated evert\n4 hour.\n\n\nManaus configuration\n\n\nHave a look at the file \ndocker-starchat/docker-compose.yml\n. For\nManaus to have good performance, you need to provide decent language\nstatistics. Update the file \n/manaus/statistics_data/english/word_frequency.tsv\n with a\nword-frequency file with the following format:\n\n\n1       you     1222421\n2       I       1052546\n3       to      823661\n....\n\n\n\n\nWe have frequency file for more than 50 languages, but consider that\nthe choice of good \"prior distribution\" of word frequency is crucial\nfor any NLP task.\n\n\nTechnology\n\n\nStarChat was design with the following goals in mind:\n\n\n\n\neasy deployment\n\n\nhorizontally scalability without any service interruption.\n\n\nmodularity\n\n\nstatelessness\n\n\n\n\nHow does StarChat work?\n\n\nWorkflow\n\n\n\n\nComponents\n\n\nStarChat uses Elasticsearch as NoSQL database and, as said above, NLP preprocessor, for\nindexing, sentence cleansing, and tokenization.\n\n\nServices\n\n\nStarChat consists of two different services: the \"KnowledBase\" and the \"DecisionTable\"\n\n\nKnowledgeBase\n\n\nFor quick setup based on real Q&A logs. It stores question and answers pairs. Given a text as input\n it proposes the pair with the closest match on the question field.\n  At the moment the KnowledBase supports only Analyzers implemented on Elasticsearch.\n\n\nDecisionTable\n\n\nThe conversational engine itself. For the usage, see below.\n\n\nConfiguration of the DecisionTable\n\n\nYou configure the DecisionTable through CSV file. Please have a look at the \nCSV provided in the doc/ directory\n.\n\n\nFields in the configuration file are of three types:\n\n\n\n\n(R)\n: Return value: the field is returned by the API\n\n\n(T)\n: Triggers to the state: when should we enter this state? \n\n\n(I)\n: Internal: a field not exposed to the API\n\n\n\n\nAnd the fields are:\n\n\n\n\nstate\n: a unique name of the state (e.g. \nforgot_password\n)\n\n\nexecution_order\n: specify an order of evaluation for analyzers the lower is the number earlier is the evaluation of the state\n\n\nmax_state_count\n: defines how many times StarChat can repropose the state during a conversation.\n\n\nanalyzer (T,I)\n: specify an analyzer expression which triggers the state\n\n\nquery (T,I)\n: list of sentences whose meaning identify the state\n\n\nbubble (R)\n: content, if any, to be shown to the user. It may contain variables like %email% or %link%.\n\n\naction (R)\n: a function to be called on the client side. StarChat developer must provide types of input and output (like an abstract method), and the GUI developer is responsible for the actual implementation (e.g. \nshow_button\n)\n\n\naction_input (R)\n: input passed to \naction\n's function (e.g., for \nshow_buttons\n can be a list of pairs \n(\"text to be shown on button\", state_to_go_when_clicked)\n \n\n\nstate_data (R)\n: a dictionary of strings with arbitrary data to pass along\n\n\nsuccess_value (R)\n: output to return in case of success\n\n\nfailure_value (R)\n: output to return in case of failure\n\n\n\n\nClient functions\n\n\nIn StarChat configuration, the developer can specify which function the front-end should\nexecute when a certain state is triggered, together with input parameters.\n\nAny function implemented on the front-end can be called.\n\n\nExample show button\n\n\n\n\nAction: \nshow_buttons\n\n\nAction input: \n{\"buttons\": [(\"Forgot Password\", \"forgot_password\"), (\"Account locked\", \"account_locked\")]}\n\n\nThe frontend will call function: \nshow_buttons(buttons={\"Forgot Password\": \"forgot_password\",\"Account locked\": \"account_locked\")\n\n\n\n\nExample \"buttons\": the front-end implements the function show_buttons and uses \"action input\" to call it. It will show two buttons, where the first returns forgot_password and the second account_locked.\n\n\nExample send email\n\n\n\n\nAction: \nsend_password_link\n\n\nAction input: \n{ \"template\": \"Reset your password here: example.com\",\"email\": \"%email%\",\"subject\": \"New password\" }\n\n\nThe frontend will call function: \nsend_password_link(template=\"Reset your password here: example.com.\",email= \"john@foo.com\", subject=\"New password\")\n\n\n\n\nExample \"send email\": the front-end implements the function send_password_link and uses \"action input\" to call it.\nThe variable %email% is automatically substituted by the variable email if available in the JSON passed to the\nStarchatResource.\n\n\nfunctions for the sample csv\n\n\nFor the CSV in the example above, the client will have to implement the following set of functions:\n\n\n\n\nshow_buttons: tell the client to render a multiple choice button\n\n\ninput: a key/value pair with the key indicating the text to be shown in the button, and the value indicating the state to follow e.g.: {\"Forgot Password\": \"forgot_password\", \"Account locked\": \"account_locked\", \"Specify your problem\": \"specify_problem\", \"I want to call an operator\": \"call_operator\", \"None of the above\": \"start\"}\n\n\noutput: the choice related to the button clicked by the user e.g.: \"account_locked\"\n\n\ninput_form: render an input form or collect the input following a specific format\n\n\ninput: a dictionary with the list of fields and the type of fields, at least \"email\" must be supported: e.g.: { \"email\": \"email\" } where the key is the name and the value is the type\n\n\noutput: a dictionary with the input values e.g.: { \"email\": \"foo@example.com\" }\n\n\nsend_password_generation_link: send an email with instructions to regenerate the password\n\n\ninput: a valid email address e.g.: \"foo@example.com\"\n\n\noutput: a dictionary with the response fields e.g.: { \"user_id\": \"123\", \"current_state\": \"forgot_password\", \"status\": \"true\" }\n\n\n\n\nRef: \nsample_state_machine_specification.csv\n.\n\n\nMechanics\n\n\n\n\nThe client implements the functions which appear in the action field of the spreadsheet. \nWe will provide interfaces.\n\n\nThe client call the rest API \"decisiontable\" endpoint communicating a state if any, \nthe user input data and other state variables\n\n\nThe client receive a response with guidance on what to return to the user and what \nare the possible next steps\n\n\nThe client render the message to the user and eventually collect the input, then \ncall again the system to get instructions on what to do next\n\n\nWhen the \"decisiontable\" functions does not return any result the user can call the \"knowledgebase\" endpoint which contains all the conversations. \n\n\n\n\nScalability\n\n\nStarChat consists of two different services: StarChat itself and an Elasticsearch cluster. \n\n\nScaling StarChat instances\n\n\nStarChat can scale horizontally by simple replication. Because StarChat is stateless, instances looking \nat the same Elasticsearch index will behave identically. New instances can then be added together\nwith a load balancing service.\n\n\nIn the diagram below, a load balancer forward requests coming from the front-end to StarChat instances \n1, 2 or 3. These instances, as said, behave identically because they all refer to \nIndex 0\n in the \nElasticsearch cluster.\n\n\n\n\nScaling Elasticsearch\n\n\nSimilarly, Elasticsearch can easily scale horizontally adding new nodes to the cluster, as explained\n in \nElasticsearch Documentation\n.\n\n\nSecurity\n\n\nStarChat is a backend service and \nshould never\n be exposed to the internet,\nit should be placed behind a firewall.\nOne of the most effective and flexible method to add an access control layer is to use \n\nKong\n in front of StarChat as a gateway, in this way\nStarChat can be shield by unwanted accesses.\n\n\nIn addition StarChat support TLS connections, the configuration file allow to\nchoose if the service should expose an https connection or an http connection\nor both.\nIn order to use the https connection the user must do the following things:\n\n\n\n\nobtain a pkcs12 server certificate from a certification authority or \ncreate a self signed certificate\n\n\nsave the certificate inside the folder \nconfig/tls/certs/\n e.g. \nconfig/tls/certs/server.p12\n\n\nset the password for the certificate inside the configuration file\n\n\nenable the https connection setting to true the https.enable property of the configuration file\n\n\noptionally disable the http connection setting to false the http.enable property of the configuration file\n\n\n\n\nFollows the block of the configuration file which is to be modified as described above in\n order to use https:\n\n\nhttps {\n  host = \"0.0.0.0\"\n  host = ${?HOST}\n  port = 8443\n  port = ${?PORT}\n  certificate = \"server.p12\"\n  password = \"uma7KnKwvh\"\n  enable = false\n}\n\nhttp {\n  host = \"0.0.0.0\"\n  host = ${?HOST}\n  port = 8888\n  port = ${?PORT}\n  enable = true\n}\n\n\n\n\nStarChat come with a default self-signed certificate for testing,\nusing it for production or sensitive environment is highly discouraged\nas well as useless from a security point of view.\n\n\nIndexing terms on term table\n\n\nThe following program index term vectors on the vector table:\n\n\nsbt \"run-main com.getjenny.command.IndexTerms --inputfile terms.txt --vecsize 300\"\n\n\n\n\nThe format for each row of an input file with 5 dimension vectors is:\n\nhello 1.0 2.0 3.0 4.0 0.0\n\n\nYou can use your ad-hoc trained vector model (as we do) otherwise you can use the google word2vec models\ntrained on google news. You can find a copy of the \nelasticsearch index with a pre-loaded google news terms\n.\n\n\nTest\n\n\nUnit tests\n\n\nA set of unit test is available using docker-compose to set up a backend, the command to run tests is:\n\n\nsbt dockerComposeUp ; sbt test ; sbt dockerComposeStop\n\n\n\n\ntest scripts with sample API calls\n\n\n\n\nA set of test script is present inside scripts/api_test\n\n\n\n\nTroubleshooting\n\n\nDocker: start from scratch\n\n\nYou might want to start from scratch, and delete all docker images. \n\n\nIf you do so (\ndocker images\n and then \ndocker rmi -f <java/elasticsearch ids>\n) remember that all data for the \nElasticsearch docker are local, and mounted only when the container is up. Therefore you need to:\n\n\ncd docker-starchat\nrm -rf elasticsearch/data/nodes/\n\n\n\n\ndocker-compose: Analyzers are not loaded\n\n\nStarChat is started immediately after elasticsearch and it is possible that elasticsearch is\n not ready to respond to REST calls from StarChat (i.e. an index not found error could be\n raised in this case).\n\n\nSample error on the logs:\n\n\n2017-06-15 10:37:22,993 >10:37:22.992UTC ERROR c.g.s.s.AnalyzerService(akka://starchat-service) com.getjenny.starchat.services.AnalyzerService(akka://starchat-service) - can't load analyzers: [jenny-en-0]\n IndexNotFoundException[no such index]\n\n\n\n\nIn order to avoid this problem you can call the services one by one:\n\n\ndocker-compose up elasticsearch # here wait elasticsearch is up and running\ndocker-compose up starchat # starchat will retrieve the Analyzers from elasticsearch\n\n\n\n\nIn alternative is possible to call the command to load/refresh the Analyzers after the docker-compose command: \n\n\ncurl -v -H \"Content-Type: application/json\" -X POST \"http://localhost:8888/decisiontable_analyzer\"\n\n\n\n\nDocker: Size of virtual memory\n\n\nIf elasticsearch complain about the size of the virtual memory:\n\n\nmax virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144]\nelastisearch exited with code 78\n\n\n\n\nrun:\n\n\nsysctl -w vm.max_map_count=262144",
            "title": "Home"
        },
        {
            "location": "/#welcome",
            "text": "This is the official repository for StarChat, a scalable conversational engine for B2B applications.",
            "title": "Welcome!"
        },
        {
            "location": "/#how-to-contribute",
            "text": "To contribute to StarChat, please send us a  pull request   from your fork of this repository.  Our concise  contribution guideline  contains the bare\nminumum requirements of the code contributions.  Before contributing (or opening issues), you might want send us an email at starchat@getjenny.com.",
            "title": "How to contribute"
        },
        {
            "location": "/#quick-start",
            "text": "",
            "title": "Quick Start"
        },
        {
            "location": "/#requirements",
            "text": "The easiest way is to install StarChat using two docker images. You only need:   sbt  docker  docker compose   In this way, you will put all the indices in the Elasticsearch (version 5.4) image, and StarChat itself in the Java (8) image.  If you do not use docker  you therefore need on your machine:   Scala 12.2  Elasticsearch 5.4",
            "title": "Requirements"
        },
        {
            "location": "/#setup-with-docker-recommended",
            "text": "1. Launch docker-compose  Generate a packet distribution:  sbt dist  Enter the directory docker-starchat:  cd  docker-starchat  You will get a message like  Your package is ready in ...../target/universal/starchat-4ee.... .zip .  Extract the packet into the docker-starchat folder:  unzip ../target/universal/starchat-4eee.....zip\nln -s starchat-4ee..../  starchat  The zip packet contains:   a set of scripts to test the endpoints and as a complement for the documentation:  starchat/scripts/api_test/  a set of command line programs  starchat/bin  to run starchat and other tools.  delete-decision-table: application to delete items from the decision table  index-corpus-on-knowledge-base: application to index a corpus on knowledge base as hidden (to improve the language model)  index-decision-table: application to index data on the decision table from a csv  index-knowledge-base: application to index data into the knowledge base  index-terms: application to index terms vectors  starchat: start starchat   Review the configuration files  starchat/config/application.conf  and configure the language if needed (by default you have  index_language = \"english\" )  (If you are re-installing StarChat, and want to start from scratch see  start from scratch .)  Start both startchat and elasticsearch:  docker-compose up -d  (Problems like  elastisearch exited with code 78 ? have a look at  troubleshooting !)  2. Create Elasticsearch indices  Run from a terminal:  # create the indices in Elasticsearch\ncurl -v -H \"Content-Type: application/json\" -X POST \"http://localhost:8888/index_management/create\"  3. Load the configuration file  Now you have to load the configuration file for the actual chat, aka  decision table . We have provided an example csv in English, therefore:  cd $STARCHAT_DIR  # or cd .. \nsbt \"run-main com.getjenny.command.IndexDecisionTable --inputfile doc/decision_table_starchat_doc.csv --skiplines 1\"  and then (you need to index the analyzer):  ./docker-starchat/starchat/bin/index-decision-table --inputfile doc/decision_table_starchat_doc.csv   This command deletes all the states it finds on the first column in the inputfile:  sbt \"run-main com.getjenny.command.DeleteDecisionTable --inputfile doc/decision_table_starchat_doc.csv\"  NB This means that if you create a state in the CSV file, index it, then delete it in the CSV and run  DeleteDecisionTable , it won't be deleted!  4. Load external corpus (optional)  To have a good words' statistics, and consequent improved matching, you might want to index a corpus which is hidden from results. For instance, you can index various sentences as hidden using the  POST /knowledgebase  endpoint with  doctype: \"hidden\" .  5. Index the FAQs (optional)  TODO: You might want to activate the  knowledge base  for simple Question and Anwer.",
            "title": "Setup with Docker (recommended)"
        },
        {
            "location": "/#install-without-docker",
            "text": "Note: we do not support this installation.  Clone the repository and enter the starchat directory.  Initialize the Elasticsearch instance (see above for Docker)\n* Run the service:  sbt compile run  The service binds on the port 8888 by default.",
            "title": "Install without Docker"
        },
        {
            "location": "/#test-the-installation",
            "text": "Is the service working?  curl -X GET localhost:8888 | python -mjson.tool  Get the  test_state  curl  -H \"Content-Type: application/json\" -X POST http://localhost:8888/get_next_response -d '{\n \"conversation_id\": \"1234\",\n  \"user_input\": { \"text\": \"Please send me the test state\" },\n  \"values\": {\n      \"return_value\": \"\",\n      \"data\": {}\n       }\n  }'  You should get:  [\n   {\n      \"score\" : 1,\n      \"action\" : \"\",\n      \"max_state_count\" : 0,\n      \"data\" : {},\n      \"bubble\" : \"This is the test state\",\n      \"failure_value\" : \"\",\n      \"traversed_states\" : [\n         \"test_state\"\n      ],\n      \"analyzer\" : \"booleanAnd(booleanNot(booleanOr(keyword(\\\"dont\\\"),keyword(\\\"don't\\\"))), keyword(\\\"test\\\"), booleanOr(keyword(\\\"send\\\"), keyword(\\\"get\\\")))\",\n      \"state_data\" : {},\n      \"action_input\" : {},\n      \"success_value\" : \"\",\n      \"conversation_id\" : \"1234\",\n      \"state\" : \"test_state\"\n   }\n]  If you look at the  \"analyzer\"  field, you'll see that this state is triggered when\nthe user types the  test  and either  get  or  send . Try with  \"text\": \"Please dont send me the test state\" \n and StarChat will send an empty message.",
            "title": "Test the installation"
        },
        {
            "location": "/#configuration-of-the-chatbot-decision-table",
            "text": "With StarChat's Decision Table you can easily implement workflow-based chatbots. After the installation (see above)\nyou only have to configure a conversation flow and eventually a front-end client.",
            "title": "Configuration of the chatbot (Decision Table)"
        },
        {
            "location": "/#nlp-processing",
            "text": "NLP processing is of course the core of any chatbot. As you have noted in the   CSV provided in the doc/ directory  there are two fields defining when StarChat should trigger a state - analyzer  and  queries .  Queries  If the  analyzer  field is empty, StarChat will query Elasticsearch for the state containing the most similar sentence in the field  queries . We have carefully configured Elasticsearch in order to provide good answers (e.g. boosting results where the same words appear etc), and results are... acceptable. But you are encouraged to use the  analyzer  field, documented below.  Analyzer  Through the  analyzer s, you can easily leverage on various NLP algorithms included in StarChat, together with NLP capabilities of Elasticsearch. You can also combine the result of those algorithms. The best way is to look at the simple example included in the   CSV provided in the doc/ directory  for the state  forgot_password :  and(or(keyword(\"reset\"),keyword(\"forgot\")),keyword(\"password\"))  The  expression   and  and  or  are called the  operators , while  keyword  is an  atom    Expressions: Atoms  Presently, the  keyword(\"reset\")  in the example provides a very simple score: occurrence of the word  reset  in the user's query divided by the total number of words. If evaluated agains the sentence \"Want to reset my password\",  keyword(\"reset\")  will currently return 0.2.   NB  This is just a temporary score used while our NLP library  manaus  is not integrated into StarChat.  These are currently the expression you can use to evaluate the goodness of a query (see  DefaultFactoryAtomic  and  StarchatFactoryAtomic :   keyword(\"word\") : as explained above, normalized  regex : evaluate a regular expression, not normalized  search(state_name) : takes a state name as argument, queries elastic search and returns the score of the most similar query in the field   queries  of the argument's state. In other words, it does what it would do without any analyzer, only with a normalized score -e.g.  search(\"lost_password_state\")    synonym(\"word\") : gives a normalized cosine distance between the argument and the closest word in the user's sentence. We use word2vec, to have an idea of two words distance you can use this  word2vec demo  by  Turku University  similar(\"a whole sentence\") :  gives a normalized cosine distance between the argument and the closest word in the user's sentence (word2vec)  similarState(state_name) :  same as above, but for the sentences in the field \"queries\" of the state in the argument.  similarEucEmd(\"a whole sentence\") : gives a non-normalized euclidean distance (calculated using the earth movers distance algorithm) between the argument and the closest sentence in the user's sentence (word2vec)  similarEucEmdState(state_name) : same as above, but for the sentences in the field \"queries\" of the state in the argument.  similarCosEmd(\"a whole sentence\") : gives a normalized cosine distance (calculated using the earth movers distance algorithm) between the argument and the closest sentence in the user's sentence (word2vec)  similarCosEmdState(state_name) : same as above, but for the sentences in the field \"queries\" of the state in the argument.  matchPatternRegex(regex) : A generic pattern extraction analyzer, it extract named patterns matching a given regex e.g. the following will match tree numbers separated by semicolumn: [first,second,third](?:([0-9]+:[0-9]:[0-9]+) if the regex matches it will create the entries into the state variables dictionary e.g.: 10:11:12 will result in Map(\"first.0\" -> \"10\", \"second.0\" -> \"11\", \"third.0\" -> \"12\") the number at the end of the name is an index incremented for multiple occurrences of the pattern in the query  matchDateDDMMYYYY(prefix) : parse a date in DDMMYYYY format is built using the matchPatternRegex with the following regex: \"(?:(?:[^0-9]+|\\A)(0[1-9]|[12][0-9]|3[01])(?:[- \\/.])(0[1-9]|1[012])(?:[- \\/.])((?:19|20)\\d\\d)(?:[^0-9]+|$))\"  existsVariable(variable_name) : check whether a variable exists or not   hasTravState (state_name): check if a state_name is present into the history of traversed states  lastTravStateIs (state_name): check if the last traversed state is state_name  prevTravStateIs(state_name) : check if the last but one traversed state is state_name  distance(\"keyword1\", ..., \"keyword N\") : calculate the cosine distance between the query and the list of keywords, this analyzer can be called using  cosDistanceKeywords   Expressions: Operators  Operators evaluate the output of one or more expression and return a value. Currently, the following operators are implemented (the the  source code ):   boolean or :   calles matches of all the exprassions it contains and returns true or false. It can be called using  bor  boolean and :  as above, it's called with  band  boolean not :  ditto,  bnot  conjunction :  if the evaluation of the expressions it contains is normalized, and they can be seen as probabilities of them being true, this is the probability that all the expressions are all true ( P(A)*P(B) )  disjunction :  as above, the probability that at least one is true ( 1-(1-P(A))*(1-P(B)) )  max : takes the max score of returned by the expression arguments   Technical corner:  expressions  Expressions , like  keywords  in the example, are called  atoms , and have the following methods/members:   def evaluate(query: String): Double : produce a score. It might be normalized to 1 or not (set  val isEvaluateNormalized: Boolean  accordingly)  val match_threshold  This is the threshold above which the expression is considered true when  matches  is called. NB The default value is 0.0, which is normally not ideal.  def matches(query: String): Boolean : calles evaluate and check agains the threshold...  val rx : the name of the atom, as it should be used in the  analyzer  field.",
            "title": "NLP processing"
        },
        {
            "location": "/#configuration-of-the-answer-recommender-knowledge-base",
            "text": "Through the  /knowledgebase  endpoint\nyou can add, edit and remove pairs of question and answers used by StarChat to recommend possible answers when a question arrives.  Documents containing Q&A must be structured like that:  {\n    \"id\": \"0\",  // id of the pair\n    \"conversation\": \"id:1000\",   // id of the conversation. This can be useful to external services\n    \"index_in_conversation\": 1,  // when the pair appears inside the conversation, as above\n    \"question\": \"thank you\",  // The question to be matched\n    \"answer\": \"you are welcome!\",  // The answer to be recommended \n    \"question_scored_terms\": [  // A list of keyword and score. You can use your own keyword extractor or our Manaus (see later)\n        [\n            \"thank\", \n            1.9\n        ]\n    ],\n    \"verified\": true,  // A variable used in some call centers\n    \"topics\": \"t1 t2\",  // Eventual topics to be associated\n    \"dclass\": \"\", // Optional field as a searchable class for answer\n    \"doctype\": \"normal\",\n    \"state\": \"\",\n    \"status\": 0\n}  See  POST /knowledgebase  for an example with  curl . Other calls ( GET, DELETE, PUT ) are used to get the state, delete it or update it.   Test the knowledge base  Just run the example in  POST /knowledgebase_search .",
            "title": "Configuration of the answer recommender (Knowledge Base)"
        },
        {
            "location": "/#manaus",
            "text": "In the Q&A pair above you saw the field question_scored_terms . Having good keywords improves enormously the\nquality of the answer. You can of course put them by hand, or run a\nsoftware which extracts the keywords from the question. If you prefer\nthe latter, but don't have any, we provide Manaus .  Manaus is still under development, but it's already included in the\nDocker's installation of StarChat. When you launch  docker-compose up\n-d , you also launch a container with Manaus which analyzes all the\nQ&A in the Knowledge Base, produces keywords and updates the field\nquestion_scored_terms for all documents. The process is repeated evert\n4 hour.  Manaus configuration  Have a look at the file  docker-starchat/docker-compose.yml . For\nManaus to have good performance, you need to provide decent language\nstatistics. Update the file  /manaus/statistics_data/english/word_frequency.tsv  with a\nword-frequency file with the following format:  1       you     1222421\n2       I       1052546\n3       to      823661\n....  We have frequency file for more than 50 languages, but consider that\nthe choice of good \"prior distribution\" of word frequency is crucial\nfor any NLP task.",
            "title": "Manaus"
        },
        {
            "location": "/#technology",
            "text": "StarChat was design with the following goals in mind:   easy deployment  horizontally scalability without any service interruption.  modularity  statelessness",
            "title": "Technology"
        },
        {
            "location": "/#how-does-starchat-work",
            "text": "Workflow   Components  StarChat uses Elasticsearch as NoSQL database and, as said above, NLP preprocessor, for\nindexing, sentence cleansing, and tokenization.  Services  StarChat consists of two different services: the \"KnowledBase\" and the \"DecisionTable\"  KnowledgeBase  For quick setup based on real Q&A logs. It stores question and answers pairs. Given a text as input\n it proposes the pair with the closest match on the question field.\n  At the moment the KnowledBase supports only Analyzers implemented on Elasticsearch.  DecisionTable  The conversational engine itself. For the usage, see below.",
            "title": "How does StarChat work?"
        },
        {
            "location": "/#configuration-of-the-decisiontable",
            "text": "You configure the DecisionTable through CSV file. Please have a look at the  CSV provided in the doc/ directory .  Fields in the configuration file are of three types:   (R) : Return value: the field is returned by the API  (T) : Triggers to the state: when should we enter this state?   (I) : Internal: a field not exposed to the API   And the fields are:   state : a unique name of the state (e.g.  forgot_password )  execution_order : specify an order of evaluation for analyzers the lower is the number earlier is the evaluation of the state  max_state_count : defines how many times StarChat can repropose the state during a conversation.  analyzer (T,I) : specify an analyzer expression which triggers the state  query (T,I) : list of sentences whose meaning identify the state  bubble (R) : content, if any, to be shown to the user. It may contain variables like %email% or %link%.  action (R) : a function to be called on the client side. StarChat developer must provide types of input and output (like an abstract method), and the GUI developer is responsible for the actual implementation (e.g.  show_button )  action_input (R) : input passed to  action 's function (e.g., for  show_buttons  can be a list of pairs  (\"text to be shown on button\", state_to_go_when_clicked)    state_data (R) : a dictionary of strings with arbitrary data to pass along  success_value (R) : output to return in case of success  failure_value (R) : output to return in case of failure",
            "title": "Configuration of the DecisionTable"
        },
        {
            "location": "/#client-functions",
            "text": "In StarChat configuration, the developer can specify which function the front-end should\nexecute when a certain state is triggered, together with input parameters. Any function implemented on the front-end can be called.  Example show button   Action:  show_buttons  Action input:  {\"buttons\": [(\"Forgot Password\", \"forgot_password\"), (\"Account locked\", \"account_locked\")]}  The frontend will call function:  show_buttons(buttons={\"Forgot Password\": \"forgot_password\",\"Account locked\": \"account_locked\")   Example \"buttons\": the front-end implements the function show_buttons and uses \"action input\" to call it. It will show two buttons, where the first returns forgot_password and the second account_locked.  Example send email   Action:  send_password_link  Action input:  { \"template\": \"Reset your password here: example.com\",\"email\": \"%email%\",\"subject\": \"New password\" }  The frontend will call function:  send_password_link(template=\"Reset your password here: example.com.\",email= \"john@foo.com\", subject=\"New password\")   Example \"send email\": the front-end implements the function send_password_link and uses \"action input\" to call it.\nThe variable %email% is automatically substituted by the variable email if available in the JSON passed to the\nStarchatResource.  functions for the sample csv  For the CSV in the example above, the client will have to implement the following set of functions:   show_buttons: tell the client to render a multiple choice button  input: a key/value pair with the key indicating the text to be shown in the button, and the value indicating the state to follow e.g.: {\"Forgot Password\": \"forgot_password\", \"Account locked\": \"account_locked\", \"Specify your problem\": \"specify_problem\", \"I want to call an operator\": \"call_operator\", \"None of the above\": \"start\"}  output: the choice related to the button clicked by the user e.g.: \"account_locked\"  input_form: render an input form or collect the input following a specific format  input: a dictionary with the list of fields and the type of fields, at least \"email\" must be supported: e.g.: { \"email\": \"email\" } where the key is the name and the value is the type  output: a dictionary with the input values e.g.: { \"email\": \"foo@example.com\" }  send_password_generation_link: send an email with instructions to regenerate the password  input: a valid email address e.g.: \"foo@example.com\"  output: a dictionary with the response fields e.g.: { \"user_id\": \"123\", \"current_state\": \"forgot_password\", \"status\": \"true\" }   Ref:  sample_state_machine_specification.csv .",
            "title": "Client functions"
        },
        {
            "location": "/#mechanics",
            "text": "The client implements the functions which appear in the action field of the spreadsheet. \nWe will provide interfaces.  The client call the rest API \"decisiontable\" endpoint communicating a state if any, \nthe user input data and other state variables  The client receive a response with guidance on what to return to the user and what \nare the possible next steps  The client render the message to the user and eventually collect the input, then \ncall again the system to get instructions on what to do next  When the \"decisiontable\" functions does not return any result the user can call the \"knowledgebase\" endpoint which contains all the conversations.",
            "title": "Mechanics"
        },
        {
            "location": "/#scalability",
            "text": "StarChat consists of two different services: StarChat itself and an Elasticsearch cluster.   Scaling StarChat instances  StarChat can scale horizontally by simple replication. Because StarChat is stateless, instances looking \nat the same Elasticsearch index will behave identically. New instances can then be added together\nwith a load balancing service.  In the diagram below, a load balancer forward requests coming from the front-end to StarChat instances \n1, 2 or 3. These instances, as said, behave identically because they all refer to  Index 0  in the \nElasticsearch cluster.   Scaling Elasticsearch  Similarly, Elasticsearch can easily scale horizontally adding new nodes to the cluster, as explained\n in  Elasticsearch Documentation .",
            "title": "Scalability"
        },
        {
            "location": "/#security",
            "text": "StarChat is a backend service and  should never  be exposed to the internet,\nit should be placed behind a firewall.\nOne of the most effective and flexible method to add an access control layer is to use  Kong  in front of StarChat as a gateway, in this way\nStarChat can be shield by unwanted accesses.  In addition StarChat support TLS connections, the configuration file allow to\nchoose if the service should expose an https connection or an http connection\nor both.\nIn order to use the https connection the user must do the following things:   obtain a pkcs12 server certificate from a certification authority or  create a self signed certificate  save the certificate inside the folder  config/tls/certs/  e.g.  config/tls/certs/server.p12  set the password for the certificate inside the configuration file  enable the https connection setting to true the https.enable property of the configuration file  optionally disable the http connection setting to false the http.enable property of the configuration file   Follows the block of the configuration file which is to be modified as described above in\n order to use https:  https {\n  host = \"0.0.0.0\"\n  host = ${?HOST}\n  port = 8443\n  port = ${?PORT}\n  certificate = \"server.p12\"\n  password = \"uma7KnKwvh\"\n  enable = false\n}\n\nhttp {\n  host = \"0.0.0.0\"\n  host = ${?HOST}\n  port = 8888\n  port = ${?PORT}\n  enable = true\n}  StarChat come with a default self-signed certificate for testing,\nusing it for production or sensitive environment is highly discouraged\nas well as useless from a security point of view.",
            "title": "Security"
        },
        {
            "location": "/#indexing-terms-on-term-table",
            "text": "The following program index term vectors on the vector table:  sbt \"run-main com.getjenny.command.IndexTerms --inputfile terms.txt --vecsize 300\"  The format for each row of an input file with 5 dimension vectors is: hello 1.0 2.0 3.0 4.0 0.0  You can use your ad-hoc trained vector model (as we do) otherwise you can use the google word2vec models\ntrained on google news. You can find a copy of the  elasticsearch index with a pre-loaded google news terms .",
            "title": "Indexing terms on term table"
        },
        {
            "location": "/#test",
            "text": "",
            "title": "Test"
        },
        {
            "location": "/#unit-tests",
            "text": "A set of unit test is available using docker-compose to set up a backend, the command to run tests is:  sbt dockerComposeUp ; sbt test ; sbt dockerComposeStop",
            "title": "Unit tests"
        },
        {
            "location": "/#test-scripts-with-sample-api-calls",
            "text": "A set of test script is present inside scripts/api_test",
            "title": "test scripts with sample API calls"
        },
        {
            "location": "/#troubleshooting",
            "text": "",
            "title": "Troubleshooting"
        },
        {
            "location": "/#docker-start-from-scratch",
            "text": "You might want to start from scratch, and delete all docker images.   If you do so ( docker images  and then  docker rmi -f <java/elasticsearch ids> ) remember that all data for the \nElasticsearch docker are local, and mounted only when the container is up. Therefore you need to:  cd docker-starchat\nrm -rf elasticsearch/data/nodes/",
            "title": "Docker: start from scratch"
        },
        {
            "location": "/#docker-compose-analyzers-are-not-loaded",
            "text": "StarChat is started immediately after elasticsearch and it is possible that elasticsearch is\n not ready to respond to REST calls from StarChat (i.e. an index not found error could be\n raised in this case).  Sample error on the logs:  2017-06-15 10:37:22,993 >10:37:22.992UTC ERROR c.g.s.s.AnalyzerService(akka://starchat-service) com.getjenny.starchat.services.AnalyzerService(akka://starchat-service) - can't load analyzers: [jenny-en-0]\n IndexNotFoundException[no such index]  In order to avoid this problem you can call the services one by one:  docker-compose up elasticsearch # here wait elasticsearch is up and running\ndocker-compose up starchat # starchat will retrieve the Analyzers from elasticsearch  In alternative is possible to call the command to load/refresh the Analyzers after the docker-compose command:   curl -v -H \"Content-Type: application/json\" -X POST \"http://localhost:8888/decisiontable_analyzer\"",
            "title": "docker-compose: Analyzers are not loaded"
        },
        {
            "location": "/#docker-size-of-virtual-memory",
            "text": "If elasticsearch complain about the size of the virtual memory:  max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144]\nelastisearch exited with code 78  run:  sysctl -w vm.max_map_count=262144",
            "title": "Docker: Size of virtual memory"
        },
        {
            "location": "/apis/",
            "text": "APIs\n\n\nPOST /get_next_response\n\n\nTell StarChat about the user actions (wrote something, clicked a button etc) and receives instruction \nabout the next state.\n\n\nData to post:\n\n\n{\n  \"conversation_id\": \"1234\",\n  \"user_input\": { \"text\": \"the text typed by the user\" }, // optional\n  \"values\": {\n    \"return_value\": \"the value either in success_value or in failure_value (Optional)\", \n    \"data\": {} // all the variables, e.g. for the STRING TEMPLATEs (Optional)\n  },\n  \"threshold\": 0.0, // the minimum match threshold\n  \"max_results\": 4 // the max number of result to return\n}\n\n\n\n\n\nReturn codes\n\n\n200\n\n\nSimilar Json, see examples below\n\n\nExample 1\n\n\nUser input is \"I forgot my password\":\n\n\ncurl  -H \"Content-Type: application/json\" -X POST http://localhost:8888/get_next_response -d '{   \n    \"conversation_id\": \"1234\",\n    \"user_input\": { \"text\": \"I forgot my password\" },\n    \"values\": {\n        \"return_value\": \"\",\n        \"data\": {}\n    },\n    \"threshold\": 0.0,\n    \"max_results\": 4\n}'\n\n\n\n\nreturns:\n\n\n[\n   {\n      \"analyzer\" : \"and(or(keyword(\\\"reset\\\"),keyword(\\\"forgot\\\")),keyword(\\\"password\\\"))\",\n      \"state\" : \"forgot_password\",\n      \"score\" : 0.25,\n      \"action\" : \"input_form\",\n      \"action_input\" : {\n         \"email\" : \"email\"\n      },\n      \"traversed_states\" : [\n         \"forgot_password\"\n      ],\n      \"success_value\" : \"send_password_generation_link\",\n      \"data\" : {},\n      \"bubble\" : \"We can reset your password by sending you a message to your registered e-mail address. Please type your email address:\",\n      \"state_data\" : {\n         \"verification\" : \"did you mean you forgot the password?\"\n      },\n      \"max_state_count\" : 0,\n      \"failure_value\" : \"dont_understand\",\n      \"conversation_id\" : \"1234\"\n   }\n]\n\n\n\n\nExample 2\n\n\nUser inserts their email after having been in \nforgot_password\n. \nThe client sends:\n\n\ncurl  -H \"Content-Type: application/json\" -X POST http://localhost:8888/get_next_response -d '\n{\n    \"conversation_id\": \"1234\",\n    \"user_input\": { \"text\": \"\" },\n    \"values\": {\n        \"return_value\": \"send_password_generation_link\",\n        \"data\": { \"email\": \"john@example.com\" }\n    }\n}'\n\n\n\n\nand gets:\n\n\n[\n   {\n      \"traversed_states\" : [],\n      \"failure_value\" : \"call_operator\",\n      \"success_value\" : \"any_further\",\n      \"action\" : \"send_password_generation_link\",\n      \"state\" : \"send_password_generation_link\",\n      \"max_state_count\" : 0,\n      \"state_data\" : {},\n      \"conversation_id\" : \"1234\",\n      \"data\" : {\n         \"email\" : \"john@example.com\"\n      },\n      \"score\" : 1,\n      \"analyzer\" : \"\",\n      \"action_input\" : {\n         \"email\" : \"john@example.com\",\n         \"subject\" : \"New password\",\n         \"template\" : \"Hi,\\nSomeone requested a new password for your account. You can set a new password here: %link%\\nIf you did not request this, just ignore this message.\"\n      },\n      \"bubble\" : \"Thank you. An e-mail will be sent to this address: john@example.com with your account details and the necessary steps for you to reset your password.\"\n   }\n]\n\n\n\n\n204\n\n\nNo response was found\n\n\n500 (error)\n\n\nInternal server error\n\n\n400 (error)\n\n\nBad request: \n\n\n\n\nmeaning: the input data structure is not valid\n\n\noutput data: no data returned\n\n\n\n\n422 (error)\n\n\n\n\nmeaning: bad request data, the input data is formally valid but there is some issue with data interpretation\n\n\noutput data: the output data structure is a json dictionary with two fields: code and message. The following code are supported:\n\n\ncode: 100\n\n\nmessage: \"error evaluating the template strings, bad values\"\n\n\n\n\n404 (error)\n\n\n\n\nmeaning: not found\n\n\noutput data: no data returned\n\n\n\n\nGET /decisiontable\n\n\nGet a document by ID\n\n\nOutput JSON\n\n\nReturn codes\n\n\n200\n\n\nSample call\n\n\n# retrieve one or more entries with given ids; ids can be specified multiple times\ncurl -v -H \"Content-Type: application/json\" \"http://localhost:8888/decisiontable?ids=further_details_access_question\"\n\n\n\n\nSample output\n\n\n{\n   \"hits\" : [\n      {\n         \"score\" : 0,\n         \"document\" : {\n            \"execution_order\" : 1,\n            \"bubble\" : \"Hello and welcome to our customer service chat. Please note that while I am not a human operator, I will do my very best to assist You today. How may I help you?\",\n            \"state\" : \"further_details_access_question\",\n            \"max_state_count\" : 0,\n            \"queries\" : [\n               \"cannot access account\",\n               \"problem access account\"\n            ],\n            \"state_data\" : {\n               \"verification\" : \"did you mean you can't access to your account?\"\n            },\n            \"action_input\" : {\n               \"None of the above\" : \"start\",\n               \"Account locked\" : \"account_locked\",\n               \"Forgot Password\" : \"forgot_password\",\n               \"Specify your problem\" : \"specify_problem\",\n               \"I want to call an operator\" : \"call_operator\"\n            },\n            \"analyzer\" : \"or(and(or(keyword(\\\"problem.*\\\"),keyword(\\\"issue.*\\\"),keyword(\\\"trouble.*\\\")),keyword(\\\"account\\\")),search(\\\"further_details_access_question\\\"))\",\n            \"success_value\" : \"eval(show_buttons)\",\n            \"action\" : \"show_buttons\",\n            \"failure_value\" : \"dont_understand\"\n         }\n      }\n   ],\n   \"total\" : 1,\n   \"max_score\" : 0\n}\n\n\n\n\nPUT /decisiontable\n\n\nOutput JSON\n\n\nReturn codes\n\n\n201\n\n\nSample call\n\n\n# update the \"further_details_access_question\" entry in the DT\ncurl -v -H \"Content-Type: application/json\" -X PUT http://localhost:8888/decisiontable/further_details_access_question -d '{\n  \"queries\": [\"cannot access account\", \"problem access account\", \"unable to access to my account\"]\n}'\n\n\n\n\nSample output\n\n\n{\n    \"created\": false,\n    \"dtype\": \"state\",\n    \"id\": \"further_details_access_question\",\n    \"index\": \"jenny-en-0\",\n    \"version\": 2\n}\n\n\n\n\nPOST /decisiontable\n\n\nInsert a new document.\n\n\nOutput JSON\n\n\nReturn codes\n\n\n201\n\n\nSample call\n\n\ncurl -v -H \"Content-Type: application/json\" -X POST http://localhost:8888/decisiontable -d '{\n  \"state\": \"further_details_access_question\",\n  \"execution_order\": 1,\n  \"max_state_count\": 0,\n  \"analyzer\": \"\",\n  \"queries\": [\"cannot access account\", \"problem access account\"],\n  \"bubble\": \"What seems to be the problem exactly?\",\n  \"action\": \"show_buttons\",\n  \"action_input\": {\"Forgot Password\": \"forgot_password\", \"Account locked\": \"account_locked\", \"Payment problem\": \"payment_problem\", \"Specify your problem\": \"specify_problem\", \"I want to call an operator\": \"call_operator\", \"None of the above\": \"start\"},\n  \"success_value\": \"eval(show_buttons)\",\n  \"failure_value\": \"dont_understand\"\n}'\n\n\n\n\nSample output\n\n\n{\n    \"created\": true,\n    \"dtype\": \"state\",\n    \"id\": \"further_details_access_question\",\n    \"index\": \"jenny-en-0\",\n    \"version\": 1\n}\n\n\n\n\nDELETE /decisiontable\n\n\nDelete a document by ID\n\n\nOutput JSON\n\n\nReturn codes\n\n\n200\n\n\nSample call\n\n\ncurl -v -H \"Content-Type: application/json\" -X DELETE http://localhost:8888/decisiontable/further_details_access_question\n\n\n\n\nSample output\n\n\n{\n    \"dtype\": \"state\",\n    \"found\": true,\n    \"id\": \"further_details_access_question\",\n    \"index\": \"jenny-en-0\",\n    \"version\": 3\n}\n\n\n\n\nSample call: delete all\n\n\ncurl -v -H \"Content-Type: application/json\" -X DELETE http://localhost:8888/decisiontable\n\n\n\n\nSample output: delete all\n\n\n{\n   \"message\" : \"delete\",\n   \"deleted\" : 120\n}\n\n\n\n\nPOST /decisiontable_search\n\n\nUpdate a document\n\n\nOutput JSON\n\n\nReturn codes\n\n\n200\n\n\nSample call\n\n\ncurl -v -H \"Content-Type: application/json\" -X POST http://localhost:8888/decisiontable_search -d '{\n  \"queries\": \"cannot access my account\",\n  \"min_score\": 0.1,\n  \"boost_exact_match_factor\": 2.0\n}'\n\n\n\n\nSample response \n\n\n{\n   \"max_score\" : 0.930855453014374,\n   \"hits\" : [\n      {\n         \"document\" : {\n            \"action_input\" : {\n               \"I want to call an operator\" : \"call_operator\",\n               \"Forgot Password\" : \"forgot_password\",\n               \"None of the above\" : \"start\",\n               \"Account locked\" : \"account_locked\",\n               \"Specify your problem\" : \"specify_problem\"\n            },\n            \"bubble\" : \"Hello and welcome to our customer service chat. Please note that while I am not a human operator, I will do my very best to assist You today. How may I help you?\",\n            \"success_value\" : \"eval(show_buttons)\",\n            \"action\" : \"show_buttons\",\n            \"queries\" : [\n               \"cannot access account\",\n               \"problem access account\"\n            ],\n            \"execution_order\" : 1,\n            \"max_state_count\" : 0,\n            \"failure_value\" : \"dont_understand\",\n            \"state_data\" : {\n               \"verification\" : \"did you mean you can't access to your account?\"\n            },\n            \"analyzer\" : \"or(and(or(keyword(\\\"problem.*\\\"),keyword(\\\"issue.*\\\"),keyword(\\\"trouble.*\\\")),keyword(\\\"account\\\")),search(\\\"further_details_access_question\\\"))\",\n            \"state\" : \"further_details_access_question\"\n         },\n         \"score\" : 0.930855453014374\n      }\n   ],\n   \"total\" : 1\n}\n\n\n\n\nGET /decisiontable_analyzer\n\n\n(WORK IN PROGRESS, PARTIALLY IMPLEMENTED)\n\n\nGet and return the map of analyzer for each state\n\n\nOutput JSON\n\n\nReturn codes\n\n\n200\n\n\nSample call\n\n\ncurl -v -H \"Content-Type: application/json\" -X GET \"http://localhost:8888/decisiontable_analyzer\"\n\n\n\n\nSample response\n\n\n{\n   \"analyzer_map\" : {\n      \"account_locked\" : {\n         \"analyzer\" : \"booleanand(keyword(\\\"locked\\\"), keyword(\\\"account\\\"), )\",\n         \"execution_order\" : 1,\n         \"build\" : true\n      },\n      \"call_operator\" : {\n         \"analyzer\" : \"and(or(keyword(\\\"call\\\"),keyword(\\\"talk\\\"),keyword(\\\"speak\\\")),keyword(\\\"operator\\\"))\",\n         \"execution_order\" : 1,\n         \"build\" : true\n      },\n      \"forgot_password\" : {\n         \"execution_order\" : 1,\n         \"build\" : true,\n         \"analyzer\" : \"and(or(keyword(\\\"reset\\\"),keyword(\\\"forgot\\\")),keyword(\\\"password\\\"))\"\n      },\n      \"terrible_feedback\" : {\n         \"build\" : true,\n         \"execution_order\" : 1,\n         \"analyzer\" : \"booleanor(keyword(\\\"idiot\\\"), keyword(\\\"fuck.*\\\"), keyword(\\\"screw\\\"), keyword(\\\"damn.*\\\"), keyword(\\\"asshole\\\"))\"\n      },\n      \"test_state\" : {\n         \"analyzer\" : \"booleanAnd(booleanNot(booleanOr(keyword(\\\"dont\\\"),keyword(\\\"don't\\\"))), keyword(\\\"test\\\"), booleanOr(keyword(\\\"send\\\"), keyword(\\\"get\\\")))\",\n         \"execution_order\" : 1,\n         \"build\" : true\n      },\n      \"further_details_access_question\" : {\n         \"execution_order\" : 1,\n         \"build\" : true,\n         \"analyzer\" : \"or(and(or(keyword(\\\"problem.*\\\"),keyword(\\\"issue.*\\\"),keyword(\\\"trouble.*\\\")),keyword(\\\"account\\\")),search(\\\"further_details_access_question\\\"))\"\n      }\n   }\n}\n\n\n\n\nPOST /decisiontable_analyzer\n\n\nLoad/reload the map of analyzer from ES\n\n\nOutput JSON\n\n\nReturn codes\n\n\n200\n\n\nSample call\n\n\ncurl -v -H \"Content-Type: application/json\" -X POST \"http://localhost:8888/decisiontable_analyzer\"\n\n\n\n\nSample response\n\n\n{\"num_of_entries\":1}\n\n\n\n\nGET /knowledgebase\n\n\nReturn a document by ID\n\n\nOutput JSON\n\n\nReturn codes\n\n\n200\n\n\nSample call\n\n\n# retrieve one or more entries with given ids; ids can be specified multiple times\ncurl -v -H \"Content-Type: application/json\" \"http://localhost:8888/knowledgebase?ids=0\"\n\n\n\n\nSample response\n\n\n{\n   \"max_score\" : 0,\n   \"total\" : 1,\n   \"hits\" : [\n      {\n         \"score\" : 0,\n         \"document\" : {\n            \"conversation\" : \"id:1000\",\n            \"id\" : \"0\",\n            \"status\" : 0,\n            \"question_scored_terms\" : [\n               [\n                  \"thank\",\n          1.09\n               ]\n            ],\n            \"verified\" : true,\n            \"answer\" : \"you are welcome!\",\n            \"topics\" : \"t1 t2\",\n            \"doctype\" : \"normal\",\n            \"index_in_conversation\" : 1,\n            \"question\" : \"thank you\",\n            \"question_negative\" : [\n              \"thank you anyway\"\n            ],\n            \"state\" : \"\"\n         }\n      }\n   ]\n}\n\n\n\n\nPOST /knowledgebase\n\n\nInsert a new document\n\n\nReturn codes\n\n\n201\n\n\ncurl -v -H \"Content-Type: application/json\" -X POST http://localhost:8888/knowledgebase -d '{\n    \"id\": \"0\",\n    \"conversation\": \"id:1000\",\n    \"index_in_conversation\": 1,\n    \"question\": \"thank you\",\n    \"question_negative\": [\"thank you anyway\"],\n    \"answer\": \"you are welcome!\",\n    \"question_scored_terms\": [\n        [\n            \"thank\",\n            1.9\n        ]\n    ],\n    \"verified\": true,\n    \"topics\": \"t1 t2\",\n    \"doctype\": \"normal\",\n    \"state\": \"\",\n    \"status\": 0\n}'\n\n\n\n\nSample response\n\n\n{   \"dtype\": \"question\",\n    \"version\": 1,\n    \"id\": \"1\",\n    \"index\": \"jenny-en-0\",\n    \"created\":true\n}\n\n\n\n\nDELETE /knowledgebase\n\n\nDelete a document by ID\n\n\nOutput JSON\n\n\nReturn codes\n\n\n200\n\n\nSample call\n\n\ncurl -v -H \"Content-Type: application/json\" -X DELETE http://localhost:8888/knowledgebase/0\n\n\n\n\nSample output\n\n\n{\n   \"id\" : \"0\",\n   \"version\" : 5,\n   \"index\" : \"jenny-en-0\",\n   \"dtype\" : \"question\",\n   \"found\" : true\n}\n\n\n\n\nSample call: delete all\n\n\ncurl -v -H \"Content-Type: application/json\" -X DELETE http://localhost:8888/knowledgebase\n\n\n\n\nSample output: delete all\n\n\n{\n   \"message\" : \"delete\",\n   \"deleted\" : 10\n}\n\n\n\n\nPUT /knowledgebase\n\n\nUpdate an existing document\n\n\nOutput JSON\n\n\nReturn codes\n\n\n200\n\n\nSample call\n\n\ncurl -v -H \"Content-Type: application/json\" -X PUT http://localhost:8888/knowledgebase/0 -d '{\n    \"question_scored_terms\": [\n                [\n                        \"thank\",\n                        1.9\n                ],\n                [\n                        \"thanks\",\n                        1.9\n                ]\n    ]\n}'\n\n\n\n\nSample response\n\n\n{\n   \"index\" : \"jenny-en-0\",\n   \"dtype\" : \"question\",\n   \"id\" : \"0\",\n   \"version\" : 3,\n   \"created\" : false\n}\n\n\n\n\nPOST /knowledgebase_search\n\n\nOutput JSON\n\n\nReturn codes\n\n\n200\n\n\nSample call\n\n\ncurl -v -H \"Content-Type: application/json\" -X POST http://localhost:8888/knowledgebase_search -d '{\n  \"question\": \"thank you\",\n  \"verified\": true,\n  \"doctype\": \"normal\"\n}'\n\n\n\n\nSample output\n\n\n{\n   \"max_score\" : 1.15013706684113,\n   \"total\" : 2,\n   \"hits\" : [\n      {\n         \"document\" : {\n            \"id\" : \"1\",\n            \"doctype\" : \"normal\",\n            \"question_scored_terms\" : [\n               [\n                  \"validation\",\n                  0.0343148699683119\n               ],\n               [\n                  \"imac\",\n                  1.12982760046835\n               ],\n               [\n                  \"aware\",\n                  3.15048958129597\n               ],\n               [\n                  \"ios\",\n                  6.14545226791214\n               ],\n               [\n                  \"activation\",\n                  4.92133804309887\n               ]\n            ],\n            \"answer\" : \"fine thanks\",\n            \"conversation\" : \"id:1000\",\n            \"state\" : \"\",\n            \"question_negative\": [\n              \"thank you anyway\"\n            ],\n            \"question\" : \"how are you?\",\n            \"status\" : 0,\n            \"index_in_conversation\" : 1,\n            \"topics\" : \"t1 t2\",\n            \"verified\" : true\n         },\n         \"score\" : 1.15013706684113\n      }\n   ]\n}\n\n\n\n\nPOST /language_guesser\n\n\nOutput JSON\n\n\nReturn codes\n\n\n200\n\n\nSample call\n\n\ncurl -v -H \"Content-Type: application/json\" -X POST \"http://localhost:8888/language_guesser\" -d \"\n{\n    \\\"input_text\\\": \\\"good morning, may I ask you a question?\\\"\n}\"\n\n\n\n\nSample output\n\n\n{\n   \"enhough_text\" : false,\n   \"language\" : \"en\",\n   \"confidence\" : \"MEDIUM\",\n   \"score\" : 0.571426689624786\n}\n\n\n\n\nGET /language_guesser\n\n\nOutput JSON\n\n\nReturn codes\n\n\n200\n\n\nSample call\n\n\ncurl -v -H \"Content-Type: application/json\" -X GET \"http://localhost:8888/language_guesser/en\"\n\n\n\n\nSample output\n\n\n{\"message\":\"updated index: jenny-en-0 dt_type_ack(true) kb_type_ack(true) kb_type_ack(true)\"}\n\n\n\n\n\nPOST /index_management/create\n\n\nOutput JSON\n\n\nReturn codes\n\n\n200\n\n\nSample call\n\n\ncurl -v -H \"Content-Type: application/json\" -X POST \"http://localhost:8888/index_management\"\n\n\n\n\nSample output\n\n\n{\"message\":\"create index: jenny-en-0 create_index_ack(true)\"}\n\n\n\n\nPOST /index_management/refresh\n\n\nOutput JSON\n\n\nReturn codes\n\n\n200\n\n\nSample call\n\n\ncurl -v -H \"Content-Type: application/json\" -X POST \"http://localhost:8888/index_management/refresh\"\n\n\n\n\nSample output\n\n\n{\n   \"failed_shards_n\" : 0,\n   \"total_shards_n\" : 10,\n   \"failed_shards\" : [],\n   \"successful_shards_n\" : 5\n}\n\n\n\n\nGET /index_management\n\n\nOutput JSON\n\n\nReturn codes\n\n\n200\n\n\nSample call\n\n\ncurl -v -H \"Content-Type: application/json\" -X GET \"http://localhost:8888/index_management\"\n\n\n\n\nSample output\n\n\n{\"message\":\"settings index: jenny-en-0 dt_type_check(state:true) kb_type_check(question:true) term_type_name(term:true)\"}\n\n\n\n\nPUT /index_management\n\n\nOutput JSON\n\n\nReturn codes\n\n\n200\n\n\nSample call\n\n\ncurl -v -H \"Content-Type: application/json\" -X PUT \"http://localhost:8888/index_management\"\n\n\n\n\nSample output\n\n\n{\"message\":\"updated index: jenny-en-0 dt_type_ack(true) kb_type_ack(true) kb_type_ack(true)\"}\n\n\n\n\nDELETE /index_management\n\n\nOutput JSON\n\n\nReturn codes\n\n\n200\n\n\nSample call\n\n\ncurl -v -H \"Content-Type: application/json\" -X DELETE \"http://localhost:8888/index_management\"\n\n\n\n\nSample output\n\n\n{\"message\":\"removed index: jenny-en-0 index_ack(true)\"}\n\n\n\n\nPOST /term/index\n\n\nIndex the term as indicated in the JSON. \n\n\nReturn codes\n\n\n200\n\n\nSample call\n\n\ncurl -v -H \"Content-Type: application/json\" -X POST http://localhost:8888/term/index -d '{\n     \"terms\": [\n         {\n            \"term\": \"\u092e\u0930\u093e\u0920\u0940\",\n            \"frequency_base\": 1.0,\n            \"frequency_stem\": 1.0,\n            \"vector\": [1.0, 2.0, 3.0],\n            \"synonyms\":\n            {\n                \"bla1\": 0.1,\n                \"bla2\": 0.2\n            },\n            \"antonyms\":\n            {\n                \"bla3\": 0.1,\n                \"bla4\": 0.2\n            },\n            \"tags\": \"tag1 tag2\",\n            \"features\":\n            {\n                \"NUM\": \"S\",\n                \"GEN\": \"M\"\n            }\n            },\n            {\n            \"term\": \"term2\",\n            \"frequency_base\": 1.0,\n            \"frequency_stem\": 1.0,\n            \"vector\": [1.0, 2.0, 3.0],\n            \"synonyms\":\n            {\n                \"bla1\": 0.1,\n                \"bla2\": 0.2\n            },\n            \"antonyms\":\n            {\n                \"bla3\": 0.1,\n                \"bla4\": 0.2\n            },\n            \"tags\": \"tag1 tag2\",\n            \"features\":\n            {\n                \"NUM\": \"P\",\n                \"GEN\": \"F\"\n            }\n            }\n   ]\n}'\n\n\n\n\n\nSample output\n\n\n{\n   \"data\" : [\n      {\n         \"version\" : 1,\n         \"created\" : true,\n         \"dtype\" : \"term\",\n         \"index\" : \"jenny-en-0\",\n         \"id\" : \"\u092e\u0930\u093e\u0920\u0940\"\n      },\n      {\n         \"dtype\" : \"term\",\n         \"created\" : true,\n         \"version\" : 1,\n         \"id\" : \"term2\",\n         \"index\" : \"jenny-en-0\"\n      }\n   ]\n}\n\n\n\n\nPOST /term/get\n\n\nGet one or more terms entry.\n\n\nReturn codes\n\n\n200\n\n\nSample call\n\n\ncurl -v -H \"Content-Type: application/json\" -X POST http://localhost:8888/term/get -d '{\n     \"ids\": [\"\u092e\u0930\u093e\u0920\u0940\", \"term2\"]\n}'\n\n\n\n\nSample output\n\n\n{\n   \"terms\" : [\n      {\n         \"vector\" : [\n            1,\n            2,\n            3\n         ],\n        \"frequency_base\": 1.0,\n        \"frequency_stem\": 1.0,\n         \"term\" : \"\u092e\u0930\u093e\u0920\u0940\",\n         \"antonyms\" : {\n            \"bla4\" : 0.2,\n            \"bla3\" : 0.1\n         },\n         \"features\" : {\n            \"NUM\" : \"S\",\n            \"GEN\" : \"M\"\n         },\n         \"synonyms\" : {\n            \"bla2\" : 0.2,\n            \"bla1\" : 0.1\n         },\n         \"tags\" : \"tag1 tag2\"\n      },\n      {\n         \"antonyms\" : {\n            \"bla3\" : 0.1,\n            \"bla4\" : 0.2\n         },\n         \"features\" : {\n            \"NUM\" : \"P\",\n            \"GEN\" : \"F\"\n         },\n         \"term\" : \"term2\",\n         \"frequency_base\": 1.0,\n         \"frequency_stem\": 1.0,\n         \"vector\" : [\n            1,\n            2,\n            3\n         ],\n         \"synonyms\" : {\n            \"bla1\" : 0.1,\n            \"bla2\" : 0.2\n         },\n         \"tags\" : \"tag1 tag2\"\n      }\n   ]\n}\n\n\n\n\n\nDELETE /term\n\n\nDelete the term.\n\n\nReturn codes\n\n\n200\n\n\nSample call\n\n\ncurl -v -H \"Content-Type: application/json\" -X DELETE http://localhost:8888/term -d '{\n     \"ids\": [\"\u092e\u0930\u093e\u0920\u0940\", \"term2\"]\n}'\n\n\n\n\nSample output\n\n\n{\n   \"data\" : [\n      {\n         \"dtype\" : \"term\",\n         \"version\" : 2,\n         \"id\" : \"\u092e\u0930\u093e\u0920\u0940\",\n         \"index\" : \"jenny-en-0\",\n         \"found\" : true\n      },\n      {\n         \"dtype\" : \"term\",\n         \"id\" : \"term2\",\n         \"version\" : 2,\n         \"found\" : true,\n         \"index\" : \"jenny-en-0\"\n      }\n   ]\n}\n\n\n\n\n\nSample call: delete all\n\n\ncurl -v -H \"Content-Type: application/json\" -X DELETE http://localhost:8888/term -d'{\n        \"ids\": []\n}'\n\n\n\n\nSample call: delete all\n\n\n{\n  \"message\":\"delete\",\n  \"deleted\":2000\n}\n\n\n\n\nPUT /term\n\n\nUpdate the entry.\n\n\nReturn codes\n\n\n200\n\n\nSample call\n\n\ncurl -v -H \"Content-Type: application/json\" -X PUT http://localhost:8888/term -d '{\n     \"terms\": [\n         {\n            \"term\": \"\u092e\u0930\u093e\u0920\u0940\",\n            \"frequency_base\": 1.0,\n            \"frequency_stem\": 1.0,\n            \"vector\": [1.0, 2.0, 3.0, 4.0],\n            \"synonyms\":\n            {\n                \"bla1\": 0.1,\n                \"bla2\": 0.2\n            },\n            \"antonyms\":\n            {\n                \"term2\": 0.1,\n                \"bla4\": 0.2\n            },\n            \"tags\": \"tag1 tag2\",\n            \"features\":\n            {\n                \"FEATURE_NEW1\": \"V\",\n                \"GEN\": \"M\"\n            }\n            },\n            {\n            \"term\": \"term2\",\n            \"frequency_base\": 1.0,\n            \"frequency_stem\": 1.0,\n            \"vector\": [1.0, 2.0, 3.0, 5.0],\n            \"synonyms\":\n            {\n                \"bla1\": 0.1,\n                \"bla2\": 0.2\n            },\n            \"antonyms\":\n            {\n                \"bla3\": 0.1,\n                \"bla4\": 0.2\n            },\n            \"tags\": \"tag1 tag2\",\n            \"features\":\n            {\n                \"FEATURE_NEW1\": \"N\",\n                \"GEN\": \"F\"\n            }\n            }\n   ]\n}'\n\n\n\n\nSample output\n\n\n{\n   \"data\" : [\n      {\n         \"version\" : 2,\n         \"id\" : \"\u092e\u0930\u093e\u0920\u0940\",\n         \"index\" : \"jenny-en-0\",\n         \"created\" : false,\n         \"dtype\" : \"term\"\n      },\n      {\n         \"index\" : \"jenny-en-0\",\n         \"id\" : \"term2\",\n         \"version\" : 2,\n         \"dtype\" : \"term\",\n         \"created\" : false\n      }\n   ]\n}\n\n\n\n\n\nGET /term/term\n\n\nSearch for term (using Elasticsearch).\n\n\nReturn codes\n\n\n200\n\n\nSample call\n\n\ncurl -v -H \"Content-Type: application/json\" -X GET http://localhost:8888/term/term -d '{\n    \"term\": \"\u092e\u0930\u093e\u0920\u0940\"\n}'\n\n\n\n\nSample output\n\n\n{\n   \"hits\" : {\n      \"terms\" : [\n         {\n            \"vector\" : [\n               1.2,\n               2.3,\n               3.4,\n               4.5\n            ],\n            \"antonyms\" : {\n               \"bla4\" : 0.2,\n               \"term2\" : 0.1\n            },\n            \"frequency_base\": 1.0,\n            \"frequency_stem\": 1.0,\n            \"features\" : {\n               \"FEATURE_NEW1\" : \"V\",\n               \"GEN\" : \"M\"\n            },\n            \"score\" : 0.6931471824646,\n            \"tags\" : \"tag1 tag2\",\n            \"term\" : \"\u092e\u0930\u093e\u0920\u0940\",\n            \"synonyms\" : {\n               \"bla2\" : 0.2,\n               \"bla1\" : 0.1\n            }\n         }\n      ]\n   },\n   \"total\" : 1,\n   \"max_score\" : 0.6931471824646\n}\n\n\n\n\nGET /term/text\n\n\nSearch for all the terms in the text and return the entries.\n\n\nReturn codes\n\n\n200\n\n\nSample call\n\n\ncurl -v -H \"Content-Type: application/json\" -X GET http://localhost:8888/term/text -d 'term2 \u092e\u0930\u093e\u0920\u0940'\n\n\n\n\nSample output\n\n\n{\n   \"max_score\" : 0.6931471824646,\n   \"hits\" : {\n      \"terms\" : [\n         {\n            \"term\" : \"\u092e\u0930\u093e\u0920\u0940\",\n            \"score\" : 0.6931471824646,\n            \"tags\" : \"tag1 tag2\",\n            \"vector\" : [\n               1.2,\n               2.3,\n               3.4,\n               4.5\n            ],\n            \"features\" : {\n               \"GEN\" : \"M\",\n               \"FEATURE_NEW1\" : \"V\"\n            },\n            \"antonyms\" : {\n               \"bla4\" : 0.2,\n               \"term2\" : 0.1\n            },\n            \"synonyms\" : {\n               \"bla2\" : 0.2,\n               \"bla1\" : 0.1\n            },\n            \"frequency_base\": 1.0,\n            \"frequency_stem\": 1.0\n         },\n         {\n            \"term\" : \"term2\",\n            \"tags\" : \"tag1 tag2\",\n            \"score\" : 0.6931471824646,\n            \"features\" : {\n               \"FEATURE_NEW1\" : \"N\",\n               \"GEN\" : \"F\"\n            },\n            \"vector\" : [\n               1.6,\n               2.7,\n               3.8,\n               5.9\n            ],\n            \"antonyms\" : {\n               \"bla3\" : 0.1,\n               \"bla4\" : 0.2\n            },\n            \"frequency_base\": 1.0,\n            \"frequency_stem\": 1.0,\n            \"synonyms\" : {\n               \"bla1\" : 0.1,\n               \"bla2\" : 0.2\n            }\n         }\n      ]\n   },\n   \"total\" : 2\n}\n\n\n\n\nGET /tokenizers\n\n\nShow a list of supported methods for tokenization and stemming\n\n\nReturn codes\n\n\n200\n\n\nSample call\n\n\ncurl -v -H \"Content-Type: application/json\" -X GET \"http://localhost:8888/tokenizers\"\n\n\n\n\nSample output\n\n\n{\n   \"shingles2\" : \"2 words shingles\",\n   \"shingles3\" : \"3 words shingles\",\n   \"shingles2_10\" : \"from 2 to 10 shingles\",\n   \"base_stem\" : \"lowercase + stemming\",\n   \"base\" : \"lowercase\",\n   \"stop\" : \"lowercase + stopwords elimination\",\n   \"shingles4\" : \"4 words shingles\",\n   \"stop_stem\" : \"lowercase + stopwords elimination + stemming\"\n}\n\n\n\n\nPOST /tokenizers\n\n\nget a list of token using the selected analyzer\n\n\nReturn codes\n\n\n200\n\n\nSample call\n\n\ncurl -v -H \"Content-Type: application/json\" -X POST \"http://localhost:8888/tokenizers\" -d \"\n{\n    \\\"text\\\": \\\"good morning, may I ask you a question?\\\",\n          \\\"tokenizer\\\": \\\"stop\\\"\n          }\"\n\n\n\n\nSample output\n\n\n{\n   \"tokens\" : [\n      {\n         \"start_offset\" : 0,\n         \"end_offset\" : 4,\n         \"token_type\" : \"word\",\n         \"token\" : \"good\",\n         \"position\" : 0\n      },\n      {\n         \"token\" : \"morning\",\n         \"position\" : 1,\n         \"token_type\" : \"word\",\n         \"end_offset\" : 12,\n         \"start_offset\" : 5\n      },\n      {\n         \"start_offset\" : 14,\n         \"end_offset\" : 17,\n         \"token_type\" : \"word\",\n         \"token\" : \"may\",\n         \"position\" : 2\n      },\n      {\n         \"token_type\" : \"word\",\n         \"token\" : \"i\",\n         \"position\" : 3,\n         \"start_offset\" : 18,\n         \"end_offset\" : 19\n      },\n      {\n         \"end_offset\" : 23,\n         \"start_offset\" : 20,\n         \"position\" : 4,\n         \"token\" : \"ask\",\n         \"token_type\" : \"word\"\n      },\n      {\n         \"end_offset\" : 27,\n         \"start_offset\" : 24,\n         \"position\" : 5,\n         \"token\" : \"you\",\n         \"token_type\" : \"word\"\n      },\n      {\n         \"end_offset\" : 38,\n         \"start_offset\" : 30,\n         \"token\" : \"question\",\n         \"position\" : 7,\n         \"token_type\" : \"word\"\n      }\n   ]\n}\n\n\n\n\nPOST /analyzers_playground\n\n\nused to test analyzers on the fly\n\n\nReturn codes\n\n\n200\n\n\nSample call keyword\n\n\ncurl -v -H 'Content-Type: application/json' -X POST http://localhost:8888/analyzers_playground -d '\n{\n        \"analyzer\": \"keyword(\\\"test\\\")\",\n        \"query\": \"this is a test\",\n        \"data\": {\"item_list\": [], \"extracted_variables\":{}}\n}\n'\n\n\n\n\nSample output keyword\n\n\n{\n   \"build_message\" : \"success\",\n   \"build\" : true,\n   \"value\" : 0.25\n}\n\n\n\n\nSample states analyzers\n\n\ncurl -v -H 'Content-Type: application/json' -X POST http://localhost:8888/analyzers_playground -d '\n{\n        \"analyzer\": \"hasTravState(\\\"one\\\")\",\n        \"query\": \"query\",\n        \"data\": {\"item_list\": [\"one\", \"two\"], \"extracted_variables\":{}}\n}\n'\n\n\n\n\nSample output states analyzers\n\n\n{\n   \"build_message\" : \"success\",\n   \"build\" : true,\n   \"value\" : 1\n}\n\n\n\n\nSample of pattern extraction through analyzers\n\n\ncurl -v -H 'Content-Type: application/json' -X POST http://localhost:8888/analyzers_playground -d' \n{\n        \"analyzer\": \"band(keyword(\\\"on\\\"), matchPatternRegex(\\\"[day,month,year](?:(0[1-9]|[12][0-9]|3[01])(?:[- \\\\\\/\\\\.])(0[1-9]|1[012])(?:[- \\\\\\/\\\\.])((?:19|20)\\\\d\\\\d))\\\"))\",\n        \"query\": \"on 31-11-1900\"\n}'\n\n\n\n\nSample output\n\n\n{\n   \"build_message\" : \"success\",\n   \"variables\" : {\n      \"month.0\" : \"11\",\n      \"day.0\" : \"31\",\n      \"year.0\" : \"1900\"\n   },\n   \"build\" : true,\n   \"value\" : 1\n}\n\n\n\n\nPOST /spellcheck/terms\n\n\nterms spellchecker based on knowledgebase text \n\n\nReturn codes\n\n\n200\n\n\nSample call\n\n\nQUERY=${1:-\"this is a tes for splellchecker\"}\ncurl -v -H \"Content-Type: application/json\" -X POST http://localhost:8888/spellcheck/terms -d \"{\n  \\\"text\\\": \\\"${QUERY}\\\",\n    \\\"prefix_length\\\": 3,\n      \\\"min_doc_freq\\\": 1\n      }\"\n\n\n\n\n{\n   \"tokens\" : [\n      {\n         \"offset\" : 0,\n         \"options\" : [\n            {\n               \"freq\" : 1284,\n               \"score\" : 0.800000011920929,\n               \"text\" : \"hello\"\n            },\n            {\n               \"text\" : \"hella\",\n               \"score\" : 0.800000011920929,\n               \"freq\" : 2\n            },\n            {\n               \"freq\" : 2,\n               \"score\" : 0.800000011920929,\n               \"text\" : \"helle\"\n            },\n            {\n               \"text\" : \"help\",\n               \"score\" : 0.75,\n               \"freq\" : 35395\n            },\n            {\n               \"score\" : 0.75,\n               \"freq\" : 5,\n               \"text\" : \"hell\"\n            }\n         ],\n         \"length\" : 5,\n         \"text\" : \"hellp\"\n      },\n      {\n         \"length\" : 4,\n         \"options\" : [],\n         \"offset\" : 7,\n         \"text\" : \"this\"\n      },\n      {\n         \"length\" : 2,\n         \"options\" : [],\n         \"offset\" : 12,\n         \"text\" : \"is\"\n      },\n      {\n         \"length\" : 1,\n         \"offset\" : 15,\n         \"options\" : [],\n         \"text\" : \"a\"\n      },\n      {\n         \"length\" : 4,\n         \"offset\" : 17,\n         \"options\" : [\n            {\n               \"text\" : \"test\",\n               \"score\" : 0.75,\n               \"freq\" : 191\n            },\n            {\n               \"freq\" : 10,\n               \"score\" : 0.5,\n               \"text\" : \"tessa\"\n            },\n            {\n               \"text\" : \"tesco\",\n               \"score\" : 0.5,\n               \"freq\" : 9\n            },\n            {\n               \"text\" : \"tesia\",\n               \"score\" : 0.5,\n               \"freq\" : 2\n            },\n            {\n               \"freq\" : 2,\n               \"score\" : 0.5,\n               \"text\" : \"tester\"\n            }\n         ],\n         \"text\" : \"tesr\"\n      }\n   ]\n}",
            "title": "APIs"
        },
        {
            "location": "/apis/#apis",
            "text": "",
            "title": "APIs"
        },
        {
            "location": "/apis/#post-get_next_response",
            "text": "Tell StarChat about the user actions (wrote something, clicked a button etc) and receives instruction \nabout the next state.  Data to post:  {\n  \"conversation_id\": \"1234\",\n  \"user_input\": { \"text\": \"the text typed by the user\" }, // optional\n  \"values\": {\n    \"return_value\": \"the value either in success_value or in failure_value (Optional)\", \n    \"data\": {} // all the variables, e.g. for the STRING TEMPLATEs (Optional)\n  },\n  \"threshold\": 0.0, // the minimum match threshold\n  \"max_results\": 4 // the max number of result to return\n}  Return codes  200  Similar Json, see examples below  Example 1  User input is \"I forgot my password\":  curl  -H \"Content-Type: application/json\" -X POST http://localhost:8888/get_next_response -d '{   \n    \"conversation_id\": \"1234\",\n    \"user_input\": { \"text\": \"I forgot my password\" },\n    \"values\": {\n        \"return_value\": \"\",\n        \"data\": {}\n    },\n    \"threshold\": 0.0,\n    \"max_results\": 4\n}'  returns:  [\n   {\n      \"analyzer\" : \"and(or(keyword(\\\"reset\\\"),keyword(\\\"forgot\\\")),keyword(\\\"password\\\"))\",\n      \"state\" : \"forgot_password\",\n      \"score\" : 0.25,\n      \"action\" : \"input_form\",\n      \"action_input\" : {\n         \"email\" : \"email\"\n      },\n      \"traversed_states\" : [\n         \"forgot_password\"\n      ],\n      \"success_value\" : \"send_password_generation_link\",\n      \"data\" : {},\n      \"bubble\" : \"We can reset your password by sending you a message to your registered e-mail address. Please type your email address:\",\n      \"state_data\" : {\n         \"verification\" : \"did you mean you forgot the password?\"\n      },\n      \"max_state_count\" : 0,\n      \"failure_value\" : \"dont_understand\",\n      \"conversation_id\" : \"1234\"\n   }\n]  Example 2  User inserts their email after having been in  forgot_password . \nThe client sends:  curl  -H \"Content-Type: application/json\" -X POST http://localhost:8888/get_next_response -d '\n{\n    \"conversation_id\": \"1234\",\n    \"user_input\": { \"text\": \"\" },\n    \"values\": {\n        \"return_value\": \"send_password_generation_link\",\n        \"data\": { \"email\": \"john@example.com\" }\n    }\n}'  and gets:  [\n   {\n      \"traversed_states\" : [],\n      \"failure_value\" : \"call_operator\",\n      \"success_value\" : \"any_further\",\n      \"action\" : \"send_password_generation_link\",\n      \"state\" : \"send_password_generation_link\",\n      \"max_state_count\" : 0,\n      \"state_data\" : {},\n      \"conversation_id\" : \"1234\",\n      \"data\" : {\n         \"email\" : \"john@example.com\"\n      },\n      \"score\" : 1,\n      \"analyzer\" : \"\",\n      \"action_input\" : {\n         \"email\" : \"john@example.com\",\n         \"subject\" : \"New password\",\n         \"template\" : \"Hi,\\nSomeone requested a new password for your account. You can set a new password here: %link%\\nIf you did not request this, just ignore this message.\"\n      },\n      \"bubble\" : \"Thank you. An e-mail will be sent to this address: john@example.com with your account details and the necessary steps for you to reset your password.\"\n   }\n]  204  No response was found  500 (error)  Internal server error  400 (error)  Bad request:    meaning: the input data structure is not valid  output data: no data returned   422 (error)   meaning: bad request data, the input data is formally valid but there is some issue with data interpretation  output data: the output data structure is a json dictionary with two fields: code and message. The following code are supported:  code: 100  message: \"error evaluating the template strings, bad values\"   404 (error)   meaning: not found  output data: no data returned",
            "title": "POST /get_next_response"
        },
        {
            "location": "/apis/#get-decisiontable",
            "text": "Get a document by ID  Output JSON  Return codes  200  Sample call  # retrieve one or more entries with given ids; ids can be specified multiple times\ncurl -v -H \"Content-Type: application/json\" \"http://localhost:8888/decisiontable?ids=further_details_access_question\"  Sample output  {\n   \"hits\" : [\n      {\n         \"score\" : 0,\n         \"document\" : {\n            \"execution_order\" : 1,\n            \"bubble\" : \"Hello and welcome to our customer service chat. Please note that while I am not a human operator, I will do my very best to assist You today. How may I help you?\",\n            \"state\" : \"further_details_access_question\",\n            \"max_state_count\" : 0,\n            \"queries\" : [\n               \"cannot access account\",\n               \"problem access account\"\n            ],\n            \"state_data\" : {\n               \"verification\" : \"did you mean you can't access to your account?\"\n            },\n            \"action_input\" : {\n               \"None of the above\" : \"start\",\n               \"Account locked\" : \"account_locked\",\n               \"Forgot Password\" : \"forgot_password\",\n               \"Specify your problem\" : \"specify_problem\",\n               \"I want to call an operator\" : \"call_operator\"\n            },\n            \"analyzer\" : \"or(and(or(keyword(\\\"problem.*\\\"),keyword(\\\"issue.*\\\"),keyword(\\\"trouble.*\\\")),keyword(\\\"account\\\")),search(\\\"further_details_access_question\\\"))\",\n            \"success_value\" : \"eval(show_buttons)\",\n            \"action\" : \"show_buttons\",\n            \"failure_value\" : \"dont_understand\"\n         }\n      }\n   ],\n   \"total\" : 1,\n   \"max_score\" : 0\n}",
            "title": "GET /decisiontable"
        },
        {
            "location": "/apis/#put-decisiontable",
            "text": "Output JSON  Return codes  201  Sample call  # update the \"further_details_access_question\" entry in the DT\ncurl -v -H \"Content-Type: application/json\" -X PUT http://localhost:8888/decisiontable/further_details_access_question -d '{\n  \"queries\": [\"cannot access account\", \"problem access account\", \"unable to access to my account\"]\n}'  Sample output  {\n    \"created\": false,\n    \"dtype\": \"state\",\n    \"id\": \"further_details_access_question\",\n    \"index\": \"jenny-en-0\",\n    \"version\": 2\n}",
            "title": "PUT /decisiontable"
        },
        {
            "location": "/apis/#post-decisiontable",
            "text": "Insert a new document.  Output JSON  Return codes  201  Sample call  curl -v -H \"Content-Type: application/json\" -X POST http://localhost:8888/decisiontable -d '{\n  \"state\": \"further_details_access_question\",\n  \"execution_order\": 1,\n  \"max_state_count\": 0,\n  \"analyzer\": \"\",\n  \"queries\": [\"cannot access account\", \"problem access account\"],\n  \"bubble\": \"What seems to be the problem exactly?\",\n  \"action\": \"show_buttons\",\n  \"action_input\": {\"Forgot Password\": \"forgot_password\", \"Account locked\": \"account_locked\", \"Payment problem\": \"payment_problem\", \"Specify your problem\": \"specify_problem\", \"I want to call an operator\": \"call_operator\", \"None of the above\": \"start\"},\n  \"success_value\": \"eval(show_buttons)\",\n  \"failure_value\": \"dont_understand\"\n}'  Sample output  {\n    \"created\": true,\n    \"dtype\": \"state\",\n    \"id\": \"further_details_access_question\",\n    \"index\": \"jenny-en-0\",\n    \"version\": 1\n}",
            "title": "POST /decisiontable"
        },
        {
            "location": "/apis/#delete-decisiontable",
            "text": "Delete a document by ID  Output JSON  Return codes  200  Sample call  curl -v -H \"Content-Type: application/json\" -X DELETE http://localhost:8888/decisiontable/further_details_access_question  Sample output  {\n    \"dtype\": \"state\",\n    \"found\": true,\n    \"id\": \"further_details_access_question\",\n    \"index\": \"jenny-en-0\",\n    \"version\": 3\n}  Sample call: delete all  curl -v -H \"Content-Type: application/json\" -X DELETE http://localhost:8888/decisiontable  Sample output: delete all  {\n   \"message\" : \"delete\",\n   \"deleted\" : 120\n}",
            "title": "DELETE /decisiontable"
        },
        {
            "location": "/apis/#post-decisiontable_search",
            "text": "Update a document  Output JSON  Return codes  200  Sample call  curl -v -H \"Content-Type: application/json\" -X POST http://localhost:8888/decisiontable_search -d '{\n  \"queries\": \"cannot access my account\",\n  \"min_score\": 0.1,\n  \"boost_exact_match_factor\": 2.0\n}'  Sample response   {\n   \"max_score\" : 0.930855453014374,\n   \"hits\" : [\n      {\n         \"document\" : {\n            \"action_input\" : {\n               \"I want to call an operator\" : \"call_operator\",\n               \"Forgot Password\" : \"forgot_password\",\n               \"None of the above\" : \"start\",\n               \"Account locked\" : \"account_locked\",\n               \"Specify your problem\" : \"specify_problem\"\n            },\n            \"bubble\" : \"Hello and welcome to our customer service chat. Please note that while I am not a human operator, I will do my very best to assist You today. How may I help you?\",\n            \"success_value\" : \"eval(show_buttons)\",\n            \"action\" : \"show_buttons\",\n            \"queries\" : [\n               \"cannot access account\",\n               \"problem access account\"\n            ],\n            \"execution_order\" : 1,\n            \"max_state_count\" : 0,\n            \"failure_value\" : \"dont_understand\",\n            \"state_data\" : {\n               \"verification\" : \"did you mean you can't access to your account?\"\n            },\n            \"analyzer\" : \"or(and(or(keyword(\\\"problem.*\\\"),keyword(\\\"issue.*\\\"),keyword(\\\"trouble.*\\\")),keyword(\\\"account\\\")),search(\\\"further_details_access_question\\\"))\",\n            \"state\" : \"further_details_access_question\"\n         },\n         \"score\" : 0.930855453014374\n      }\n   ],\n   \"total\" : 1\n}",
            "title": "POST /decisiontable_search"
        },
        {
            "location": "/apis/#get-decisiontable_analyzer",
            "text": "(WORK IN PROGRESS, PARTIALLY IMPLEMENTED)  Get and return the map of analyzer for each state  Output JSON  Return codes  200  Sample call  curl -v -H \"Content-Type: application/json\" -X GET \"http://localhost:8888/decisiontable_analyzer\"  Sample response  {\n   \"analyzer_map\" : {\n      \"account_locked\" : {\n         \"analyzer\" : \"booleanand(keyword(\\\"locked\\\"), keyword(\\\"account\\\"), )\",\n         \"execution_order\" : 1,\n         \"build\" : true\n      },\n      \"call_operator\" : {\n         \"analyzer\" : \"and(or(keyword(\\\"call\\\"),keyword(\\\"talk\\\"),keyword(\\\"speak\\\")),keyword(\\\"operator\\\"))\",\n         \"execution_order\" : 1,\n         \"build\" : true\n      },\n      \"forgot_password\" : {\n         \"execution_order\" : 1,\n         \"build\" : true,\n         \"analyzer\" : \"and(or(keyword(\\\"reset\\\"),keyword(\\\"forgot\\\")),keyword(\\\"password\\\"))\"\n      },\n      \"terrible_feedback\" : {\n         \"build\" : true,\n         \"execution_order\" : 1,\n         \"analyzer\" : \"booleanor(keyword(\\\"idiot\\\"), keyword(\\\"fuck.*\\\"), keyword(\\\"screw\\\"), keyword(\\\"damn.*\\\"), keyword(\\\"asshole\\\"))\"\n      },\n      \"test_state\" : {\n         \"analyzer\" : \"booleanAnd(booleanNot(booleanOr(keyword(\\\"dont\\\"),keyword(\\\"don't\\\"))), keyword(\\\"test\\\"), booleanOr(keyword(\\\"send\\\"), keyword(\\\"get\\\")))\",\n         \"execution_order\" : 1,\n         \"build\" : true\n      },\n      \"further_details_access_question\" : {\n         \"execution_order\" : 1,\n         \"build\" : true,\n         \"analyzer\" : \"or(and(or(keyword(\\\"problem.*\\\"),keyword(\\\"issue.*\\\"),keyword(\\\"trouble.*\\\")),keyword(\\\"account\\\")),search(\\\"further_details_access_question\\\"))\"\n      }\n   }\n}",
            "title": "GET /decisiontable_analyzer"
        },
        {
            "location": "/apis/#post-decisiontable_analyzer",
            "text": "Load/reload the map of analyzer from ES  Output JSON  Return codes  200  Sample call  curl -v -H \"Content-Type: application/json\" -X POST \"http://localhost:8888/decisiontable_analyzer\"  Sample response  {\"num_of_entries\":1}",
            "title": "POST /decisiontable_analyzer"
        },
        {
            "location": "/apis/#get-knowledgebase",
            "text": "Return a document by ID  Output JSON  Return codes  200  Sample call  # retrieve one or more entries with given ids; ids can be specified multiple times\ncurl -v -H \"Content-Type: application/json\" \"http://localhost:8888/knowledgebase?ids=0\"  Sample response  {\n   \"max_score\" : 0,\n   \"total\" : 1,\n   \"hits\" : [\n      {\n         \"score\" : 0,\n         \"document\" : {\n            \"conversation\" : \"id:1000\",\n            \"id\" : \"0\",\n            \"status\" : 0,\n            \"question_scored_terms\" : [\n               [\n                  \"thank\",\n          1.09\n               ]\n            ],\n            \"verified\" : true,\n            \"answer\" : \"you are welcome!\",\n            \"topics\" : \"t1 t2\",\n            \"doctype\" : \"normal\",\n            \"index_in_conversation\" : 1,\n            \"question\" : \"thank you\",\n            \"question_negative\" : [\n              \"thank you anyway\"\n            ],\n            \"state\" : \"\"\n         }\n      }\n   ]\n}",
            "title": "GET /knowledgebase"
        },
        {
            "location": "/apis/#post-knowledgebase",
            "text": "Insert a new document  Return codes  201  curl -v -H \"Content-Type: application/json\" -X POST http://localhost:8888/knowledgebase -d '{\n    \"id\": \"0\",\n    \"conversation\": \"id:1000\",\n    \"index_in_conversation\": 1,\n    \"question\": \"thank you\",\n    \"question_negative\": [\"thank you anyway\"],\n    \"answer\": \"you are welcome!\",\n    \"question_scored_terms\": [\n        [\n            \"thank\",\n            1.9\n        ]\n    ],\n    \"verified\": true,\n    \"topics\": \"t1 t2\",\n    \"doctype\": \"normal\",\n    \"state\": \"\",\n    \"status\": 0\n}'  Sample response  {   \"dtype\": \"question\",\n    \"version\": 1,\n    \"id\": \"1\",\n    \"index\": \"jenny-en-0\",\n    \"created\":true\n}",
            "title": "POST /knowledgebase"
        },
        {
            "location": "/apis/#delete-knowledgebase",
            "text": "Delete a document by ID  Output JSON  Return codes  200  Sample call  curl -v -H \"Content-Type: application/json\" -X DELETE http://localhost:8888/knowledgebase/0  Sample output  {\n   \"id\" : \"0\",\n   \"version\" : 5,\n   \"index\" : \"jenny-en-0\",\n   \"dtype\" : \"question\",\n   \"found\" : true\n}  Sample call: delete all  curl -v -H \"Content-Type: application/json\" -X DELETE http://localhost:8888/knowledgebase  Sample output: delete all  {\n   \"message\" : \"delete\",\n   \"deleted\" : 10\n}",
            "title": "DELETE /knowledgebase"
        },
        {
            "location": "/apis/#put-knowledgebase",
            "text": "Update an existing document  Output JSON  Return codes  200  Sample call  curl -v -H \"Content-Type: application/json\" -X PUT http://localhost:8888/knowledgebase/0 -d '{\n    \"question_scored_terms\": [\n                [\n                        \"thank\",\n                        1.9\n                ],\n                [\n                        \"thanks\",\n                        1.9\n                ]\n    ]\n}'  Sample response  {\n   \"index\" : \"jenny-en-0\",\n   \"dtype\" : \"question\",\n   \"id\" : \"0\",\n   \"version\" : 3,\n   \"created\" : false\n}",
            "title": "PUT /knowledgebase"
        },
        {
            "location": "/apis/#post-knowledgebase_search",
            "text": "Output JSON  Return codes  200  Sample call  curl -v -H \"Content-Type: application/json\" -X POST http://localhost:8888/knowledgebase_search -d '{\n  \"question\": \"thank you\",\n  \"verified\": true,\n  \"doctype\": \"normal\"\n}'  Sample output  {\n   \"max_score\" : 1.15013706684113,\n   \"total\" : 2,\n   \"hits\" : [\n      {\n         \"document\" : {\n            \"id\" : \"1\",\n            \"doctype\" : \"normal\",\n            \"question_scored_terms\" : [\n               [\n                  \"validation\",\n                  0.0343148699683119\n               ],\n               [\n                  \"imac\",\n                  1.12982760046835\n               ],\n               [\n                  \"aware\",\n                  3.15048958129597\n               ],\n               [\n                  \"ios\",\n                  6.14545226791214\n               ],\n               [\n                  \"activation\",\n                  4.92133804309887\n               ]\n            ],\n            \"answer\" : \"fine thanks\",\n            \"conversation\" : \"id:1000\",\n            \"state\" : \"\",\n            \"question_negative\": [\n              \"thank you anyway\"\n            ],\n            \"question\" : \"how are you?\",\n            \"status\" : 0,\n            \"index_in_conversation\" : 1,\n            \"topics\" : \"t1 t2\",\n            \"verified\" : true\n         },\n         \"score\" : 1.15013706684113\n      }\n   ]\n}",
            "title": "POST /knowledgebase_search"
        },
        {
            "location": "/apis/#post-language_guesser",
            "text": "Output JSON  Return codes  200  Sample call  curl -v -H \"Content-Type: application/json\" -X POST \"http://localhost:8888/language_guesser\" -d \"\n{\n    \\\"input_text\\\": \\\"good morning, may I ask you a question?\\\"\n}\"  Sample output  {\n   \"enhough_text\" : false,\n   \"language\" : \"en\",\n   \"confidence\" : \"MEDIUM\",\n   \"score\" : 0.571426689624786\n}",
            "title": "POST /language_guesser"
        },
        {
            "location": "/apis/#get-language_guesser",
            "text": "Output JSON  Return codes  200  Sample call  curl -v -H \"Content-Type: application/json\" -X GET \"http://localhost:8888/language_guesser/en\"  Sample output  {\"message\":\"updated index: jenny-en-0 dt_type_ack(true) kb_type_ack(true) kb_type_ack(true)\"}",
            "title": "GET /language_guesser"
        },
        {
            "location": "/apis/#post-index_managementcreate",
            "text": "Output JSON  Return codes  200  Sample call  curl -v -H \"Content-Type: application/json\" -X POST \"http://localhost:8888/index_management\"  Sample output  {\"message\":\"create index: jenny-en-0 create_index_ack(true)\"}",
            "title": "POST /index_management/create"
        },
        {
            "location": "/apis/#post-index_managementrefresh",
            "text": "Output JSON  Return codes  200  Sample call  curl -v -H \"Content-Type: application/json\" -X POST \"http://localhost:8888/index_management/refresh\"  Sample output  {\n   \"failed_shards_n\" : 0,\n   \"total_shards_n\" : 10,\n   \"failed_shards\" : [],\n   \"successful_shards_n\" : 5\n}",
            "title": "POST /index_management/refresh"
        },
        {
            "location": "/apis/#get-index_management",
            "text": "Output JSON  Return codes  200  Sample call  curl -v -H \"Content-Type: application/json\" -X GET \"http://localhost:8888/index_management\"  Sample output  {\"message\":\"settings index: jenny-en-0 dt_type_check(state:true) kb_type_check(question:true) term_type_name(term:true)\"}",
            "title": "GET /index_management"
        },
        {
            "location": "/apis/#put-index_management",
            "text": "Output JSON  Return codes  200  Sample call  curl -v -H \"Content-Type: application/json\" -X PUT \"http://localhost:8888/index_management\"  Sample output  {\"message\":\"updated index: jenny-en-0 dt_type_ack(true) kb_type_ack(true) kb_type_ack(true)\"}",
            "title": "PUT /index_management"
        },
        {
            "location": "/apis/#delete-index_management",
            "text": "Output JSON  Return codes  200  Sample call  curl -v -H \"Content-Type: application/json\" -X DELETE \"http://localhost:8888/index_management\"  Sample output  {\"message\":\"removed index: jenny-en-0 index_ack(true)\"}",
            "title": "DELETE /index_management"
        },
        {
            "location": "/apis/#post-termindex",
            "text": "Index the term as indicated in the JSON.   Return codes  200  Sample call  curl -v -H \"Content-Type: application/json\" -X POST http://localhost:8888/term/index -d '{\n     \"terms\": [\n         {\n            \"term\": \"\u092e\u0930\u093e\u0920\u0940\",\n            \"frequency_base\": 1.0,\n            \"frequency_stem\": 1.0,\n            \"vector\": [1.0, 2.0, 3.0],\n            \"synonyms\":\n            {\n                \"bla1\": 0.1,\n                \"bla2\": 0.2\n            },\n            \"antonyms\":\n            {\n                \"bla3\": 0.1,\n                \"bla4\": 0.2\n            },\n            \"tags\": \"tag1 tag2\",\n            \"features\":\n            {\n                \"NUM\": \"S\",\n                \"GEN\": \"M\"\n            }\n            },\n            {\n            \"term\": \"term2\",\n            \"frequency_base\": 1.0,\n            \"frequency_stem\": 1.0,\n            \"vector\": [1.0, 2.0, 3.0],\n            \"synonyms\":\n            {\n                \"bla1\": 0.1,\n                \"bla2\": 0.2\n            },\n            \"antonyms\":\n            {\n                \"bla3\": 0.1,\n                \"bla4\": 0.2\n            },\n            \"tags\": \"tag1 tag2\",\n            \"features\":\n            {\n                \"NUM\": \"P\",\n                \"GEN\": \"F\"\n            }\n            }\n   ]\n}'  Sample output  {\n   \"data\" : [\n      {\n         \"version\" : 1,\n         \"created\" : true,\n         \"dtype\" : \"term\",\n         \"index\" : \"jenny-en-0\",\n         \"id\" : \"\u092e\u0930\u093e\u0920\u0940\"\n      },\n      {\n         \"dtype\" : \"term\",\n         \"created\" : true,\n         \"version\" : 1,\n         \"id\" : \"term2\",\n         \"index\" : \"jenny-en-0\"\n      }\n   ]\n}",
            "title": "POST /term/index"
        },
        {
            "location": "/apis/#post-termget",
            "text": "Get one or more terms entry.  Return codes  200  Sample call  curl -v -H \"Content-Type: application/json\" -X POST http://localhost:8888/term/get -d '{\n     \"ids\": [\"\u092e\u0930\u093e\u0920\u0940\", \"term2\"]\n}'  Sample output  {\n   \"terms\" : [\n      {\n         \"vector\" : [\n            1,\n            2,\n            3\n         ],\n        \"frequency_base\": 1.0,\n        \"frequency_stem\": 1.0,\n         \"term\" : \"\u092e\u0930\u093e\u0920\u0940\",\n         \"antonyms\" : {\n            \"bla4\" : 0.2,\n            \"bla3\" : 0.1\n         },\n         \"features\" : {\n            \"NUM\" : \"S\",\n            \"GEN\" : \"M\"\n         },\n         \"synonyms\" : {\n            \"bla2\" : 0.2,\n            \"bla1\" : 0.1\n         },\n         \"tags\" : \"tag1 tag2\"\n      },\n      {\n         \"antonyms\" : {\n            \"bla3\" : 0.1,\n            \"bla4\" : 0.2\n         },\n         \"features\" : {\n            \"NUM\" : \"P\",\n            \"GEN\" : \"F\"\n         },\n         \"term\" : \"term2\",\n         \"frequency_base\": 1.0,\n         \"frequency_stem\": 1.0,\n         \"vector\" : [\n            1,\n            2,\n            3\n         ],\n         \"synonyms\" : {\n            \"bla1\" : 0.1,\n            \"bla2\" : 0.2\n         },\n         \"tags\" : \"tag1 tag2\"\n      }\n   ]\n}",
            "title": "POST /term/get"
        },
        {
            "location": "/apis/#delete-term",
            "text": "Delete the term.  Return codes  200  Sample call  curl -v -H \"Content-Type: application/json\" -X DELETE http://localhost:8888/term -d '{\n     \"ids\": [\"\u092e\u0930\u093e\u0920\u0940\", \"term2\"]\n}'  Sample output  {\n   \"data\" : [\n      {\n         \"dtype\" : \"term\",\n         \"version\" : 2,\n         \"id\" : \"\u092e\u0930\u093e\u0920\u0940\",\n         \"index\" : \"jenny-en-0\",\n         \"found\" : true\n      },\n      {\n         \"dtype\" : \"term\",\n         \"id\" : \"term2\",\n         \"version\" : 2,\n         \"found\" : true,\n         \"index\" : \"jenny-en-0\"\n      }\n   ]\n}  Sample call: delete all  curl -v -H \"Content-Type: application/json\" -X DELETE http://localhost:8888/term -d'{\n        \"ids\": []\n}'  Sample call: delete all  {\n  \"message\":\"delete\",\n  \"deleted\":2000\n}",
            "title": "DELETE /term"
        },
        {
            "location": "/apis/#put-term",
            "text": "Update the entry.  Return codes  200  Sample call  curl -v -H \"Content-Type: application/json\" -X PUT http://localhost:8888/term -d '{\n     \"terms\": [\n         {\n            \"term\": \"\u092e\u0930\u093e\u0920\u0940\",\n            \"frequency_base\": 1.0,\n            \"frequency_stem\": 1.0,\n            \"vector\": [1.0, 2.0, 3.0, 4.0],\n            \"synonyms\":\n            {\n                \"bla1\": 0.1,\n                \"bla2\": 0.2\n            },\n            \"antonyms\":\n            {\n                \"term2\": 0.1,\n                \"bla4\": 0.2\n            },\n            \"tags\": \"tag1 tag2\",\n            \"features\":\n            {\n                \"FEATURE_NEW1\": \"V\",\n                \"GEN\": \"M\"\n            }\n            },\n            {\n            \"term\": \"term2\",\n            \"frequency_base\": 1.0,\n            \"frequency_stem\": 1.0,\n            \"vector\": [1.0, 2.0, 3.0, 5.0],\n            \"synonyms\":\n            {\n                \"bla1\": 0.1,\n                \"bla2\": 0.2\n            },\n            \"antonyms\":\n            {\n                \"bla3\": 0.1,\n                \"bla4\": 0.2\n            },\n            \"tags\": \"tag1 tag2\",\n            \"features\":\n            {\n                \"FEATURE_NEW1\": \"N\",\n                \"GEN\": \"F\"\n            }\n            }\n   ]\n}'  Sample output  {\n   \"data\" : [\n      {\n         \"version\" : 2,\n         \"id\" : \"\u092e\u0930\u093e\u0920\u0940\",\n         \"index\" : \"jenny-en-0\",\n         \"created\" : false,\n         \"dtype\" : \"term\"\n      },\n      {\n         \"index\" : \"jenny-en-0\",\n         \"id\" : \"term2\",\n         \"version\" : 2,\n         \"dtype\" : \"term\",\n         \"created\" : false\n      }\n   ]\n}",
            "title": "PUT /term"
        },
        {
            "location": "/apis/#get-termterm",
            "text": "Search for term (using Elasticsearch).  Return codes  200  Sample call  curl -v -H \"Content-Type: application/json\" -X GET http://localhost:8888/term/term -d '{\n    \"term\": \"\u092e\u0930\u093e\u0920\u0940\"\n}'  Sample output  {\n   \"hits\" : {\n      \"terms\" : [\n         {\n            \"vector\" : [\n               1.2,\n               2.3,\n               3.4,\n               4.5\n            ],\n            \"antonyms\" : {\n               \"bla4\" : 0.2,\n               \"term2\" : 0.1\n            },\n            \"frequency_base\": 1.0,\n            \"frequency_stem\": 1.0,\n            \"features\" : {\n               \"FEATURE_NEW1\" : \"V\",\n               \"GEN\" : \"M\"\n            },\n            \"score\" : 0.6931471824646,\n            \"tags\" : \"tag1 tag2\",\n            \"term\" : \"\u092e\u0930\u093e\u0920\u0940\",\n            \"synonyms\" : {\n               \"bla2\" : 0.2,\n               \"bla1\" : 0.1\n            }\n         }\n      ]\n   },\n   \"total\" : 1,\n   \"max_score\" : 0.6931471824646\n}",
            "title": "GET /term/term"
        },
        {
            "location": "/apis/#get-termtext",
            "text": "Search for all the terms in the text and return the entries.  Return codes  200  Sample call  curl -v -H \"Content-Type: application/json\" -X GET http://localhost:8888/term/text -d 'term2 \u092e\u0930\u093e\u0920\u0940'  Sample output  {\n   \"max_score\" : 0.6931471824646,\n   \"hits\" : {\n      \"terms\" : [\n         {\n            \"term\" : \"\u092e\u0930\u093e\u0920\u0940\",\n            \"score\" : 0.6931471824646,\n            \"tags\" : \"tag1 tag2\",\n            \"vector\" : [\n               1.2,\n               2.3,\n               3.4,\n               4.5\n            ],\n            \"features\" : {\n               \"GEN\" : \"M\",\n               \"FEATURE_NEW1\" : \"V\"\n            },\n            \"antonyms\" : {\n               \"bla4\" : 0.2,\n               \"term2\" : 0.1\n            },\n            \"synonyms\" : {\n               \"bla2\" : 0.2,\n               \"bla1\" : 0.1\n            },\n            \"frequency_base\": 1.0,\n            \"frequency_stem\": 1.0\n         },\n         {\n            \"term\" : \"term2\",\n            \"tags\" : \"tag1 tag2\",\n            \"score\" : 0.6931471824646,\n            \"features\" : {\n               \"FEATURE_NEW1\" : \"N\",\n               \"GEN\" : \"F\"\n            },\n            \"vector\" : [\n               1.6,\n               2.7,\n               3.8,\n               5.9\n            ],\n            \"antonyms\" : {\n               \"bla3\" : 0.1,\n               \"bla4\" : 0.2\n            },\n            \"frequency_base\": 1.0,\n            \"frequency_stem\": 1.0,\n            \"synonyms\" : {\n               \"bla1\" : 0.1,\n               \"bla2\" : 0.2\n            }\n         }\n      ]\n   },\n   \"total\" : 2\n}",
            "title": "GET /term/text"
        },
        {
            "location": "/apis/#get-tokenizers",
            "text": "Show a list of supported methods for tokenization and stemming  Return codes  200  Sample call  curl -v -H \"Content-Type: application/json\" -X GET \"http://localhost:8888/tokenizers\"  Sample output  {\n   \"shingles2\" : \"2 words shingles\",\n   \"shingles3\" : \"3 words shingles\",\n   \"shingles2_10\" : \"from 2 to 10 shingles\",\n   \"base_stem\" : \"lowercase + stemming\",\n   \"base\" : \"lowercase\",\n   \"stop\" : \"lowercase + stopwords elimination\",\n   \"shingles4\" : \"4 words shingles\",\n   \"stop_stem\" : \"lowercase + stopwords elimination + stemming\"\n}",
            "title": "GET /tokenizers"
        },
        {
            "location": "/apis/#post-tokenizers",
            "text": "get a list of token using the selected analyzer  Return codes  200  Sample call  curl -v -H \"Content-Type: application/json\" -X POST \"http://localhost:8888/tokenizers\" -d \"\n{\n    \\\"text\\\": \\\"good morning, may I ask you a question?\\\",\n          \\\"tokenizer\\\": \\\"stop\\\"\n          }\"  Sample output  {\n   \"tokens\" : [\n      {\n         \"start_offset\" : 0,\n         \"end_offset\" : 4,\n         \"token_type\" : \"word\",\n         \"token\" : \"good\",\n         \"position\" : 0\n      },\n      {\n         \"token\" : \"morning\",\n         \"position\" : 1,\n         \"token_type\" : \"word\",\n         \"end_offset\" : 12,\n         \"start_offset\" : 5\n      },\n      {\n         \"start_offset\" : 14,\n         \"end_offset\" : 17,\n         \"token_type\" : \"word\",\n         \"token\" : \"may\",\n         \"position\" : 2\n      },\n      {\n         \"token_type\" : \"word\",\n         \"token\" : \"i\",\n         \"position\" : 3,\n         \"start_offset\" : 18,\n         \"end_offset\" : 19\n      },\n      {\n         \"end_offset\" : 23,\n         \"start_offset\" : 20,\n         \"position\" : 4,\n         \"token\" : \"ask\",\n         \"token_type\" : \"word\"\n      },\n      {\n         \"end_offset\" : 27,\n         \"start_offset\" : 24,\n         \"position\" : 5,\n         \"token\" : \"you\",\n         \"token_type\" : \"word\"\n      },\n      {\n         \"end_offset\" : 38,\n         \"start_offset\" : 30,\n         \"token\" : \"question\",\n         \"position\" : 7,\n         \"token_type\" : \"word\"\n      }\n   ]\n}",
            "title": "POST /tokenizers"
        },
        {
            "location": "/apis/#post-analyzers_playground",
            "text": "used to test analyzers on the fly  Return codes  200  Sample call keyword  curl -v -H 'Content-Type: application/json' -X POST http://localhost:8888/analyzers_playground -d '\n{\n        \"analyzer\": \"keyword(\\\"test\\\")\",\n        \"query\": \"this is a test\",\n        \"data\": {\"item_list\": [], \"extracted_variables\":{}}\n}\n'  Sample output keyword  {\n   \"build_message\" : \"success\",\n   \"build\" : true,\n   \"value\" : 0.25\n}  Sample states analyzers  curl -v -H 'Content-Type: application/json' -X POST http://localhost:8888/analyzers_playground -d '\n{\n        \"analyzer\": \"hasTravState(\\\"one\\\")\",\n        \"query\": \"query\",\n        \"data\": {\"item_list\": [\"one\", \"two\"], \"extracted_variables\":{}}\n}\n'  Sample output states analyzers  {\n   \"build_message\" : \"success\",\n   \"build\" : true,\n   \"value\" : 1\n}  Sample of pattern extraction through analyzers  curl -v -H 'Content-Type: application/json' -X POST http://localhost:8888/analyzers_playground -d' \n{\n        \"analyzer\": \"band(keyword(\\\"on\\\"), matchPatternRegex(\\\"[day,month,year](?:(0[1-9]|[12][0-9]|3[01])(?:[- \\\\\\/\\\\.])(0[1-9]|1[012])(?:[- \\\\\\/\\\\.])((?:19|20)\\\\d\\\\d))\\\"))\",\n        \"query\": \"on 31-11-1900\"\n}'  Sample output  {\n   \"build_message\" : \"success\",\n   \"variables\" : {\n      \"month.0\" : \"11\",\n      \"day.0\" : \"31\",\n      \"year.0\" : \"1900\"\n   },\n   \"build\" : true,\n   \"value\" : 1\n}",
            "title": "POST /analyzers_playground"
        },
        {
            "location": "/apis/#post-spellcheckterms",
            "text": "terms spellchecker based on knowledgebase text   Return codes  200  Sample call  QUERY=${1:-\"this is a tes for splellchecker\"}\ncurl -v -H \"Content-Type: application/json\" -X POST http://localhost:8888/spellcheck/terms -d \"{\n  \\\"text\\\": \\\"${QUERY}\\\",\n    \\\"prefix_length\\\": 3,\n      \\\"min_doc_freq\\\": 1\n      }\"  {\n   \"tokens\" : [\n      {\n         \"offset\" : 0,\n         \"options\" : [\n            {\n               \"freq\" : 1284,\n               \"score\" : 0.800000011920929,\n               \"text\" : \"hello\"\n            },\n            {\n               \"text\" : \"hella\",\n               \"score\" : 0.800000011920929,\n               \"freq\" : 2\n            },\n            {\n               \"freq\" : 2,\n               \"score\" : 0.800000011920929,\n               \"text\" : \"helle\"\n            },\n            {\n               \"text\" : \"help\",\n               \"score\" : 0.75,\n               \"freq\" : 35395\n            },\n            {\n               \"score\" : 0.75,\n               \"freq\" : 5,\n               \"text\" : \"hell\"\n            }\n         ],\n         \"length\" : 5,\n         \"text\" : \"hellp\"\n      },\n      {\n         \"length\" : 4,\n         \"options\" : [],\n         \"offset\" : 7,\n         \"text\" : \"this\"\n      },\n      {\n         \"length\" : 2,\n         \"options\" : [],\n         \"offset\" : 12,\n         \"text\" : \"is\"\n      },\n      {\n         \"length\" : 1,\n         \"offset\" : 15,\n         \"options\" : [],\n         \"text\" : \"a\"\n      },\n      {\n         \"length\" : 4,\n         \"offset\" : 17,\n         \"options\" : [\n            {\n               \"text\" : \"test\",\n               \"score\" : 0.75,\n               \"freq\" : 191\n            },\n            {\n               \"freq\" : 10,\n               \"score\" : 0.5,\n               \"text\" : \"tessa\"\n            },\n            {\n               \"text\" : \"tesco\",\n               \"score\" : 0.5,\n               \"freq\" : 9\n            },\n            {\n               \"text\" : \"tesia\",\n               \"score\" : 0.5,\n               \"freq\" : 2\n            },\n            {\n               \"freq\" : 2,\n               \"score\" : 0.5,\n               \"text\" : \"tester\"\n            }\n         ],\n         \"text\" : \"tesr\"\n      }\n   ]\n}",
            "title": "POST /spellcheck/terms"
        },
        {
            "location": "/about/",
            "text": "GetJenny\n\n\nGetJenny\n, the company behind StarChat, is a Finnish startup which provides automated systems for customer services.\n\n\nThrough StarChat, GetJenny provides the backend engine able to manage conversations or to recommend answers based on past conversations and integrate it into its customers' brand-to-consumer communication platform.\n\n\nAlthough all the integration software is closed source, the backend, StarChat, is open source. People can download, modify and use it.\n\n\nTry it at \ngit.io/*chat\n!",
            "title": "About"
        },
        {
            "location": "/about/#getjenny",
            "text": "GetJenny , the company behind StarChat, is a Finnish startup which provides automated systems for customer services.  Through StarChat, GetJenny provides the backend engine able to manage conversations or to recommend answers based on past conversations and integrate it into its customers' brand-to-consumer communication platform.  Although all the integration software is closed source, the backend, StarChat, is open source. People can download, modify and use it.  Try it at  git.io/*chat !",
            "title": "GetJenny"
        }
    ]
}