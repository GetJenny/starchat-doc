{
    "docs": [
        {
            "location": "/", 
            "text": "Welcome!\n\n\nThis is the official repository for StarChat, a scalable conversational engine for B2B applications.\n\n\nHow to contribute\n\n\nTo contribute to StarChat, please send us a \npull request\n  from your fork of this repository.\n\n\nOur concise \ncontribution guideline\n contains the bare\nminumum requirements of the code contributions.\n\n\nBefore contributing (or opening issues), you might want send us an email at starchat@getjenny.com.\n\n\nQuick Start\n\n\nRequirements\n\n\nThe easiest way is to install StarChat using two docker images. You only need:\n\n\n\n\nsbt\n\n\ndocker\n\n\ndocker compose\n\n\n\n\nIn this way, you will put all the indices in the Elasticsearch (version 5.4) image, and StarChat itself in the Java (8) image.\n\n\nIf you do not use docker\n you therefore need on your machine:\n\n\n\n\nScala 12.2\n\n\nElasticsearch 5.4\n\n\n\n\nSetup with Docker (recommended)\n\n\n1. Launch docker-compose\n\n\nGenerate a packet distribution:\n\n\nsbt dist\n\n\n\n\nEnter the directory docker-starchat:\n\n\ncd  docker-starchat\n\n\n\n\nYou will get a message like \nYour package is ready in ...../target/universal/starchat-4ee.... .zip\n.  Extract the packet into the docker-starchat folder:\n\n\nunzip ../target/universal/starchat-4eee.....zip\nln -s starchat-4ee..../  starchat\n\n\n\n\nThe zip packet contains:\n\n\n\n\na set of scripts to test the endpoints and as a complement for the documentation: \nstarchat/scripts/api_test/\n\n\na set of command line programs \nstarchat/bin\n to run starchat and other tools.\n\n\ndelete-decision-table: application to delete items from the decision table\n\n\nindex-corpus-on-knowledge-base: application to index a corpus on knowledge base as hidden (to improve the language model)\n\n\nindex-decision-table: application to index data on the decision table from a csv\n\n\nindex-knowledge-base: application to index data into the knowledge base\n\n\nindex-terms: application to index terms vectors\n\n\nstarchat: start starchat\n\n\n\n\nReview the configuration files \nstarchat/config/application.conf\n and configure the language if needed (by default you have \nindex_language = \"english\"\n)\n\n\n(If you are re-installing StarChat, and want to start from scratch see \nstart from scratch\n.)\n\n\nStart both startchat and elasticsearch:\n\n\ndocker-compose up -d\n\n\n\n\n(Problems like \nelastisearch exited with code 78\n? have a look at \ntroubleshooting\n!)\n\n\n2. Create Elasticsearch indices\n\n\nRun from a terminal:\n\n\n# create the indices in Elasticsearch\ncurl -v -H \nContent-Type: application/json\n -X POST \nhttp://localhost:8888/index_management/create\n\n\n\n\n\n3. Load the configuration file\n\n\nNow you have to load the configuration file for the actual chat, aka \ndecision table\n. We have provided an example csv in English, therefore:\n\n\ncd $STARCHAT_DIR  # or cd .. \nsbt \nrun-main com.getjenny.command.IndexDecisionTable --inputfile doc/decision_table_starchat_doc.csv --skiplines 1\n\n\n\n\n\nand then (you need to index the analyzer):\n\n\n./docker-starchat/starchat/bin/index-decision-table --inputfile doc/decision_table_starchat_doc.csv \n\n\n\n\nThis command deletes all the states it finds on the first column in the inputfile:\n\n\nsbt \nrun-main com.getjenny.command.DeleteDecisionTable --inputfile doc/decision_table_starchat_doc.csv\n\n\n\n\n\nNB This means that if you create a state in the CSV file, index it, then delete it in the CSV and run \nDeleteDecisionTable\n, it won't be deleted!\n\n\n4. Load external corpus (optional)\n\n\nTo have a good words' statistics, and consequent improved matching, you might want to index a corpus which is hidden from results. For instance, you can index various sentences as hidden using the \nPOST /knowledgebase\n endpoint with \ndoctype: \"hidden\"\n.\n\n\n5. Index the FAQs (optional)\n\n\nTODO: You might want to activate the \nknowledge base\n for simple Question and Anwer. \n\n\nInstall without Docker\n\n\nNote: we do not support this installation.\n\n Clone the repository and enter the starchat directory.\n\n Initialize the Elasticsearch instance (see above for Docker)\n* Run the service: \nsbt compile run\n\n\nThe service binds on the port 8888 by default.\n\n\nTest the installation\n\n\nIs the service working?\n\n\ncurl -X GET localhost:8888 | python -mjson.tool\n\n\nGet the \ntest_state\n\n\ncurl  -H \nContent-Type: application/json\n -X POST http://localhost:8888/get_next_response -d '{\n \nconversation_id\n: \n1234\n,\n  \nuser_input\n: { \ntext\n: \nPlease send me the test state\n },\n  \nvalues\n: {\n      \nreturn_value\n: \n,\n      \ndata\n: {}\n       }\n  }'\n\n\n\n\nYou should get:\n\n\n[\n   {\n      \nscore\n : 1,\n      \naction\n : \n,\n      \nmax_state_count\n : 0,\n      \ndata\n : {},\n      \nbubble\n : \nThis is the test state\n,\n      \nfailure_value\n : \n,\n      \ntraversed_states\n : [\n         \ntest_state\n\n      ],\n      \nanalyzer\n : \nbooleanAnd(booleanNot(booleanOr(keyword(\\\ndont\\\n),keyword(\\\ndon't\\\n))), keyword(\\\ntest\\\n), booleanOr(keyword(\\\nsend\\\n), keyword(\\\nget\\\n)))\n,\n      \nstate_data\n : {},\n      \naction_input\n : {},\n      \nsuccess_value\n : \n,\n      \nconversation_id\n : \n1234\n,\n      \nstate\n : \ntest_state\n\n   }\n]\n\n\n\n\nIf you look at the \n\"analyzer\"\n field, you'll see that this state is triggered when\nthe user types the \ntest\n and either \nget\n or \nsend\n. Try with \n\"text\": \"Please dont send me the test state\"\n\n and StarChat will send an empty message.\n\n\nConfiguration of the chatbot (Decision Table)\n\n\nWith StarChat's Decision Table you can easily implement workflow-based chatbots. After the installation (see above)\nyou only have to configure a conversation flow and eventually a front-end client.\n\n\nNLP processing\n\n\nNLP processing is of course the core of any chatbot. As you have noted in the  \nCSV provided in the doc/ directory\n there are two fields defining when StarChat should trigger a state -\nanalyzer\n and \nqueries\n.\n\n\nQueries\n\n\nIf the \nanalyzer\n field is empty, StarChat will query Elasticsearch for the state containing the most similar sentence in the field \nqueries\n. We have carefully configured Elasticsearch in order to provide good answers (e.g. boosting results where the same words appear etc), and results are... acceptable. But you are encouraged to use the \nanalyzer\n field, documented below.\n\n\nAnalyzer\n\n\nThrough the \nanalyzer\ns, you can easily leverage on various NLP algorithms included in StarChat, together with NLP capabilities of Elasticsearch. You can also combine the result of those algorithms. The best way is to look at the simple example included in the  \nCSV provided in the doc/ directory\n for the state \nforgot_passord\n:\n\n\nand(or(keyword(\"reset\"),keyword(\"forgot\")),keyword(\"password\"))\n\n\nThe \nexpression\n \nand\n and \nor\n are called the \noperators\n, while \nkeyword\n is an \natom\n \n\n\nExpressions: Atoms\n\n\nPresently, the \nkeyword(\"reset\")\n in the example provides a very simple score: occurrence of the word \nreset\n in the user's query divided by the total number of words. If evaluated agains the sentence \"Want to reset my password\", \nkeyword(\"reset\")\n will currently return 0.2.  \nNB\n This is just a temporary score used while our NLP library \nmanaus\n is not integrated into StarChat.\n\n\nThese are currently the expression you can use to evaluate the goodness of a query (see \nDefaultFactoryAtomic\n and \nStarchatFactoryAtomic\n:\n\n\n\n\nkeyword(\"word\")\n: as explained above, normalized\n\n\nregex\n: evaluate a regular expression, not normalized\n\n\nsearch(state_name)\n: takes a state name as argument, queries elastic search and returns the score of the most similar query in the field  \nqueries\n of the argument's state. In other words, it does what it would do without any analyzer, only with a normalized score -e.g. \nsearch(\"lost_password_state\")\n \n\n\nsynonym(\"word\")\n: gives a normalized cosine distance between the argument and the closest word in the user's sentence. We use word2vec, to have an idea of two words distance you can use this \nword2vec demo\n by \nTurku University\n\n\nsimilar(\"a whole sentence\")\n:  gives a normalized cosine distance between the argument and the closest word in the user's sentence (word2vec)\n\n\nsimilarState(state_name)\n:  same as above, but for the sentences in the field \"queries\" of the state in the argument.\n\n\n\n\nExpressions: Operators\n\n\nOperators evaluate the output of one or more expression and return a value. Currently, the following operators are implemented (the the \nsource code\n):\n\n\n\n\nboolean or\n:   calles matches of all the exprassions it contains and returns true or false. It can be called using \nbor\n\n\nboolean and\n:  as above, it's called with \nband\n\n\nboolean not\n:  ditto, \nbnot\n\n\nconjunction\n:  if the evaluation of the expressions it contains is normalized, and they can be seen as probabilities of them being true, this is the probability that all the expressions are all true (\nP(A)*P(B)\n)\n\n\ndisjunction\n:  as above, the probability that at least one is true (\n1-(1-P(A))*(1-P(B))\n)\n\n\nmax\n: takes the max score of returned by the expression arguments\n\n\n\n\nTechnical corner: \nexpressions\n\n\nExpressions\n, like \nkeywords\n in the example, are called \natoms\n, and have the following methods/members:\n\n\n\n\ndef evaluate(query: String): Double\n: produce a score. It might be normalized to 1 or not (set \nval isEvaluateNormalized: Boolean\n accordingly)\n\n\nval match_threshold\n This is the threshold above which the expression is considered true when \nmatches\n is called. NB The default value is 0.0, which is normally not ideal.\n\n\ndef matches(query: String): Boolean\n: calles evaluate and check agains the threshold...\n\n\nval rx\n: the name of the atom, as it should be used in the \nanalyzer\n field.\n\n\n\n\nConfiguration of the answer recommender (Knowledge Base)\n\n\nThrough the \n/knowledgebase\n endpoint\nyou can add, edit and remove pairs of question and answers used by StarChat to recommend possible answers when a question arrives.\n\n\nDocuments containing Q\nA must be structured like that:\n\n\n{\n    \nid\n: \n0\n,  // id of the pair\n    \nconversation\n: \nid:1000\n,   // id of the conversation. This can be useful to external services\n    \nindex_in_conversation\n: 1,  // when the pair appears inside the conversation, as above\n    \nquestion\n: \nthank you\n,  // The question to be matched\n    \nanswer\n: \nyou are welcome!\n,  // The answer to be recommended \n    \nquestion_scored_terms\n: [  // A list of keyword and score. You can use your own keyword extractor or our Manaus (see later)\n        [\n            \nthank\n, \n            1.9\n        ]\n    ],\n    \nverified\n: true,  // A variable used in some call centers\n    \ntopics\n: \nt1 t2\n,  // Eventual topics to be associated\n    \ndoctype\n: \nnormal\n,\n    \nstate\n: \n,\n    \nstatus\n: 0\n}\n\n\n\n\nSee \nPOST /knowledgebase\n for an example with \ncurl\n. Other calls (\nGET, DELETE, PUT\n) are used to get the state, delete it or update it. \n\n\nTest the knowledge base\n\n\nJust run the example in \nPOST /knowledgebase_search\n.\n\n\nManaus\n\n\nIn the Q\nA pair above you saw the field\n\nquestion_scored_terms\n. Having good keywords improves enormously the\nquality of the answer. You can of course put them by hand, or run a\nsoftware which extracts the keywords from the question. If you prefer\nthe latter, but don't have any, we provide\n\nManaus\n.\n\n\nManaus is still under development, but it's already included in the\nDocker's installation of StarChat. When you launch \ndocker-compose up\n-d\n, you also launch a container with Manaus which analyzes all the\nQ\nA in the Knowledge Base, produces keywords and updates the field\nquestion_scored_terms for all documents. The process is repeated evert\n4 hour.\n\n\nManaus configuration\n\n\nHave a look at the file \ndocker-starchat/docker-compose.yml\n. For\nManaus to have good performance, you need to provide decent language\nstatistics. Update the file \n/manaus/statistics_data/english/word_frequency.tsv\n with a\nword-frequency file with the following format:\n\n\n1       you     1222421\n2       I       1052546\n3       to      823661\n....\n\n\n\n\nWe have frequency file for more than 50 languages, but consider that\nthe choice of good \"prior distribution\" of word frequency is crucial\nfor any NLP task.\n\n\nTechnology\n\n\nStarChat was design with the following goals in mind:\n\n\n\n\neasy deployment\n\n\nhorizontally scalability without any service interruption.\n\n\nmodularity\n\n\nstatelessness\n\n\n\n\nHow does StarChat work?\n\n\nWorkflow\n\n\n\n\nComponents\n\n\nStarChat uses Elasticsearch as NoSQL database and, as said above, NLP preprocessor, for\nindexing, sentence cleansing, and tokenization.\n\n\nServices\n\n\nStarChat consists of two different services: the \"KnowledBase\" and the \"DecisionTable\"\n\n\nKnowledgeBase\n\n\nFor quick setup based on real Q\nA logs. It stores question and answers pairs. Given a text as input\n it proposes the pair with the closest match on the question field.\n  At the moment the KnowledBase supports only Analyzers implemented on Elasticsearch.\n\n\nDecisionTable\n\n\nThe conversational engine itself. For the usage, see below.\n\n\nConfiguration of the DecisionTable\n\n\nYou configure the DecisionTable through CSV file. Please have a look at the \nCSV provided in the doc/ directory\n.\n\n\nFields in the configuration file are of three types:\n\n\n\n\n(R)\n: Return value: the field is returned by the API\n\n\n(T)\n: Triggers to the state: when should we enter this state? \n\n\n(I)\n: Internal: a field not exposed to the API\n\n\n\n\nAnd the fields are:\n\n\n\n\nstate\n: a unique name of the state (e.g. \nforgot_password\n)\n\n\nexecution_order\n: specify an order of evaluation for analyzers the lower is the number earlier is the evaluation of the state\n\n\nmax_state_count\n: defines how many times StarChat can repropose the state during a conversation.\n\n\nanalyzer (T,I)\n: specify an analyzer expression which triggers the state\n\n\nquery (T,I)\n: list of sentences whose meaning identify the state\n\n\nbubble (R)\n: content, if any, to be shown to the user. It may contain variables like %email% or %link%.\n\n\naction (R)\n: a function to be called on the client side. StarChat developer must provide types of input and output (like an abstract method), and the GUI developer is responsible for the actual implementation (e.g. \nshow_button\n)\n\n\naction_input (R)\n: input passed to \naction\n's function (e.g., for \nshow_buttons\n can be a list of pairs \n(\"text to be shown on button\", state_to_go_when_clicked)\n \n\n\nstate_data (R)\n: a dictionary of strings with arbitrary data to pass along\n\n\nsuccess_value (R)\n: output to return in case of success\n\n\nfailure_value (R)\n: output to return in case of failure\n\n\n\n\nClient functions\n\n\nIn StarChat configuration, the developer can specify which function the front-end should\nexecute when a certain state is triggered, together with input parameters.\n\nAny function implemented on the front-end can be called.\n\n\nExample show button\n\n\n\n\nAction: \nshow_buttons\n\n\nAction input: \n{\"buttons\": [(\"Forgot Password\", \"forgot_password\"), (\"Account locked\", \"account_locked\")]}\n\n\nThe frontend will call function: \nshow_buttons(buttons={\"Forgot Password\": \"forgot_password\",\"Account locked\": \"account_locked\")\n\n\n\n\nExample \"buttons\": the front-end implements the function show_buttons and uses \"action input\" to call it. It will show two buttons, where the first returns forgot_password and the second account_locked.\n\n\nExample send email\n\n\n\n\nAction: \nsend_password_link\n\n\nAction input: \n{ \"template\": \"Reset your password here: example.com\",\"email\": \"%email%\",\"subject\": \"New password\" }\n\n\nThe frontend will call function: \nsend_password_link(template=\"Reset your password here: example.com.\",email= \"john@foo.com\", subject=\"New password\")\n\n\n\n\nExample \"send email\": the front-end implements the function send_password_link and uses \"action input\" to call it.\nThe variable %email% is automatically substituted by the variable email if available in the JSON passed to the\nStarchatResource.\n\n\nfunctions for the sample csv\n\n\nFor the CSV in the example above, the client will have to implement the following set of functions:\n\n\n\n\nshow_buttons: tell the client to render a multiple choice button\n\n\ninput: a key/value pair with the key indicating the text to be shown in the button, and the value indicating the state to follow e.g.: {\"Forgot Password\": \"forgot_password\", \"Account locked\": \"account_locked\", \"Specify your problem\": \"specify_problem\", \"I want to call an operator\": \"call_operator\", \"None of the above\": \"start\"}\n\n\noutput: the choice related to the button clicked by the user e.g.: \"account_locked\"\n\n\ninput_form: render an input form or collect the input following a specific format\n\n\ninput: a dictionary with the list of fields and the type of fields, at least \"email\" must be supported: e.g.: { \"email\": \"email\" } where the key is the name and the value is the type\n\n\noutput: a dictionary with the input values e.g.: { \"email\": \"foo@example.com\" }\n\n\nsend_password_generation_link: send an email with instructions to regenerate the password\n\n\ninput: a valid email address e.g.: \"foo@example.com\"\n\n\noutput: a dictionary with the response fields e.g.: { \"user_id\": \"123\", \"current_state\": \"forgot_password\", \"status\": \"true\" }\n\n\n\n\nRef: \nsample_state_machine_specification.csv\n.\n\n\nMechanics\n\n\n\n\nThe client implements the functions which appear in the action field of the spreadsheet. \nWe will provide interfaces.\n\n\nThe client call the rest API \"decisiontable\" endpoint communicating a state if any, \nthe user input data and other state variables\n\n\nThe client receive a response with guidance on what to return to the user and what \nare the possible next steps\n\n\nThe client render the message to the user and eventually collect the input, then \ncall again the system to get instructions on what to do next\n\n\nWhen the \"decisiontable\" functions does not return any result the user can call the \"knowledgebase\" endpoint which contains all the conversations. \n\n\n\n\nScalability\n\n\nStarChat consists of two different services: StarChat itself and an Elasticsearch cluster. \n\n\nScaling StarChat instances\n\n\nStarChat can scale horizontally by simple replication. Because StarChat is stateless, instances looking \nat the same Elasticsearch index will behave identically. New instances can then be added together\nwith a load balancing service.\n\n\nIn the diagram below, a load balancer forward requests coming from the front-end to StarChat instances \n1, 2 or 3. These instances, as said, behave identically because they all refer to \nIndex 0\n in the \nElasticsearch cluster.\n\n\n\n\nScaling Elasticsearch\n\n\nSimilarly, Elasticsearch can easily scale horizontally adding new nodes to the cluster, as explained\n in \nElasticsearch Documentation\n.\n\n\nSecurity\n\n\nStarChat is a backend service and \nshould never\n be exposed to the internet,\nit should be placed behind a firewall.\nOne of the most effective and flexible method to add an access control layer is to use \n\nKong\n in front of StarChat as a gateway, in this way\nStarChat can be shield by unwanted accesses.\n\n\nIn addition StarChat support TLS connections, the configuration file allow to\nchoose if the service should expose an https connection or an http connection\nor both.\nIn order to use the https connection the user must do the following things:\n\n\n\n\nobtain a pkcs12 server certificate from a certification authority or \ncreate a self signed certificate\n\n\nsave the certificate inside the folder \nconfig/tls/certs/\n e.g. \nconfig/tls/certs/server.p12\n\n\nset the password for the certificate inside the configuration file\n\n\nenable the https connection setting to true the https.enable property of the configuration file\n\n\noptionally disable the http connection setting to false the http.enable property of the configuration file\n\n\n\n\nFollows the block of the configuration file which is to be modified as described above in\n order to use https:\n\n\nhttps {\n  host = \n0.0.0.0\n\n  host = ${?HOST}\n  port = 8443\n  port = ${?PORT}\n  certificate = \nserver.p12\n\n  password = \numa7KnKwvh\n\n  enable = false\n}\n\nhttp {\n  host = \n0.0.0.0\n\n  host = ${?HOST}\n  port = 8888\n  port = ${?PORT}\n  enable = true\n}\n\n\n\n\nStarChat come with a default self-signed certificate for testing,\nusing it for production or sensitive environment is highly discouraged\nas well as useless from a security point of view.\n\n\nIndexing terms on term table\n\n\nThe following program index term vectors on the vector table:\n\n\nsbt \nrun-main com.getjenny.command.IndexTerms --inputfile terms.txt --vecsize 300\n\n\n\n\n\nThe format for each row of an input file with 5 dimension vectors is:\n\nhello 1.0 2.0 3.0 4.0 0.0\n\n\nYou can use your ad-hoc trained vector model (as we do) otherwise you can use the google word2vec models\ntrained on google news. You can find a copy of the \nelasticsearch index with a pre-loaded google news terms\n.\n\n\nTest\n\n\n\n\nUnit tests are available with \nsbt test\n command\n\n\nA set of test script is present inside scripts/api_test\n\n\n\n\nTroubleshooting\n\n\nDocker: start from scratch\n\n\nYou might want to start from scratch, and delete all docker images. \n\n\nIf you do so (\ndocker images\n and then \ndocker rmi -f \njava/elasticsearch ids\n) remember that all data for the \nElasticsearch docker are local, and mounted only when the container is up. Therefore you need to:\n\n\ncd docker-starchat\nrm -rf elasticsearch/data/nodes/\n\n\n\n\ndocker-compose: Analyzers are not loaded\n\n\nStarChat is started immediately after elasticsearch and it is possible that elasticsearch is\n not ready to respond to REST calls from StarChat (i.e. an index not found error could be\n raised in this case).\n\n\nSample error on the logs:\n\n\n2017-06-15 10:37:22,993 \n10:37:22.992UTC ERROR c.g.s.s.AnalyzerService(akka://starchat-service) com.getjenny.starchat.services.AnalyzerService(akka://starchat-service) - can't load analyzers: [jenny-en-0]\n IndexNotFoundException[no such index]\n\n\n\n\nIn order to avoid this problem you can call the services one by one:\n\n\ndocker-compose up elasticsearch # here wait elasticsearch is up and running\ndocker-compose up starchat # starchat will retrieve the Analyzers from elasticsearch\n\n\n\n\nIn alternative is possible to call the command to load/refresh the Analyzers after the docker-compose command: \n\n\ncurl -v -H \nContent-Type: application/json\n -X POST \nhttp://localhost:8888/decisiontable_analyzer\n\n\n\n\n\nDocker: Size of virtual memory\n\n\nIf elasticsearch complain about the size of the virtual memory:\n\n\nmax virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144]\nelastisearch exited with code 78\n\n\n\n\nrun:\n\n\nsysctl -w vm.max_map_count=262144", 
            "title": "Home"
        }, 
        {
            "location": "/#welcome", 
            "text": "This is the official repository for StarChat, a scalable conversational engine for B2B applications.", 
            "title": "Welcome!"
        }, 
        {
            "location": "/#how-to-contribute", 
            "text": "To contribute to StarChat, please send us a  pull request   from your fork of this repository.  Our concise  contribution guideline  contains the bare\nminumum requirements of the code contributions.  Before contributing (or opening issues), you might want send us an email at starchat@getjenny.com.", 
            "title": "How to contribute"
        }, 
        {
            "location": "/#quick-start", 
            "text": "", 
            "title": "Quick Start"
        }, 
        {
            "location": "/#requirements", 
            "text": "The easiest way is to install StarChat using two docker images. You only need:   sbt  docker  docker compose   In this way, you will put all the indices in the Elasticsearch (version 5.4) image, and StarChat itself in the Java (8) image.  If you do not use docker  you therefore need on your machine:   Scala 12.2  Elasticsearch 5.4", 
            "title": "Requirements"
        }, 
        {
            "location": "/#setup-with-docker-recommended", 
            "text": "", 
            "title": "Setup with Docker (recommended)"
        }, 
        {
            "location": "/#1-launch-docker-compose", 
            "text": "Generate a packet distribution:  sbt dist  Enter the directory docker-starchat:  cd  docker-starchat  You will get a message like  Your package is ready in ...../target/universal/starchat-4ee.... .zip .  Extract the packet into the docker-starchat folder:  unzip ../target/universal/starchat-4eee.....zip\nln -s starchat-4ee..../  starchat  The zip packet contains:   a set of scripts to test the endpoints and as a complement for the documentation:  starchat/scripts/api_test/  a set of command line programs  starchat/bin  to run starchat and other tools.  delete-decision-table: application to delete items from the decision table  index-corpus-on-knowledge-base: application to index a corpus on knowledge base as hidden (to improve the language model)  index-decision-table: application to index data on the decision table from a csv  index-knowledge-base: application to index data into the knowledge base  index-terms: application to index terms vectors  starchat: start starchat   Review the configuration files  starchat/config/application.conf  and configure the language if needed (by default you have  index_language = \"english\" )  (If you are re-installing StarChat, and want to start from scratch see  start from scratch .)  Start both startchat and elasticsearch:  docker-compose up -d  (Problems like  elastisearch exited with code 78 ? have a look at  troubleshooting !)", 
            "title": "1. Launch docker-compose"
        }, 
        {
            "location": "/#2-create-elasticsearch-indices", 
            "text": "Run from a terminal:  # create the indices in Elasticsearch\ncurl -v -H  Content-Type: application/json  -X POST  http://localhost:8888/index_management/create", 
            "title": "2. Create Elasticsearch indices"
        }, 
        {
            "location": "/#3-load-the-configuration-file", 
            "text": "Now you have to load the configuration file for the actual chat, aka  decision table . We have provided an example csv in English, therefore:  cd $STARCHAT_DIR  # or cd .. \nsbt  run-main com.getjenny.command.IndexDecisionTable --inputfile doc/decision_table_starchat_doc.csv --skiplines 1   and then (you need to index the analyzer):  ./docker-starchat/starchat/bin/index-decision-table --inputfile doc/decision_table_starchat_doc.csv   This command deletes all the states it finds on the first column in the inputfile:  sbt  run-main com.getjenny.command.DeleteDecisionTable --inputfile doc/decision_table_starchat_doc.csv   NB This means that if you create a state in the CSV file, index it, then delete it in the CSV and run  DeleteDecisionTable , it won't be deleted!", 
            "title": "3. Load the configuration file"
        }, 
        {
            "location": "/#4-load-external-corpus-optional", 
            "text": "To have a good words' statistics, and consequent improved matching, you might want to index a corpus which is hidden from results. For instance, you can index various sentences as hidden using the  POST /knowledgebase  endpoint with  doctype: \"hidden\" .", 
            "title": "4. Load external corpus (optional)"
        }, 
        {
            "location": "/#5-index-the-faqs-optional", 
            "text": "TODO: You might want to activate the  knowledge base  for simple Question and Anwer.", 
            "title": "5. Index the FAQs (optional)"
        }, 
        {
            "location": "/#install-without-docker", 
            "text": "Note: we do not support this installation.  Clone the repository and enter the starchat directory.  Initialize the Elasticsearch instance (see above for Docker)\n* Run the service:  sbt compile run  The service binds on the port 8888 by default.", 
            "title": "Install without Docker"
        }, 
        {
            "location": "/#test-the-installation", 
            "text": "Is the service working?  curl -X GET localhost:8888 | python -mjson.tool  Get the  test_state  curl  -H  Content-Type: application/json  -X POST http://localhost:8888/get_next_response -d '{\n  conversation_id :  1234 ,\n   user_input : {  text :  Please send me the test state  },\n   values : {\n       return_value :  ,\n       data : {}\n       }\n  }'  You should get:  [\n   {\n       score  : 1,\n       action  :  ,\n       max_state_count  : 0,\n       data  : {},\n       bubble  :  This is the test state ,\n       failure_value  :  ,\n       traversed_states  : [\n          test_state \n      ],\n       analyzer  :  booleanAnd(booleanNot(booleanOr(keyword(\\ dont\\ ),keyword(\\ don't\\ ))), keyword(\\ test\\ ), booleanOr(keyword(\\ send\\ ), keyword(\\ get\\ ))) ,\n       state_data  : {},\n       action_input  : {},\n       success_value  :  ,\n       conversation_id  :  1234 ,\n       state  :  test_state \n   }\n]  If you look at the  \"analyzer\"  field, you'll see that this state is triggered when\nthe user types the  test  and either  get  or  send . Try with  \"text\": \"Please dont send me the test state\" \n and StarChat will send an empty message.", 
            "title": "Test the installation"
        }, 
        {
            "location": "/#configuration-of-the-chatbot-decision-table", 
            "text": "With StarChat's Decision Table you can easily implement workflow-based chatbots. After the installation (see above)\nyou only have to configure a conversation flow and eventually a front-end client.", 
            "title": "Configuration of the chatbot (Decision Table)"
        }, 
        {
            "location": "/#nlp-processing", 
            "text": "NLP processing is of course the core of any chatbot. As you have noted in the   CSV provided in the doc/ directory  there are two fields defining when StarChat should trigger a state - analyzer  and  queries .", 
            "title": "NLP processing"
        }, 
        {
            "location": "/#queries", 
            "text": "If the  analyzer  field is empty, StarChat will query Elasticsearch for the state containing the most similar sentence in the field  queries . We have carefully configured Elasticsearch in order to provide good answers (e.g. boosting results where the same words appear etc), and results are... acceptable. But you are encouraged to use the  analyzer  field, documented below.", 
            "title": "Queries"
        }, 
        {
            "location": "/#analyzer", 
            "text": "Through the  analyzer s, you can easily leverage on various NLP algorithms included in StarChat, together with NLP capabilities of Elasticsearch. You can also combine the result of those algorithms. The best way is to look at the simple example included in the   CSV provided in the doc/ directory  for the state  forgot_passord :  and(or(keyword(\"reset\"),keyword(\"forgot\")),keyword(\"password\"))  The  expression   and  and  or  are called the  operators , while  keyword  is an  atom", 
            "title": "Analyzer"
        }, 
        {
            "location": "/#expressions-atoms", 
            "text": "Presently, the  keyword(\"reset\")  in the example provides a very simple score: occurrence of the word  reset  in the user's query divided by the total number of words. If evaluated agains the sentence \"Want to reset my password\",  keyword(\"reset\")  will currently return 0.2.   NB  This is just a temporary score used while our NLP library  manaus  is not integrated into StarChat.  These are currently the expression you can use to evaluate the goodness of a query (see  DefaultFactoryAtomic  and  StarchatFactoryAtomic :   keyword(\"word\") : as explained above, normalized  regex : evaluate a regular expression, not normalized  search(state_name) : takes a state name as argument, queries elastic search and returns the score of the most similar query in the field   queries  of the argument's state. In other words, it does what it would do without any analyzer, only with a normalized score -e.g.  search(\"lost_password_state\")    synonym(\"word\") : gives a normalized cosine distance between the argument and the closest word in the user's sentence. We use word2vec, to have an idea of two words distance you can use this  word2vec demo  by  Turku University  similar(\"a whole sentence\") :  gives a normalized cosine distance between the argument and the closest word in the user's sentence (word2vec)  similarState(state_name) :  same as above, but for the sentences in the field \"queries\" of the state in the argument.", 
            "title": "Expressions: Atoms"
        }, 
        {
            "location": "/#expressions-operators", 
            "text": "Operators evaluate the output of one or more expression and return a value. Currently, the following operators are implemented (the the  source code ):   boolean or :   calles matches of all the exprassions it contains and returns true or false. It can be called using  bor  boolean and :  as above, it's called with  band  boolean not :  ditto,  bnot  conjunction :  if the evaluation of the expressions it contains is normalized, and they can be seen as probabilities of them being true, this is the probability that all the expressions are all true ( P(A)*P(B) )  disjunction :  as above, the probability that at least one is true ( 1-(1-P(A))*(1-P(B)) )  max : takes the max score of returned by the expression arguments", 
            "title": "Expressions: Operators"
        }, 
        {
            "location": "/#technical-corner-expressions", 
            "text": "Expressions , like  keywords  in the example, are called  atoms , and have the following methods/members:   def evaluate(query: String): Double : produce a score. It might be normalized to 1 or not (set  val isEvaluateNormalized: Boolean  accordingly)  val match_threshold  This is the threshold above which the expression is considered true when  matches  is called. NB The default value is 0.0, which is normally not ideal.  def matches(query: String): Boolean : calles evaluate and check agains the threshold...  val rx : the name of the atom, as it should be used in the  analyzer  field.", 
            "title": "Technical corner: expressions"
        }, 
        {
            "location": "/#configuration-of-the-answer-recommender-knowledge-base", 
            "text": "Through the  /knowledgebase  endpoint\nyou can add, edit and remove pairs of question and answers used by StarChat to recommend possible answers when a question arrives.  Documents containing Q A must be structured like that:  {\n     id :  0 ,  // id of the pair\n     conversation :  id:1000 ,   // id of the conversation. This can be useful to external services\n     index_in_conversation : 1,  // when the pair appears inside the conversation, as above\n     question :  thank you ,  // The question to be matched\n     answer :  you are welcome! ,  // The answer to be recommended \n     question_scored_terms : [  // A list of keyword and score. You can use your own keyword extractor or our Manaus (see later)\n        [\n             thank , \n            1.9\n        ]\n    ],\n     verified : true,  // A variable used in some call centers\n     topics :  t1 t2 ,  // Eventual topics to be associated\n     doctype :  normal ,\n     state :  ,\n     status : 0\n}  See  POST /knowledgebase  for an example with  curl . Other calls ( GET, DELETE, PUT ) are used to get the state, delete it or update it.", 
            "title": "Configuration of the answer recommender (Knowledge Base)"
        }, 
        {
            "location": "/#test-the-knowledge-base", 
            "text": "Just run the example in  POST /knowledgebase_search .", 
            "title": "Test the knowledge base"
        }, 
        {
            "location": "/#manaus", 
            "text": "In the Q A pair above you saw the field question_scored_terms . Having good keywords improves enormously the\nquality of the answer. You can of course put them by hand, or run a\nsoftware which extracts the keywords from the question. If you prefer\nthe latter, but don't have any, we provide Manaus .  Manaus is still under development, but it's already included in the\nDocker's installation of StarChat. When you launch  docker-compose up\n-d , you also launch a container with Manaus which analyzes all the\nQ A in the Knowledge Base, produces keywords and updates the field\nquestion_scored_terms for all documents. The process is repeated evert\n4 hour.", 
            "title": "Manaus"
        }, 
        {
            "location": "/#manaus-configuration", 
            "text": "Have a look at the file  docker-starchat/docker-compose.yml . For\nManaus to have good performance, you need to provide decent language\nstatistics. Update the file  /manaus/statistics_data/english/word_frequency.tsv  with a\nword-frequency file with the following format:  1       you     1222421\n2       I       1052546\n3       to      823661\n....  We have frequency file for more than 50 languages, but consider that\nthe choice of good \"prior distribution\" of word frequency is crucial\nfor any NLP task.", 
            "title": "Manaus configuration"
        }, 
        {
            "location": "/#technology", 
            "text": "StarChat was design with the following goals in mind:   easy deployment  horizontally scalability without any service interruption.  modularity  statelessness", 
            "title": "Technology"
        }, 
        {
            "location": "/#how-does-starchat-work", 
            "text": "", 
            "title": "How does StarChat work?"
        }, 
        {
            "location": "/#workflow", 
            "text": "", 
            "title": "Workflow"
        }, 
        {
            "location": "/#components", 
            "text": "StarChat uses Elasticsearch as NoSQL database and, as said above, NLP preprocessor, for\nindexing, sentence cleansing, and tokenization.", 
            "title": "Components"
        }, 
        {
            "location": "/#services", 
            "text": "StarChat consists of two different services: the \"KnowledBase\" and the \"DecisionTable\"", 
            "title": "Services"
        }, 
        {
            "location": "/#knowledgebase", 
            "text": "For quick setup based on real Q A logs. It stores question and answers pairs. Given a text as input\n it proposes the pair with the closest match on the question field.\n  At the moment the KnowledBase supports only Analyzers implemented on Elasticsearch.", 
            "title": "KnowledgeBase"
        }, 
        {
            "location": "/#decisiontable", 
            "text": "The conversational engine itself. For the usage, see below.", 
            "title": "DecisionTable"
        }, 
        {
            "location": "/#configuration-of-the-decisiontable", 
            "text": "You configure the DecisionTable through CSV file. Please have a look at the  CSV provided in the doc/ directory .  Fields in the configuration file are of three types:   (R) : Return value: the field is returned by the API  (T) : Triggers to the state: when should we enter this state?   (I) : Internal: a field not exposed to the API   And the fields are:   state : a unique name of the state (e.g.  forgot_password )  execution_order : specify an order of evaluation for analyzers the lower is the number earlier is the evaluation of the state  max_state_count : defines how many times StarChat can repropose the state during a conversation.  analyzer (T,I) : specify an analyzer expression which triggers the state  query (T,I) : list of sentences whose meaning identify the state  bubble (R) : content, if any, to be shown to the user. It may contain variables like %email% or %link%.  action (R) : a function to be called on the client side. StarChat developer must provide types of input and output (like an abstract method), and the GUI developer is responsible for the actual implementation (e.g.  show_button )  action_input (R) : input passed to  action 's function (e.g., for  show_buttons  can be a list of pairs  (\"text to be shown on button\", state_to_go_when_clicked)    state_data (R) : a dictionary of strings with arbitrary data to pass along  success_value (R) : output to return in case of success  failure_value (R) : output to return in case of failure", 
            "title": "Configuration of the DecisionTable"
        }, 
        {
            "location": "/#client-functions", 
            "text": "In StarChat configuration, the developer can specify which function the front-end should\nexecute when a certain state is triggered, together with input parameters. Any function implemented on the front-end can be called.", 
            "title": "Client functions"
        }, 
        {
            "location": "/#example-show-button", 
            "text": "Action:  show_buttons  Action input:  {\"buttons\": [(\"Forgot Password\", \"forgot_password\"), (\"Account locked\", \"account_locked\")]}  The frontend will call function:  show_buttons(buttons={\"Forgot Password\": \"forgot_password\",\"Account locked\": \"account_locked\")   Example \"buttons\": the front-end implements the function show_buttons and uses \"action input\" to call it. It will show two buttons, where the first returns forgot_password and the second account_locked.", 
            "title": "Example show button"
        }, 
        {
            "location": "/#example-send-email", 
            "text": "Action:  send_password_link  Action input:  { \"template\": \"Reset your password here: example.com\",\"email\": \"%email%\",\"subject\": \"New password\" }  The frontend will call function:  send_password_link(template=\"Reset your password here: example.com.\",email= \"john@foo.com\", subject=\"New password\")   Example \"send email\": the front-end implements the function send_password_link and uses \"action input\" to call it.\nThe variable %email% is automatically substituted by the variable email if available in the JSON passed to the\nStarchatResource.", 
            "title": "Example send email"
        }, 
        {
            "location": "/#functions-for-the-sample-csv", 
            "text": "For the CSV in the example above, the client will have to implement the following set of functions:   show_buttons: tell the client to render a multiple choice button  input: a key/value pair with the key indicating the text to be shown in the button, and the value indicating the state to follow e.g.: {\"Forgot Password\": \"forgot_password\", \"Account locked\": \"account_locked\", \"Specify your problem\": \"specify_problem\", \"I want to call an operator\": \"call_operator\", \"None of the above\": \"start\"}  output: the choice related to the button clicked by the user e.g.: \"account_locked\"  input_form: render an input form or collect the input following a specific format  input: a dictionary with the list of fields and the type of fields, at least \"email\" must be supported: e.g.: { \"email\": \"email\" } where the key is the name and the value is the type  output: a dictionary with the input values e.g.: { \"email\": \"foo@example.com\" }  send_password_generation_link: send an email with instructions to regenerate the password  input: a valid email address e.g.: \"foo@example.com\"  output: a dictionary with the response fields e.g.: { \"user_id\": \"123\", \"current_state\": \"forgot_password\", \"status\": \"true\" }   Ref:  sample_state_machine_specification.csv .", 
            "title": "functions for the sample csv"
        }, 
        {
            "location": "/#mechanics", 
            "text": "The client implements the functions which appear in the action field of the spreadsheet. \nWe will provide interfaces.  The client call the rest API \"decisiontable\" endpoint communicating a state if any, \nthe user input data and other state variables  The client receive a response with guidance on what to return to the user and what \nare the possible next steps  The client render the message to the user and eventually collect the input, then \ncall again the system to get instructions on what to do next  When the \"decisiontable\" functions does not return any result the user can call the \"knowledgebase\" endpoint which contains all the conversations.", 
            "title": "Mechanics"
        }, 
        {
            "location": "/#scalability", 
            "text": "StarChat consists of two different services: StarChat itself and an Elasticsearch cluster.", 
            "title": "Scalability"
        }, 
        {
            "location": "/#scaling-starchat-instances", 
            "text": "StarChat can scale horizontally by simple replication. Because StarChat is stateless, instances looking \nat the same Elasticsearch index will behave identically. New instances can then be added together\nwith a load balancing service.  In the diagram below, a load balancer forward requests coming from the front-end to StarChat instances \n1, 2 or 3. These instances, as said, behave identically because they all refer to  Index 0  in the \nElasticsearch cluster.", 
            "title": "Scaling StarChat instances"
        }, 
        {
            "location": "/#scaling-elasticsearch", 
            "text": "Similarly, Elasticsearch can easily scale horizontally adding new nodes to the cluster, as explained\n in  Elasticsearch Documentation .", 
            "title": "Scaling Elasticsearch"
        }, 
        {
            "location": "/#security", 
            "text": "StarChat is a backend service and  should never  be exposed to the internet,\nit should be placed behind a firewall.\nOne of the most effective and flexible method to add an access control layer is to use  Kong  in front of StarChat as a gateway, in this way\nStarChat can be shield by unwanted accesses.  In addition StarChat support TLS connections, the configuration file allow to\nchoose if the service should expose an https connection or an http connection\nor both.\nIn order to use the https connection the user must do the following things:   obtain a pkcs12 server certificate from a certification authority or  create a self signed certificate  save the certificate inside the folder  config/tls/certs/  e.g.  config/tls/certs/server.p12  set the password for the certificate inside the configuration file  enable the https connection setting to true the https.enable property of the configuration file  optionally disable the http connection setting to false the http.enable property of the configuration file   Follows the block of the configuration file which is to be modified as described above in\n order to use https:  https {\n  host =  0.0.0.0 \n  host = ${?HOST}\n  port = 8443\n  port = ${?PORT}\n  certificate =  server.p12 \n  password =  uma7KnKwvh \n  enable = false\n}\n\nhttp {\n  host =  0.0.0.0 \n  host = ${?HOST}\n  port = 8888\n  port = ${?PORT}\n  enable = true\n}  StarChat come with a default self-signed certificate for testing,\nusing it for production or sensitive environment is highly discouraged\nas well as useless from a security point of view.", 
            "title": "Security"
        }, 
        {
            "location": "/#indexing-terms-on-term-table", 
            "text": "The following program index term vectors on the vector table:  sbt  run-main com.getjenny.command.IndexTerms --inputfile terms.txt --vecsize 300   The format for each row of an input file with 5 dimension vectors is: hello 1.0 2.0 3.0 4.0 0.0  You can use your ad-hoc trained vector model (as we do) otherwise you can use the google word2vec models\ntrained on google news. You can find a copy of the  elasticsearch index with a pre-loaded google news terms .", 
            "title": "Indexing terms on term table"
        }, 
        {
            "location": "/#test", 
            "text": "Unit tests are available with  sbt test  command  A set of test script is present inside scripts/api_test", 
            "title": "Test"
        }, 
        {
            "location": "/#troubleshooting", 
            "text": "", 
            "title": "Troubleshooting"
        }, 
        {
            "location": "/#docker-start-from-scratch", 
            "text": "You might want to start from scratch, and delete all docker images.   If you do so ( docker images  and then  docker rmi -f  java/elasticsearch ids ) remember that all data for the \nElasticsearch docker are local, and mounted only when the container is up. Therefore you need to:  cd docker-starchat\nrm -rf elasticsearch/data/nodes/", 
            "title": "Docker: start from scratch"
        }, 
        {
            "location": "/#docker-compose-analyzers-are-not-loaded", 
            "text": "StarChat is started immediately after elasticsearch and it is possible that elasticsearch is\n not ready to respond to REST calls from StarChat (i.e. an index not found error could be\n raised in this case).  Sample error on the logs:  2017-06-15 10:37:22,993  10:37:22.992UTC ERROR c.g.s.s.AnalyzerService(akka://starchat-service) com.getjenny.starchat.services.AnalyzerService(akka://starchat-service) - can't load analyzers: [jenny-en-0]\n IndexNotFoundException[no such index]  In order to avoid this problem you can call the services one by one:  docker-compose up elasticsearch # here wait elasticsearch is up and running\ndocker-compose up starchat # starchat will retrieve the Analyzers from elasticsearch  In alternative is possible to call the command to load/refresh the Analyzers after the docker-compose command:   curl -v -H  Content-Type: application/json  -X POST  http://localhost:8888/decisiontable_analyzer", 
            "title": "docker-compose: Analyzers are not loaded"
        }, 
        {
            "location": "/#docker-size-of-virtual-memory", 
            "text": "If elasticsearch complain about the size of the virtual memory:  max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144]\nelastisearch exited with code 78  run:  sysctl -w vm.max_map_count=262144", 
            "title": "Docker: Size of virtual memory"
        }, 
        {
            "location": "/apis/", 
            "text": "APIs\n\n\nPOST /get_next_response\n\n\nTell StarChat about the user actions (wrote something, clicked a button etc) and receives instruction \nabout the next state.\n\n\nData to post:\n\n\n{\n  \nconversation_id\n: \n1234\n,\n  \nuser_input\n: { \ntext\n: \nthe text typed by the user\n }, // optional\n  \nvalues\n: {\n    \nreturn_value\n: \nthe value either in success_value or in failure_value (Optional)\n, \n    \ndata\n: {} // all the variables, e.g. for the STRING TEMPLATEs (Optional)\n  },\n  \nthreshold\n: 0.0, // the minimum match threshold\n  \nmax_results\n: 4 // the max number of result to return\n}\n\n\n\n\n\nReturn codes\n\n\n200\n\n\nSimilar Json, see examples below\n\n\nExample 1\n\n\nUser input is \"I forgot my password\":\n\n\ncurl  -H \nContent-Type: application/json\n -X POST http://localhost:8888/get_next_response -d '{   \n    \nconversation_id\n: \n1234\n,\n    \nuser_input\n: { \ntext\n: \nI forgot my password\n },\n    \nvalues\n: {\n        \nreturn_value\n: \n,\n        \ndata\n: {}\n    },\n    \nthreshold\n: 0.0,\n    \nmax_results\n: 4\n}'\n\n\n\n\nreturns:\n\n\n[\n   {\n      \nanalyzer\n : \nand(or(keyword(\\\nreset\\\n),keyword(\\\nforgot\\\n)),keyword(\\\npassword\\\n))\n,\n      \nstate\n : \nforgot_password\n,\n      \nscore\n : 0.25,\n      \naction\n : \ninput_form\n,\n      \naction_input\n : {\n         \nemail\n : \nemail\n\n      },\n      \ntraversed_states\n : [\n         \nforgot_password\n\n      ],\n      \nsuccess_value\n : \nsend_password_generation_link\n,\n      \ndata\n : {},\n      \nbubble\n : \nWe can reset your password by sending you a message to your registered e-mail address. Please type your email address:\n,\n      \nstate_data\n : {\n         \nverification\n : \ndid you mean you forgot the password?\n\n      },\n      \nmax_state_count\n : 0,\n      \nfailure_value\n : \ndont_understand\n,\n      \nconversation_id\n : \n1234\n\n   }\n]\n\n\n\n\nExample 2\n\n\nUser inserts their email after having been in \nforgot_password\n. \nThe client sends:\n\n\ncurl  -H \nContent-Type: application/json\n -X POST http://localhost:8888/get_next_response -d '\n{\n    \nconversation_id\n: \n1234\n,\n    \nuser_input\n: { \ntext\n: \n },\n    \nvalues\n: {\n        \nreturn_value\n: \nsend_password_generation_link\n,\n        \ndata\n: { \nemail\n: \njohn@example.com\n }\n    }\n}'\n\n\n\n\nand gets:\n\n\n[\n   {\n      \ntraversed_states\n : [],\n      \nfailure_value\n : \ncall_operator\n,\n      \nsuccess_value\n : \nany_further\n,\n      \naction\n : \nsend_password_generation_link\n,\n      \nstate\n : \nsend_password_generation_link\n,\n      \nmax_state_count\n : 0,\n      \nstate_data\n : {},\n      \nconversation_id\n : \n1234\n,\n      \ndata\n : {\n         \nemail\n : \njohn@example.com\n\n      },\n      \nscore\n : 1,\n      \nanalyzer\n : \n,\n      \naction_input\n : {\n         \nemail\n : \njohn@example.com\n,\n         \nsubject\n : \nNew password\n,\n         \ntemplate\n : \nHi,\\nSomeone requested a new password for your account. You can set a new password here: %link%\\nIf you did not request this, just ignore this message.\n\n      },\n      \nbubble\n : \nThank you. An e-mail will be sent to this address: john@example.com with your account details and the necessary steps for you to reset your password.\n\n   }\n]\n\n\n\n\n204\n\n\nNo response was found\n\n\n500 (error)\n\n\nInternal server error\n\n\n400 (error)\n\n\nBad request: \n\n\n\n\nmeaning: the input data structure is not valid\n\n\noutput data: no data returned\n\n\n\n\n422 (error)\n\n\n\n\nmeaning: bad request data, the input data is formally valid but there is some issue with data interpretation\n\n\noutput data: the output data structure is a json dictionary with two fields: code and message. The following code are supported:\n\n\ncode: 100\n\n\nmessage: \"error evaluating the template strings, bad values\"\n\n\n\n\n404 (error)\n\n\n\n\nmeaning: not found\n\n\noutput data: no data returned\n\n\n\n\nGET /decisiontable\n\n\nGet a document by ID\n\n\nOutput JSON\n\n\nReturn codes\n\n\n200\n\n\nSample call\n\n\n# retrieve one or more entries with given ids; ids can be specified multiple times\ncurl -v -H \nContent-Type: application/json\n \nhttp://localhost:8888/decisiontable?ids=further_details_access_question\n\n\n\n\n\nSample output\n\n\n{\n   \nhits\n : [\n      {\n         \nscore\n : 0,\n         \ndocument\n : {\n            \nexecution_order\n : 1,\n            \nbubble\n : \nHello and welcome to our customer service chat. Please note that while I am not a human operator, I will do my very best to assist You today. How may I help you?\n,\n            \nstate\n : \nfurther_details_access_question\n,\n            \nmax_state_count\n : 0,\n            \nqueries\n : [\n               \ncannot access account\n,\n               \nproblem access account\n\n            ],\n            \nstate_data\n : {\n               \nverification\n : \ndid you mean you can't access to your account?\n\n            },\n            \naction_input\n : {\n               \nNone of the above\n : \nstart\n,\n               \nAccount locked\n : \naccount_locked\n,\n               \nForgot Password\n : \nforgot_password\n,\n               \nSpecify your problem\n : \nspecify_problem\n,\n               \nI want to call an operator\n : \ncall_operator\n\n            },\n            \nanalyzer\n : \nor(and(or(keyword(\\\nproblem.*\\\n),keyword(\\\nissue.*\\\n),keyword(\\\ntrouble.*\\\n)),keyword(\\\naccount\\\n)),search(\\\nfurther_details_access_question\\\n))\n,\n            \nsuccess_value\n : \neval(show_buttons)\n,\n            \naction\n : \nshow_buttons\n,\n            \nfailure_value\n : \ndont_understand\n\n         }\n      }\n   ],\n   \ntotal\n : 1,\n   \nmax_score\n : 0\n}\n\n\n\n\nPUT /decisiontable\n\n\nOutput JSON\n\n\nReturn codes\n\n\n201\n\n\nSample call\n\n\n# update the \nfurther_details_access_question\n entry in the DT\ncurl -v -H \nContent-Type: application/json\n -X PUT http://localhost:8888/decisiontable/further_details_access_question -d '{\n  \nqueries\n: [\ncannot access account\n, \nproblem access account\n, \nunable to access to my account\n]\n}'\n\n\n\n\nSample output\n\n\n{\n    \ncreated\n: false,\n    \ndtype\n: \nstate\n,\n    \nid\n: \nfurther_details_access_question\n,\n    \nindex\n: \njenny-en-0\n,\n    \nversion\n: 2\n}\n\n\n\n\nPOST /decisiontable\n\n\nInsert a new document.\n\n\nOutput JSON\n\n\nReturn codes\n\n\n201\n\n\nSample call\n\n\ncurl -v -H \nContent-Type: application/json\n -X POST http://localhost:8888/decisiontable -d '{\n  \nstate\n: \nfurther_details_access_question\n,\n  \nexecution_order\n: 1,\n  \nmax_state_count\n: 0,\n  \nanalyzer\n: \n,\n  \nqueries\n: [\ncannot access account\n, \nproblem access account\n],\n  \nbubble\n: \nWhat seems to be the problem exactly?\n,\n  \naction\n: \nshow_buttons\n,\n  \naction_input\n: {\nForgot Password\n: \nforgot_password\n, \nAccount locked\n: \naccount_locked\n, \nPayment problem\n: \npayment_problem\n, \nSpecify your problem\n: \nspecify_problem\n, \nI want to call an operator\n: \ncall_operator\n, \nNone of the above\n: \nstart\n},\n  \nsuccess_value\n: \neval(show_buttons)\n,\n  \nfailure_value\n: \ndont_understand\n\n}'\n\n\n\n\nSample output\n\n\n{\n    \ncreated\n: true,\n    \ndtype\n: \nstate\n,\n    \nid\n: \nfurther_details_access_question\n,\n    \nindex\n: \njenny-en-0\n,\n    \nversion\n: 1\n}\n\n\n\n\nDELETE /decisiontable\n\n\nDelete a document by ID\n\n\nOutput JSON\n\n\nReturn codes\n\n\n200\n\n\nSample call\n\n\ncurl -v -H \nContent-Type: application/json\n -X DELETE http://localhost:8888/decisiontable/further_details_access_question\n\n\n\n\nSample output\n\n\n{\n    \ndtype\n: \nstate\n,\n    \nfound\n: true,\n    \nid\n: \nfurther_details_access_question\n,\n    \nindex\n: \njenny-en-0\n,\n    \nversion\n: 3\n}\n\n\n\n\nPOST /decisiontable_search\n\n\nUpdate a document\n\n\nOutput JSON\n\n\nReturn codes\n\n\n200\n\n\nSample call\n\n\ncurl -v -H \nContent-Type: application/json\n -X POST http://localhost:8888/decisiontable_search -d '{\n  \nqueries\n: \ncannot access my account\n,\n  \nmin_score\n: 0.1,\n  \nboost_exact_match_factor\n: 2.0\n}'\n\n\n\n\nSample response \n\n\n{\n   \nmax_score\n : 0.930855453014374,\n   \nhits\n : [\n      {\n         \ndocument\n : {\n            \naction_input\n : {\n               \nI want to call an operator\n : \ncall_operator\n,\n               \nForgot Password\n : \nforgot_password\n,\n               \nNone of the above\n : \nstart\n,\n               \nAccount locked\n : \naccount_locked\n,\n               \nSpecify your problem\n : \nspecify_problem\n\n            },\n            \nbubble\n : \nHello and welcome to our customer service chat. Please note that while I am not a human operator, I will do my very best to assist You today. How may I help you?\n,\n            \nsuccess_value\n : \neval(show_buttons)\n,\n            \naction\n : \nshow_buttons\n,\n            \nqueries\n : [\n               \ncannot access account\n,\n               \nproblem access account\n\n            ],\n            \nexecution_order\n : 1,\n            \nmax_state_count\n : 0,\n            \nfailure_value\n : \ndont_understand\n,\n            \nstate_data\n : {\n               \nverification\n : \ndid you mean you can't access to your account?\n\n            },\n            \nanalyzer\n : \nor(and(or(keyword(\\\nproblem.*\\\n),keyword(\\\nissue.*\\\n),keyword(\\\ntrouble.*\\\n)),keyword(\\\naccount\\\n)),search(\\\nfurther_details_access_question\\\n))\n,\n            \nstate\n : \nfurther_details_access_question\n\n         },\n         \nscore\n : 0.930855453014374\n      }\n   ],\n   \ntotal\n : 1\n}\n\n\n\n\nGET /decisiontable_analyzer\n\n\n(WORK IN PROGRESS, PARTIALLY IMPLEMENTED)\n\n\nGet and return the map of analyzer for each state\n\n\nOutput JSON\n\n\nReturn codes\n\n\n200\n\n\nSample call\n\n\ncurl -v -H \nContent-Type: application/json\n -X GET \nhttp://localhost:8888/decisiontable_analyzer\n\n\n\n\n\nSample response\n\n\n{\n   \nanalyzer_map\n : {\n      \naccount_locked\n : {\n         \nanalyzer\n : \nbooleanand(keyword(\\\nlocked\\\n), keyword(\\\naccount\\\n), )\n,\n         \nexecution_order\n : 1,\n         \nbuild\n : true\n      },\n      \ncall_operator\n : {\n         \nanalyzer\n : \nand(or(keyword(\\\ncall\\\n),keyword(\\\ntalk\\\n),keyword(\\\nspeak\\\n)),keyword(\\\noperator\\\n))\n,\n         \nexecution_order\n : 1,\n         \nbuild\n : true\n      },\n      \nforgot_password\n : {\n         \nexecution_order\n : 1,\n         \nbuild\n : true,\n         \nanalyzer\n : \nand(or(keyword(\\\nreset\\\n),keyword(\\\nforgot\\\n)),keyword(\\\npassword\\\n))\n\n      },\n      \nterrible_feedback\n : {\n         \nbuild\n : true,\n         \nexecution_order\n : 1,\n         \nanalyzer\n : \nbooleanor(keyword(\\\nidiot\\\n), keyword(\\\nfuck.*\\\n), keyword(\\\nscrew\\\n), keyword(\\\ndamn.*\\\n), keyword(\\\nasshole\\\n))\n\n      },\n      \ntest_state\n : {\n         \nanalyzer\n : \nbooleanAnd(booleanNot(booleanOr(keyword(\\\ndont\\\n),keyword(\\\ndon't\\\n))), keyword(\\\ntest\\\n), booleanOr(keyword(\\\nsend\\\n), keyword(\\\nget\\\n)))\n,\n         \nexecution_order\n : 1,\n         \nbuild\n : true\n      },\n      \nfurther_details_access_question\n : {\n         \nexecution_order\n : 1,\n         \nbuild\n : true,\n         \nanalyzer\n : \nor(and(or(keyword(\\\nproblem.*\\\n),keyword(\\\nissue.*\\\n),keyword(\\\ntrouble.*\\\n)),keyword(\\\naccount\\\n)),search(\\\nfurther_details_access_question\\\n))\n\n      }\n   }\n}\n\n\n\n\nPOST /decisiontable_analyzer\n\n\nLoad/reload the map of analyzer from ES\n\n\nOutput JSON\n\n\nReturn codes\n\n\n200\n\n\nSample call\n\n\ncurl -v -H \nContent-Type: application/json\n -X POST \nhttp://localhost:8888/decisiontable_analyzer\n\n\n\n\n\nSample response\n\n\n{\nnum_of_entries\n:1}\n\n\n\n\nGET /knowledgebase\n\n\nReturn a document by ID\n\n\nOutput JSON\n\n\nReturn codes\n\n\n200\n\n\nSample call\n\n\n# retrieve one or more entries with given ids; ids can be specified multiple times\ncurl -v -H \nContent-Type: application/json\n \nhttp://localhost:8888/knowledgebase?ids=0\n\n\n\n\n\nSample response\n\n\n{\n   \nmax_score\n : 0,\n   \ntotal\n : 1,\n   \nhits\n : [\n      {\n         \nscore\n : 0,\n         \ndocument\n : {\n            \nconversation\n : \nid:1000\n,\n            \nid\n : \n0\n,\n            \nstatus\n : 0,\n            \nquestion_scored_terms\n : [\n               [\n                  \nthank\n,\n          1.09\n               ]\n            ],\n            \nverified\n : true,\n            \nanswer\n : \nyou are welcome!\n,\n            \ntopics\n : \nt1 t2\n,\n            \ndoctype\n : \nnormal\n,\n            \nindex_in_conversation\n : 1,\n            \nquestion\n : \nthank you\n,\n            \nstate\n : \n\n         }\n      }\n   ]\n}\n\n\n\n\nPOST /knowledgebase\n\n\nInsert a new document\n\n\nReturn codes\n\n\n201\n\n\ncurl -v -H \nContent-Type: application/json\n -X POST http://localhost:8888/knowledgebase -d '{\n    \nid\n: \n0\n,\n    \nconversation\n: \nid:1000\n,\n    \nindex_in_conversation\n: 1,\n    \nquestion\n: \nthank you\n,\n    \nanswer\n: \nyou are welcome!\n,\n    \nquestion_scored_terms\n: [\n        [\n            \nthank\n,\n            1.9\n        ]\n    ],\n    \nverified\n: true,\n    \ntopics\n: \nt1 t2\n,\n    \ndoctype\n: \nnormal\n,\n    \nstate\n: \n,\n    \nstatus\n: 0\n}'\n\n\n\n\nSample response\n\n\n{   \ndtype\n: \nquestion\n,\n    \nversion\n: 1,\n    \nid\n: \n1\n,\n    \nindex\n: \njenny-en-0\n,\n    \ncreated\n:true\n}\n\n\n\n\nDELETE /knowledgebase\n\n\nDelete a document by ID\n\n\nOutput JSON\n\n\nReturn codes\n\n\n200\n\n\nSample call\n\n\ncurl -v -H \nContent-Type: application/json\n -X DELETE http://localhost:8888/knowledgebase/0\n\n\n\n\nSample output\n\n\n{\n   \nid\n : \n0\n,\n   \nversion\n : 5,\n   \nindex\n : \njenny-en-0\n,\n   \ndtype\n : \nquestion\n,\n   \nfound\n : true\n}\n\n\n\n\nPUT /knowledgebase\n\n\nUpdate an existing document\n\n\nOutput JSON\n\n\nReturn codes\n\n\n200\n\n\nSample call\n\n\ncurl -v -H \nContent-Type: application/json\n -X PUT http://localhost:8888/knowledgebase/0 -d '{\n    \nquestion_scored_terms\n: [\n                [\n                        \nthank\n,\n                        1.9\n                ],\n                [\n                        \nthanks\n,\n                        1.9\n                ]\n    ]\n}'\n\n\n\n\nSample response\n\n\n{\n   \nindex\n : \njenny-en-0\n,\n   \ndtype\n : \nquestion\n,\n   \nid\n : \n0\n,\n   \nversion\n : 3,\n   \ncreated\n : false\n}\n\n\n\n\nPOST /knowledgebase_search\n\n\nOutput JSON\n\n\nReturn codes\n\n\n200\n\n\nSample call\n\n\ncurl -v -H \nContent-Type: application/json\n -X POST http://localhost:8888/knowledgebase_search -d '{\n  \nquestion\n: \nthank you\n,\n  \nverified\n: true,\n  \ndoctype\n: \nnormal\n\n}'\n\n\n\n\nSample output\n\n\n{\n   \nmax_score\n : 1.15013706684113,\n   \ntotal\n : 2,\n   \nhits\n : [\n      {\n         \ndocument\n : {\n            \nid\n : \n1\n,\n            \ndoctype\n : \nnormal\n,\n            \nquestion_scored_terms\n : [\n               [\n                  \nvalidation\n,\n                  0.0343148699683119\n               ],\n               [\n                  \nimac\n,\n                  1.12982760046835\n               ],\n               [\n                  \naware\n,\n                  3.15048958129597\n               ],\n               [\n                  \nios\n,\n                  6.14545226791214\n               ],\n               [\n                  \nactivation\n,\n                  4.92133804309887\n               ]\n            ],\n            \nanswer\n : \nfine thanks\n,\n            \nconversation\n : \nid:1000\n,\n            \nstate\n : \n,\n            \nquestion\n : \nhow are you?\n,\n            \nstatus\n : 0,\n            \nindex_in_conversation\n : 1,\n            \ntopics\n : \nt1 t2\n,\n            \nverified\n : true\n         },\n         \nscore\n : 1.15013706684113\n      }\n   ]\n}\n\n\n\n\nPOST /language_guesser\n\n\nOutput JSON\n\n\nReturn codes\n\n\n200\n\n\nSample call\n\n\ncurl -v -H \nContent-Type: application/json\n -X POST \nhttp://localhost:8888/language_guesser\n -d \n\n{\n    \\\ninput_text\\\n: \\\ngood morning, may I ask you a question?\\\n\n}\n\n\n\n\n\nSample output\n\n\n{\n   \nenhough_text\n : false,\n   \nlanguage\n : \nen\n,\n   \nconfidence\n : \nMEDIUM\n,\n   \nscore\n : 0.571426689624786\n}\n\n\n\n\nGET /language_guesser\n\n\nOutput JSON\n\n\nReturn codes\n\n\n200\n\n\nSample call\n\n\ncurl -v -H \nContent-Type: application/json\n -X GET \nhttp://localhost:8888/language_guesser/en\n\n\n\n\n\nSample output\n\n\n{\nmessage\n:\nupdated index: jenny-en-0 dt_type_ack(true) kb_type_ack(true) kb_type_ack(true)\n}\n\n\n\n\n\nPOST /index_management/create\n\n\nOutput JSON\n\n\nReturn codes\n\n\n200\n\n\nSample call\n\n\ncurl -v -H \nContent-Type: application/json\n -X POST \nhttp://localhost:8888/index_management\n\n\n\n\n\nSample output\n\n\n{\nmessage\n:\ncreate index: jenny-en-0 create_index_ack(true)\n}\n\n\n\n\nPOST /index_management/refresh\n\n\nOutput JSON\n\n\nReturn codes\n\n\n200\n\n\nSample call\n\n\ncurl -v -H \nContent-Type: application/json\n -X POST \nhttp://localhost:8888/index_management/refresh\n\n\n\n\n\nSample output\n\n\n{\n   \nfailed_shards_n\n : 0,\n   \ntotal_shards_n\n : 10,\n   \nfailed_shards\n : [],\n   \nsuccessful_shards_n\n : 5\n}\n\n\n\n\nGET /index_management\n\n\nOutput JSON\n\n\nReturn codes\n\n\n200\n\n\nSample call\n\n\ncurl -v -H \nContent-Type: application/json\n -X GET \nhttp://localhost:8888/index_management\n\n\n\n\n\nSample output\n\n\n{\nmessage\n:\nsettings index: jenny-en-0 dt_type_check(state:true) kb_type_check(question:true) term_type_name(term:true)\n}\n\n\n\n\nPUT /index_management\n\n\nOutput JSON\n\n\nReturn codes\n\n\n200\n\n\nSample call\n\n\ncurl -v -H \nContent-Type: application/json\n -X PUT \nhttp://localhost:8888/index_management\n\n\n\n\n\nSample output\n\n\n{\nmessage\n:\nupdated index: jenny-en-0 dt_type_ack(true) kb_type_ack(true) kb_type_ack(true)\n}\n\n\n\n\nDELETE /index_management\n\n\nOutput JSON\n\n\nReturn codes\n\n\n200\n\n\nSample call\n\n\ncurl -v -H \nContent-Type: application/json\n -X DELETE \nhttp://localhost:8888/index_management\n\n\n\n\n\nSample output\n\n\n{\nmessage\n:\nremoved index: jenny-en-0 index_ack(true)\n}\n\n\n\n\nPOST /term/index\n\n\nIndex the term as indicated in the JSON. \n\n\nReturn codes\n\n\n200\n\n\nSample call\n\n\ncurl -v -H \nContent-Type: application/json\n -X POST http://localhost:8888/term/index -d '{\n     \nterms\n: [\n         {\n            \nterm\n: \n\u092e\u0930\u093e\u0920\u0940\n,\n            \nfrequency_base\n: 1.0,\n            \nfrequency_stem\n: 1.0,\n            \nvector\n: [1.0, 2.0, 3.0],\n            \nsynonyms\n:\n            {\n                \nbla1\n: 0.1,\n                \nbla2\n: 0.2\n            },\n            \nantonyms\n:\n            {\n                \nbla3\n: 0.1,\n                \nbla4\n: 0.2\n            },\n            \ntags\n: \ntag1 tag2\n,\n            \nfeatures\n:\n            {\n                \nNUM\n: \nS\n,\n                \nGEN\n: \nM\n\n            }\n            },\n            {\n            \nterm\n: \nterm2\n,\n            \nfrequency_base\n: 1.0,\n            \nfrequency_stem\n: 1.0,\n            \nvector\n: [1.0, 2.0, 3.0],\n            \nsynonyms\n:\n            {\n                \nbla1\n: 0.1,\n                \nbla2\n: 0.2\n            },\n            \nantonyms\n:\n            {\n                \nbla3\n: 0.1,\n                \nbla4\n: 0.2\n            },\n            \ntags\n: \ntag1 tag2\n,\n            \nfeatures\n:\n            {\n                \nNUM\n: \nP\n,\n                \nGEN\n: \nF\n\n            }\n            }\n   ]\n}'\n\n\n\n\n\nSample output\n\n\n{\n   \ndata\n : [\n      {\n         \nversion\n : 1,\n         \ncreated\n : true,\n         \ndtype\n : \nterm\n,\n         \nindex\n : \njenny-en-0\n,\n         \nid\n : \n\u092e\u0930\u093e\u0920\u0940\n\n      },\n      {\n         \ndtype\n : \nterm\n,\n         \ncreated\n : true,\n         \nversion\n : 1,\n         \nid\n : \nterm2\n,\n         \nindex\n : \njenny-en-0\n\n      }\n   ]\n}\n\n\n\n\nPOST /term/get\n\n\nGet one or more terms entry.\n\n\nReturn codes\n\n\n200\n\n\nSample call\n\n\ncurl -v -H \nContent-Type: application/json\n -X POST http://localhost:8888/term/get -d '{\n     \nids\n: [\n\u092e\u0930\u093e\u0920\u0940\n, \nterm2\n]\n}'\n\n\n\n\nSample output\n\n\n{\n   \nterms\n : [\n      {\n         \nvector\n : [\n            1,\n            2,\n            3\n         ],\n        \nfrequency_base\n: 1.0,\n        \nfrequency_stem\n: 1.0,\n         \nterm\n : \n\u092e\u0930\u093e\u0920\u0940\n,\n         \nantonyms\n : {\n            \nbla4\n : 0.2,\n            \nbla3\n : 0.1\n         },\n         \nfeatures\n : {\n            \nNUM\n : \nS\n,\n            \nGEN\n : \nM\n\n         },\n         \nsynonyms\n : {\n            \nbla2\n : 0.2,\n            \nbla1\n : 0.1\n         },\n         \ntags\n : \ntag1 tag2\n\n      },\n      {\n         \nantonyms\n : {\n            \nbla3\n : 0.1,\n            \nbla4\n : 0.2\n         },\n         \nfeatures\n : {\n            \nNUM\n : \nP\n,\n            \nGEN\n : \nF\n\n         },\n         \nterm\n : \nterm2\n,\n         \nfrequency_base\n: 1.0,\n         \nfrequency_stem\n: 1.0,\n         \nvector\n : [\n            1,\n            2,\n            3\n         ],\n         \nsynonyms\n : {\n            \nbla1\n : 0.1,\n            \nbla2\n : 0.2\n         },\n         \ntags\n : \ntag1 tag2\n\n      }\n   ]\n}\n\n\n\n\n\nDELETE /term\n\n\nDelete the term.\n\n\nReturn codes\n\n\n200\n\n\nSample call\n\n\ncurl -v -H \nContent-Type: application/json\n -X DELETE http://localhost:8888/term -d '{\n     \nids\n: [\n\u092e\u0930\u093e\u0920\u0940\n, \nterm2\n]\n}'\n\n\n\n\nSample output\n\n\n{\n   \ndata\n : [\n      {\n         \ndtype\n : \nterm\n,\n         \nversion\n : 2,\n         \nid\n : \n\u092e\u0930\u093e\u0920\u0940\n,\n         \nindex\n : \njenny-en-0\n,\n         \nfound\n : true\n      },\n      {\n         \ndtype\n : \nterm\n,\n         \nid\n : \nterm2\n,\n         \nversion\n : 2,\n         \nfound\n : true,\n         \nindex\n : \njenny-en-0\n\n      }\n   ]\n}\n\n\n\n\n\nPUT /term\n\n\nUpdate the entry.\n\n\nReturn codes\n\n\n200\n\n\nSample call\n\n\ncurl -v -H \nContent-Type: application/json\n -X PUT http://localhost:8888/term -d '{\n     \nterms\n: [\n         {\n            \nterm\n: \n\u092e\u0930\u093e\u0920\u0940\n,\n            \nfrequency_base\n: 1.0,\n            \nfrequency_stem\n: 1.0,\n            \nvector\n: [1.0, 2.0, 3.0, 4.0],\n            \nsynonyms\n:\n            {\n                \nbla1\n: 0.1,\n                \nbla2\n: 0.2\n            },\n            \nantonyms\n:\n            {\n                \nterm2\n: 0.1,\n                \nbla4\n: 0.2\n            },\n            \ntags\n: \ntag1 tag2\n,\n            \nfeatures\n:\n            {\n                \nFEATURE_NEW1\n: \nV\n,\n                \nGEN\n: \nM\n\n            }\n            },\n            {\n            \nterm\n: \nterm2\n,\n            \nfrequency_base\n: 1.0,\n            \nfrequency_stem\n: 1.0,\n            \nvector\n: [1.0, 2.0, 3.0, 5.0],\n            \nsynonyms\n:\n            {\n                \nbla1\n: 0.1,\n                \nbla2\n: 0.2\n            },\n            \nantonyms\n:\n            {\n                \nbla3\n: 0.1,\n                \nbla4\n: 0.2\n            },\n            \ntags\n: \ntag1 tag2\n,\n            \nfeatures\n:\n            {\n                \nFEATURE_NEW1\n: \nN\n,\n                \nGEN\n: \nF\n\n            }\n            }\n   ]\n}'\n\n\n\n\nSample output\n\n\n{\n   \ndata\n : [\n      {\n         \nversion\n : 2,\n         \nid\n : \n\u092e\u0930\u093e\u0920\u0940\n,\n         \nindex\n : \njenny-en-0\n,\n         \ncreated\n : false,\n         \ndtype\n : \nterm\n\n      },\n      {\n         \nindex\n : \njenny-en-0\n,\n         \nid\n : \nterm2\n,\n         \nversion\n : 2,\n         \ndtype\n : \nterm\n,\n         \ncreated\n : false\n      }\n   ]\n}\n\n\n\n\n\nGET /term/term\n\n\nSearch for term (using Elasticsearch).\n\n\nReturn codes\n\n\n200\n\n\nSample call\n\n\ncurl -v -H \nContent-Type: application/json\n -X GET http://localhost:8888/term/term -d '{\n    \nterm\n: \n\u092e\u0930\u093e\u0920\u0940\n\n}'\n\n\n\n\nSample output\n\n\n{\n   \nhits\n : {\n      \nterms\n : [\n         {\n            \nvector\n : [\n               1.2,\n               2.3,\n               3.4,\n               4.5\n            ],\n            \nantonyms\n : {\n               \nbla4\n : 0.2,\n               \nterm2\n : 0.1\n            },\n            \nfrequency_base\n: 1.0,\n            \nfrequency_stem\n: 1.0,\n            \nfeatures\n : {\n               \nFEATURE_NEW1\n : \nV\n,\n               \nGEN\n : \nM\n\n            },\n            \nscore\n : 0.6931471824646,\n            \ntags\n : \ntag1 tag2\n,\n            \nterm\n : \n\u092e\u0930\u093e\u0920\u0940\n,\n            \nsynonyms\n : {\n               \nbla2\n : 0.2,\n               \nbla1\n : 0.1\n            }\n         }\n      ]\n   },\n   \ntotal\n : 1,\n   \nmax_score\n : 0.6931471824646\n}\n\n\n\n\nGET /term/text\n\n\nSearch for all the terms in the text and return the entries.\n\n\nReturn codes\n\n\n200\n\n\nSample call\n\n\ncurl -v -H \nContent-Type: application/json\n -X GET http://localhost:8888/term/text -d 'term2 \u092e\u0930\u093e\u0920\u0940'\n\n\n\n\nSample output\n\n\n{\n   \nmax_score\n : 0.6931471824646,\n   \nhits\n : {\n      \nterms\n : [\n         {\n            \nterm\n : \n\u092e\u0930\u093e\u0920\u0940\n,\n            \nscore\n : 0.6931471824646,\n            \ntags\n : \ntag1 tag2\n,\n            \nvector\n : [\n               1.2,\n               2.3,\n               3.4,\n               4.5\n            ],\n            \nfeatures\n : {\n               \nGEN\n : \nM\n,\n               \nFEATURE_NEW1\n : \nV\n\n            },\n            \nantonyms\n : {\n               \nbla4\n : 0.2,\n               \nterm2\n : 0.1\n            },\n            \nsynonyms\n : {\n               \nbla2\n : 0.2,\n               \nbla1\n : 0.1\n            },\n            \nfrequency_base\n: 1.0,\n            \nfrequency_stem\n: 1.0\n         },\n         {\n            \nterm\n : \nterm2\n,\n            \ntags\n : \ntag1 tag2\n,\n            \nscore\n : 0.6931471824646,\n            \nfeatures\n : {\n               \nFEATURE_NEW1\n : \nN\n,\n               \nGEN\n : \nF\n\n            },\n            \nvector\n : [\n               1.6,\n               2.7,\n               3.8,\n               5.9\n            ],\n            \nantonyms\n : {\n               \nbla3\n : 0.1,\n               \nbla4\n : 0.2\n            },\n            \nfrequency_base\n: 1.0,\n            \nfrequency_stem\n: 1.0,\n            \nsynonyms\n : {\n               \nbla1\n : 0.1,\n               \nbla2\n : 0.2\n            }\n         }\n      ]\n   },\n   \ntotal\n : 2\n}\n\n\n\n\nGET /tokenizers\n\n\nShow a list of supported methods for tokenization and stemming\n\n\nReturn codes\n\n\n200\n\n\nSample call\n\n\ncurl -v -H \nContent-Type: application/json\n -X GET \nhttp://localhost:8888/tokenizers\n\n\n\n\n\nSample output\n\n\n{\n   \nshingles2\n : \n2 words shingles\n,\n   \nshingles3\n : \n3 words shingles\n,\n   \nshingles2_10\n : \nfrom 2 to 10 shingles\n,\n   \nbase_stem\n : \nlowercase + stemming\n,\n   \nbase\n : \nlowercase\n,\n   \nstop\n : \nlowercase + stopwords elimination\n,\n   \nshingles4\n : \n4 words shingles\n,\n   \nstop_stem\n : \nlowercase + stopwords elimination + stemming\n\n}\n\n\n\n\nPOST /tokenizers\n\n\nget a list of token using the selected analyzer\n\n\nReturn codes\n\n\n200\n\n\nSample call\n\n\ncurl -v -H \nContent-Type: application/json\n -X POST \nhttp://localhost:8888/tokenizers\n -d \n\n{\n    \\\ntext\\\n: \\\ngood morning, may I ask you a question?\\\n,\n          \\\ntokenizer\\\n: \\\nstop\\\n\n          }\n\n\n\n\n\nSample output\n\n\n{\n   \ntokens\n : [\n      {\n         \nstart_offset\n : 0,\n         \nend_offset\n : 4,\n         \ntoken_type\n : \nword\n,\n         \ntoken\n : \ngood\n,\n         \nposition\n : 0\n      },\n      {\n         \ntoken\n : \nmorning\n,\n         \nposition\n : 1,\n         \ntoken_type\n : \nword\n,\n         \nend_offset\n : 12,\n         \nstart_offset\n : 5\n      },\n      {\n         \nstart_offset\n : 14,\n         \nend_offset\n : 17,\n         \ntoken_type\n : \nword\n,\n         \ntoken\n : \nmay\n,\n         \nposition\n : 2\n      },\n      {\n         \ntoken_type\n : \nword\n,\n         \ntoken\n : \ni\n,\n         \nposition\n : 3,\n         \nstart_offset\n : 18,\n         \nend_offset\n : 19\n      },\n      {\n         \nend_offset\n : 23,\n         \nstart_offset\n : 20,\n         \nposition\n : 4,\n         \ntoken\n : \nask\n,\n         \ntoken_type\n : \nword\n\n      },\n      {\n         \nend_offset\n : 27,\n         \nstart_offset\n : 24,\n         \nposition\n : 5,\n         \ntoken\n : \nyou\n,\n         \ntoken_type\n : \nword\n\n      },\n      {\n         \nend_offset\n : 38,\n         \nstart_offset\n : 30,\n         \ntoken\n : \nquestion\n,\n         \nposition\n : 7,\n         \ntoken_type\n : \nword\n\n      }\n   ]\n}\n\n\n\n\nPOST /analyzers_playground\n\n\nused to test analyzers on the fly\n\n\nReturn codes\n\n\n200\n\n\nSample call\n\n\nANALYZER=\nkeyword(\\\\\\\ntest\\\\\\\n)\n\nQUERY=\nthis is a test\n\ncurl -v -H \nContent-Type: application/json\n -X POST \nhttp://localhost:8888/analyzers_playground\n -d \n\n{\n        \\\nanalyzer\\\n: \\\n${ANALYZER}\\\n,\n            \\\nquery\\\n: \\\n${QUERY}\\\n\n        }\n\n\n\n\n\nSample output\n\n\n{\n   \nvalue\n : 0.25,\n   \nbuild_message\n : \nsuccess\n,\n   \nbuild\n : true\n}\n\n\n\n\nSample of pattern extraction through analyzers\n\n\ncurl -v -H 'Content-Type: application/json' -X POST http://localhost:8888/analyzers_playground -d' \n{\n        \nanalyzer\n: \nband(keyword(\\\non\\\n), matchPatternRegex(\\\n[day,month,year](?:(0[1-9]|[12][0-9]|3[01])(?:[- \\\\\\/\\\\.])(0[1-9]|1[012])(?:[- \\\\\\/\\\\.])((?:19|20)\\\\d\\\\d))\\\n))\n,\n        \nquery\n: \non 31-11-1900\n\n}'```\n\nSample output\n\n```json\n{\n   \nbuild_message\n : \nsuccess\n,\n   \nvariables\n : {\n      \nmonth.0\n : \n11\n,\n      \nday.0\n : \n31\n,\n      \nyear.0\n : \n1900\n\n   },\n   \nbuild\n : true,\n   \nvalue\n : 1\n}\n\n\n\n\nPOST /spellcheck/terms\n\n\nterms spellchecker based on knowledgebase text \n\n\nReturn codes\n\n\n200\n\n\nSample call\n\n\nQUERY=${1:-\nthis is a tes for splellchecker\n}\ncurl -v -H \nContent-Type: application/json\n -X POST http://localhost:8888/spellcheck/terms -d \n{\n  \\\ntext\\\n: \\\n${QUERY}\\\n,\n    \\\nprefix_length\\\n: 3,\n      \\\nmin_doc_freq\\\n: 1\n      }\n\n\n\n\n\n{\n   \ntokens\n : [\n      {\n         \noffset\n : 0,\n         \noptions\n : [\n            {\n               \nfreq\n : 1284,\n               \nscore\n : 0.800000011920929,\n               \ntext\n : \nhello\n\n            },\n            {\n               \ntext\n : \nhella\n,\n               \nscore\n : 0.800000011920929,\n               \nfreq\n : 2\n            },\n            {\n               \nfreq\n : 2,\n               \nscore\n : 0.800000011920929,\n               \ntext\n : \nhelle\n\n            },\n            {\n               \ntext\n : \nhelp\n,\n               \nscore\n : 0.75,\n               \nfreq\n : 35395\n            },\n            {\n               \nscore\n : 0.75,\n               \nfreq\n : 5,\n               \ntext\n : \nhell\n\n            }\n         ],\n         \nlength\n : 5,\n         \ntext\n : \nhellp\n\n      },\n      {\n         \nlength\n : 4,\n         \noptions\n : [],\n         \noffset\n : 7,\n         \ntext\n : \nthis\n\n      },\n      {\n         \nlength\n : 2,\n         \noptions\n : [],\n         \noffset\n : 12,\n         \ntext\n : \nis\n\n      },\n      {\n         \nlength\n : 1,\n         \noffset\n : 15,\n         \noptions\n : [],\n         \ntext\n : \na\n\n      },\n      {\n         \nlength\n : 4,\n         \noffset\n : 17,\n         \noptions\n : [\n            {\n               \ntext\n : \ntest\n,\n               \nscore\n : 0.75,\n               \nfreq\n : 191\n            },\n            {\n               \nfreq\n : 10,\n               \nscore\n : 0.5,\n               \ntext\n : \ntessa\n\n            },\n            {\n               \ntext\n : \ntesco\n,\n               \nscore\n : 0.5,\n               \nfreq\n : 9\n            },\n            {\n               \ntext\n : \ntesia\n,\n               \nscore\n : 0.5,\n               \nfreq\n : 2\n            },\n            {\n               \nfreq\n : 2,\n               \nscore\n : 0.5,\n               \ntext\n : \ntester\n\n            }\n         ],\n         \ntext\n : \ntesr\n\n      }\n   ]\n}", 
            "title": "APIs"
        }, 
        {
            "location": "/apis/#apis", 
            "text": "", 
            "title": "APIs"
        }, 
        {
            "location": "/apis/#post-get_next_response", 
            "text": "Tell StarChat about the user actions (wrote something, clicked a button etc) and receives instruction \nabout the next state.  Data to post:  {\n   conversation_id :  1234 ,\n   user_input : {  text :  the text typed by the user  }, // optional\n   values : {\n     return_value :  the value either in success_value or in failure_value (Optional) , \n     data : {} // all the variables, e.g. for the STRING TEMPLATEs (Optional)\n  },\n   threshold : 0.0, // the minimum match threshold\n   max_results : 4 // the max number of result to return\n}", 
            "title": "POST /get_next_response"
        }, 
        {
            "location": "/apis/#return-codes", 
            "text": "", 
            "title": "Return codes"
        }, 
        {
            "location": "/apis/#200", 
            "text": "Similar Json, see examples below", 
            "title": "200"
        }, 
        {
            "location": "/apis/#example-1", 
            "text": "User input is \"I forgot my password\":  curl  -H  Content-Type: application/json  -X POST http://localhost:8888/get_next_response -d '{   \n     conversation_id :  1234 ,\n     user_input : {  text :  I forgot my password  },\n     values : {\n         return_value :  ,\n         data : {}\n    },\n     threshold : 0.0,\n     max_results : 4\n}'  returns:  [\n   {\n       analyzer  :  and(or(keyword(\\ reset\\ ),keyword(\\ forgot\\ )),keyword(\\ password\\ )) ,\n       state  :  forgot_password ,\n       score  : 0.25,\n       action  :  input_form ,\n       action_input  : {\n          email  :  email \n      },\n       traversed_states  : [\n          forgot_password \n      ],\n       success_value  :  send_password_generation_link ,\n       data  : {},\n       bubble  :  We can reset your password by sending you a message to your registered e-mail address. Please type your email address: ,\n       state_data  : {\n          verification  :  did you mean you forgot the password? \n      },\n       max_state_count  : 0,\n       failure_value  :  dont_understand ,\n       conversation_id  :  1234 \n   }\n]", 
            "title": "Example 1"
        }, 
        {
            "location": "/apis/#example-2", 
            "text": "User inserts their email after having been in  forgot_password . \nThe client sends:  curl  -H  Content-Type: application/json  -X POST http://localhost:8888/get_next_response -d '\n{\n     conversation_id :  1234 ,\n     user_input : {  text :   },\n     values : {\n         return_value :  send_password_generation_link ,\n         data : {  email :  john@example.com  }\n    }\n}'  and gets:  [\n   {\n       traversed_states  : [],\n       failure_value  :  call_operator ,\n       success_value  :  any_further ,\n       action  :  send_password_generation_link ,\n       state  :  send_password_generation_link ,\n       max_state_count  : 0,\n       state_data  : {},\n       conversation_id  :  1234 ,\n       data  : {\n          email  :  john@example.com \n      },\n       score  : 1,\n       analyzer  :  ,\n       action_input  : {\n          email  :  john@example.com ,\n          subject  :  New password ,\n          template  :  Hi,\\nSomeone requested a new password for your account. You can set a new password here: %link%\\nIf you did not request this, just ignore this message. \n      },\n       bubble  :  Thank you. An e-mail will be sent to this address: john@example.com with your account details and the necessary steps for you to reset your password. \n   }\n]", 
            "title": "Example 2"
        }, 
        {
            "location": "/apis/#204", 
            "text": "No response was found", 
            "title": "204"
        }, 
        {
            "location": "/apis/#500-error", 
            "text": "Internal server error", 
            "title": "500 (error)"
        }, 
        {
            "location": "/apis/#400-error", 
            "text": "Bad request:    meaning: the input data structure is not valid  output data: no data returned", 
            "title": "400 (error)"
        }, 
        {
            "location": "/apis/#422-error", 
            "text": "meaning: bad request data, the input data is formally valid but there is some issue with data interpretation  output data: the output data structure is a json dictionary with two fields: code and message. The following code are supported:  code: 100  message: \"error evaluating the template strings, bad values\"", 
            "title": "422 (error)"
        }, 
        {
            "location": "/apis/#404-error", 
            "text": "meaning: not found  output data: no data returned", 
            "title": "404 (error)"
        }, 
        {
            "location": "/apis/#get-decisiontable", 
            "text": "Get a document by ID  Output JSON", 
            "title": "GET /decisiontable"
        }, 
        {
            "location": "/apis/#return-codes_1", 
            "text": "", 
            "title": "Return codes"
        }, 
        {
            "location": "/apis/#200_1", 
            "text": "Sample call  # retrieve one or more entries with given ids; ids can be specified multiple times\ncurl -v -H  Content-Type: application/json   http://localhost:8888/decisiontable?ids=further_details_access_question   Sample output  {\n    hits  : [\n      {\n          score  : 0,\n          document  : {\n             execution_order  : 1,\n             bubble  :  Hello and welcome to our customer service chat. Please note that while I am not a human operator, I will do my very best to assist You today. How may I help you? ,\n             state  :  further_details_access_question ,\n             max_state_count  : 0,\n             queries  : [\n                cannot access account ,\n                problem access account \n            ],\n             state_data  : {\n                verification  :  did you mean you can't access to your account? \n            },\n             action_input  : {\n                None of the above  :  start ,\n                Account locked  :  account_locked ,\n                Forgot Password  :  forgot_password ,\n                Specify your problem  :  specify_problem ,\n                I want to call an operator  :  call_operator \n            },\n             analyzer  :  or(and(or(keyword(\\ problem.*\\ ),keyword(\\ issue.*\\ ),keyword(\\ trouble.*\\ )),keyword(\\ account\\ )),search(\\ further_details_access_question\\ )) ,\n             success_value  :  eval(show_buttons) ,\n             action  :  show_buttons ,\n             failure_value  :  dont_understand \n         }\n      }\n   ],\n    total  : 1,\n    max_score  : 0\n}", 
            "title": "200"
        }, 
        {
            "location": "/apis/#put-decisiontable", 
            "text": "Output JSON", 
            "title": "PUT /decisiontable"
        }, 
        {
            "location": "/apis/#return-codes_2", 
            "text": "", 
            "title": "Return codes"
        }, 
        {
            "location": "/apis/#201", 
            "text": "Sample call  # update the  further_details_access_question  entry in the DT\ncurl -v -H  Content-Type: application/json  -X PUT http://localhost:8888/decisiontable/further_details_access_question -d '{\n   queries : [ cannot access account ,  problem access account ,  unable to access to my account ]\n}'  Sample output  {\n     created : false,\n     dtype :  state ,\n     id :  further_details_access_question ,\n     index :  jenny-en-0 ,\n     version : 2\n}", 
            "title": "201"
        }, 
        {
            "location": "/apis/#post-decisiontable", 
            "text": "Insert a new document.  Output JSON", 
            "title": "POST /decisiontable"
        }, 
        {
            "location": "/apis/#return-codes_3", 
            "text": "", 
            "title": "Return codes"
        }, 
        {
            "location": "/apis/#201_1", 
            "text": "Sample call  curl -v -H  Content-Type: application/json  -X POST http://localhost:8888/decisiontable -d '{\n   state :  further_details_access_question ,\n   execution_order : 1,\n   max_state_count : 0,\n   analyzer :  ,\n   queries : [ cannot access account ,  problem access account ],\n   bubble :  What seems to be the problem exactly? ,\n   action :  show_buttons ,\n   action_input : { Forgot Password :  forgot_password ,  Account locked :  account_locked ,  Payment problem :  payment_problem ,  Specify your problem :  specify_problem ,  I want to call an operator :  call_operator ,  None of the above :  start },\n   success_value :  eval(show_buttons) ,\n   failure_value :  dont_understand \n}'  Sample output  {\n     created : true,\n     dtype :  state ,\n     id :  further_details_access_question ,\n     index :  jenny-en-0 ,\n     version : 1\n}", 
            "title": "201"
        }, 
        {
            "location": "/apis/#delete-decisiontable", 
            "text": "Delete a document by ID  Output JSON", 
            "title": "DELETE /decisiontable"
        }, 
        {
            "location": "/apis/#return-codes_4", 
            "text": "", 
            "title": "Return codes"
        }, 
        {
            "location": "/apis/#200_2", 
            "text": "Sample call  curl -v -H  Content-Type: application/json  -X DELETE http://localhost:8888/decisiontable/further_details_access_question  Sample output  {\n     dtype :  state ,\n     found : true,\n     id :  further_details_access_question ,\n     index :  jenny-en-0 ,\n     version : 3\n}", 
            "title": "200"
        }, 
        {
            "location": "/apis/#post-decisiontable_search", 
            "text": "Update a document  Output JSON", 
            "title": "POST /decisiontable_search"
        }, 
        {
            "location": "/apis/#return-codes_5", 
            "text": "", 
            "title": "Return codes"
        }, 
        {
            "location": "/apis/#200_3", 
            "text": "Sample call  curl -v -H  Content-Type: application/json  -X POST http://localhost:8888/decisiontable_search -d '{\n   queries :  cannot access my account ,\n   min_score : 0.1,\n   boost_exact_match_factor : 2.0\n}'  Sample response   {\n    max_score  : 0.930855453014374,\n    hits  : [\n      {\n          document  : {\n             action_input  : {\n                I want to call an operator  :  call_operator ,\n                Forgot Password  :  forgot_password ,\n                None of the above  :  start ,\n                Account locked  :  account_locked ,\n                Specify your problem  :  specify_problem \n            },\n             bubble  :  Hello and welcome to our customer service chat. Please note that while I am not a human operator, I will do my very best to assist You today. How may I help you? ,\n             success_value  :  eval(show_buttons) ,\n             action  :  show_buttons ,\n             queries  : [\n                cannot access account ,\n                problem access account \n            ],\n             execution_order  : 1,\n             max_state_count  : 0,\n             failure_value  :  dont_understand ,\n             state_data  : {\n                verification  :  did you mean you can't access to your account? \n            },\n             analyzer  :  or(and(or(keyword(\\ problem.*\\ ),keyword(\\ issue.*\\ ),keyword(\\ trouble.*\\ )),keyword(\\ account\\ )),search(\\ further_details_access_question\\ )) ,\n             state  :  further_details_access_question \n         },\n          score  : 0.930855453014374\n      }\n   ],\n    total  : 1\n}", 
            "title": "200"
        }, 
        {
            "location": "/apis/#get-decisiontable_analyzer", 
            "text": "(WORK IN PROGRESS, PARTIALLY IMPLEMENTED)  Get and return the map of analyzer for each state  Output JSON", 
            "title": "GET /decisiontable_analyzer"
        }, 
        {
            "location": "/apis/#return-codes_6", 
            "text": "", 
            "title": "Return codes"
        }, 
        {
            "location": "/apis/#200_4", 
            "text": "Sample call  curl -v -H  Content-Type: application/json  -X GET  http://localhost:8888/decisiontable_analyzer   Sample response  {\n    analyzer_map  : {\n       account_locked  : {\n          analyzer  :  booleanand(keyword(\\ locked\\ ), keyword(\\ account\\ ), ) ,\n          execution_order  : 1,\n          build  : true\n      },\n       call_operator  : {\n          analyzer  :  and(or(keyword(\\ call\\ ),keyword(\\ talk\\ ),keyword(\\ speak\\ )),keyword(\\ operator\\ )) ,\n          execution_order  : 1,\n          build  : true\n      },\n       forgot_password  : {\n          execution_order  : 1,\n          build  : true,\n          analyzer  :  and(or(keyword(\\ reset\\ ),keyword(\\ forgot\\ )),keyword(\\ password\\ )) \n      },\n       terrible_feedback  : {\n          build  : true,\n          execution_order  : 1,\n          analyzer  :  booleanor(keyword(\\ idiot\\ ), keyword(\\ fuck.*\\ ), keyword(\\ screw\\ ), keyword(\\ damn.*\\ ), keyword(\\ asshole\\ )) \n      },\n       test_state  : {\n          analyzer  :  booleanAnd(booleanNot(booleanOr(keyword(\\ dont\\ ),keyword(\\ don't\\ ))), keyword(\\ test\\ ), booleanOr(keyword(\\ send\\ ), keyword(\\ get\\ ))) ,\n          execution_order  : 1,\n          build  : true\n      },\n       further_details_access_question  : {\n          execution_order  : 1,\n          build  : true,\n          analyzer  :  or(and(or(keyword(\\ problem.*\\ ),keyword(\\ issue.*\\ ),keyword(\\ trouble.*\\ )),keyword(\\ account\\ )),search(\\ further_details_access_question\\ )) \n      }\n   }\n}", 
            "title": "200"
        }, 
        {
            "location": "/apis/#post-decisiontable_analyzer", 
            "text": "Load/reload the map of analyzer from ES  Output JSON", 
            "title": "POST /decisiontable_analyzer"
        }, 
        {
            "location": "/apis/#return-codes_7", 
            "text": "", 
            "title": "Return codes"
        }, 
        {
            "location": "/apis/#200_5", 
            "text": "Sample call  curl -v -H  Content-Type: application/json  -X POST  http://localhost:8888/decisiontable_analyzer   Sample response  { num_of_entries :1}", 
            "title": "200"
        }, 
        {
            "location": "/apis/#get-knowledgebase", 
            "text": "Return a document by ID  Output JSON", 
            "title": "GET /knowledgebase"
        }, 
        {
            "location": "/apis/#return-codes_8", 
            "text": "", 
            "title": "Return codes"
        }, 
        {
            "location": "/apis/#200_6", 
            "text": "Sample call  # retrieve one or more entries with given ids; ids can be specified multiple times\ncurl -v -H  Content-Type: application/json   http://localhost:8888/knowledgebase?ids=0   Sample response  {\n    max_score  : 0,\n    total  : 1,\n    hits  : [\n      {\n          score  : 0,\n          document  : {\n             conversation  :  id:1000 ,\n             id  :  0 ,\n             status  : 0,\n             question_scored_terms  : [\n               [\n                   thank ,\n          1.09\n               ]\n            ],\n             verified  : true,\n             answer  :  you are welcome! ,\n             topics  :  t1 t2 ,\n             doctype  :  normal ,\n             index_in_conversation  : 1,\n             question  :  thank you ,\n             state  :  \n         }\n      }\n   ]\n}", 
            "title": "200"
        }, 
        {
            "location": "/apis/#post-knowledgebase", 
            "text": "Insert a new document", 
            "title": "POST /knowledgebase"
        }, 
        {
            "location": "/apis/#return-codes_9", 
            "text": "", 
            "title": "Return codes"
        }, 
        {
            "location": "/apis/#201_2", 
            "text": "curl -v -H  Content-Type: application/json  -X POST http://localhost:8888/knowledgebase -d '{\n     id :  0 ,\n     conversation :  id:1000 ,\n     index_in_conversation : 1,\n     question :  thank you ,\n     answer :  you are welcome! ,\n     question_scored_terms : [\n        [\n             thank ,\n            1.9\n        ]\n    ],\n     verified : true,\n     topics :  t1 t2 ,\n     doctype :  normal ,\n     state :  ,\n     status : 0\n}'  Sample response  {    dtype :  question ,\n     version : 1,\n     id :  1 ,\n     index :  jenny-en-0 ,\n     created :true\n}", 
            "title": "201"
        }, 
        {
            "location": "/apis/#delete-knowledgebase", 
            "text": "Delete a document by ID  Output JSON", 
            "title": "DELETE /knowledgebase"
        }, 
        {
            "location": "/apis/#return-codes_10", 
            "text": "", 
            "title": "Return codes"
        }, 
        {
            "location": "/apis/#200_7", 
            "text": "Sample call  curl -v -H  Content-Type: application/json  -X DELETE http://localhost:8888/knowledgebase/0  Sample output  {\n    id  :  0 ,\n    version  : 5,\n    index  :  jenny-en-0 ,\n    dtype  :  question ,\n    found  : true\n}", 
            "title": "200"
        }, 
        {
            "location": "/apis/#put-knowledgebase", 
            "text": "Update an existing document  Output JSON", 
            "title": "PUT /knowledgebase"
        }, 
        {
            "location": "/apis/#return-codes_11", 
            "text": "", 
            "title": "Return codes"
        }, 
        {
            "location": "/apis/#200_8", 
            "text": "Sample call  curl -v -H  Content-Type: application/json  -X PUT http://localhost:8888/knowledgebase/0 -d '{\n     question_scored_terms : [\n                [\n                         thank ,\n                        1.9\n                ],\n                [\n                         thanks ,\n                        1.9\n                ]\n    ]\n}'  Sample response  {\n    index  :  jenny-en-0 ,\n    dtype  :  question ,\n    id  :  0 ,\n    version  : 3,\n    created  : false\n}", 
            "title": "200"
        }, 
        {
            "location": "/apis/#post-knowledgebase_search", 
            "text": "Output JSON", 
            "title": "POST /knowledgebase_search"
        }, 
        {
            "location": "/apis/#return-codes_12", 
            "text": "", 
            "title": "Return codes"
        }, 
        {
            "location": "/apis/#200_9", 
            "text": "Sample call  curl -v -H  Content-Type: application/json  -X POST http://localhost:8888/knowledgebase_search -d '{\n   question :  thank you ,\n   verified : true,\n   doctype :  normal \n}'  Sample output  {\n    max_score  : 1.15013706684113,\n    total  : 2,\n    hits  : [\n      {\n          document  : {\n             id  :  1 ,\n             doctype  :  normal ,\n             question_scored_terms  : [\n               [\n                   validation ,\n                  0.0343148699683119\n               ],\n               [\n                   imac ,\n                  1.12982760046835\n               ],\n               [\n                   aware ,\n                  3.15048958129597\n               ],\n               [\n                   ios ,\n                  6.14545226791214\n               ],\n               [\n                   activation ,\n                  4.92133804309887\n               ]\n            ],\n             answer  :  fine thanks ,\n             conversation  :  id:1000 ,\n             state  :  ,\n             question  :  how are you? ,\n             status  : 0,\n             index_in_conversation  : 1,\n             topics  :  t1 t2 ,\n             verified  : true\n         },\n          score  : 1.15013706684113\n      }\n   ]\n}", 
            "title": "200"
        }, 
        {
            "location": "/apis/#post-language_guesser", 
            "text": "Output JSON", 
            "title": "POST /language_guesser"
        }, 
        {
            "location": "/apis/#return-codes_13", 
            "text": "", 
            "title": "Return codes"
        }, 
        {
            "location": "/apis/#200_10", 
            "text": "Sample call  curl -v -H  Content-Type: application/json  -X POST  http://localhost:8888/language_guesser  -d  \n{\n    \\ input_text\\ : \\ good morning, may I ask you a question?\\ \n}   Sample output  {\n    enhough_text  : false,\n    language  :  en ,\n    confidence  :  MEDIUM ,\n    score  : 0.571426689624786\n}", 
            "title": "200"
        }, 
        {
            "location": "/apis/#get-language_guesser", 
            "text": "Output JSON", 
            "title": "GET /language_guesser"
        }, 
        {
            "location": "/apis/#return-codes_14", 
            "text": "", 
            "title": "Return codes"
        }, 
        {
            "location": "/apis/#200_11", 
            "text": "Sample call  curl -v -H  Content-Type: application/json  -X GET  http://localhost:8888/language_guesser/en   Sample output  { message : updated index: jenny-en-0 dt_type_ack(true) kb_type_ack(true) kb_type_ack(true) }", 
            "title": "200"
        }, 
        {
            "location": "/apis/#post-index_managementcreate", 
            "text": "Output JSON", 
            "title": "POST /index_management/create"
        }, 
        {
            "location": "/apis/#return-codes_15", 
            "text": "", 
            "title": "Return codes"
        }, 
        {
            "location": "/apis/#200_12", 
            "text": "Sample call  curl -v -H  Content-Type: application/json  -X POST  http://localhost:8888/index_management   Sample output  { message : create index: jenny-en-0 create_index_ack(true) }", 
            "title": "200"
        }, 
        {
            "location": "/apis/#post-index_managementrefresh", 
            "text": "Output JSON", 
            "title": "POST /index_management/refresh"
        }, 
        {
            "location": "/apis/#return-codes_16", 
            "text": "", 
            "title": "Return codes"
        }, 
        {
            "location": "/apis/#200_13", 
            "text": "Sample call  curl -v -H  Content-Type: application/json  -X POST  http://localhost:8888/index_management/refresh   Sample output  {\n    failed_shards_n  : 0,\n    total_shards_n  : 10,\n    failed_shards  : [],\n    successful_shards_n  : 5\n}", 
            "title": "200"
        }, 
        {
            "location": "/apis/#get-index_management", 
            "text": "Output JSON", 
            "title": "GET /index_management"
        }, 
        {
            "location": "/apis/#return-codes_17", 
            "text": "", 
            "title": "Return codes"
        }, 
        {
            "location": "/apis/#200_14", 
            "text": "Sample call  curl -v -H  Content-Type: application/json  -X GET  http://localhost:8888/index_management   Sample output  { message : settings index: jenny-en-0 dt_type_check(state:true) kb_type_check(question:true) term_type_name(term:true) }", 
            "title": "200"
        }, 
        {
            "location": "/apis/#put-index_management", 
            "text": "Output JSON", 
            "title": "PUT /index_management"
        }, 
        {
            "location": "/apis/#return-codes_18", 
            "text": "", 
            "title": "Return codes"
        }, 
        {
            "location": "/apis/#200_15", 
            "text": "Sample call  curl -v -H  Content-Type: application/json  -X PUT  http://localhost:8888/index_management   Sample output  { message : updated index: jenny-en-0 dt_type_ack(true) kb_type_ack(true) kb_type_ack(true) }", 
            "title": "200"
        }, 
        {
            "location": "/apis/#delete-index_management", 
            "text": "Output JSON", 
            "title": "DELETE /index_management"
        }, 
        {
            "location": "/apis/#return-codes_19", 
            "text": "", 
            "title": "Return codes"
        }, 
        {
            "location": "/apis/#200_16", 
            "text": "Sample call  curl -v -H  Content-Type: application/json  -X DELETE  http://localhost:8888/index_management   Sample output  { message : removed index: jenny-en-0 index_ack(true) }", 
            "title": "200"
        }, 
        {
            "location": "/apis/#post-termindex", 
            "text": "Index the term as indicated in the JSON.", 
            "title": "POST /term/index"
        }, 
        {
            "location": "/apis/#return-codes_20", 
            "text": "", 
            "title": "Return codes"
        }, 
        {
            "location": "/apis/#200_17", 
            "text": "Sample call  curl -v -H  Content-Type: application/json  -X POST http://localhost:8888/term/index -d '{\n      terms : [\n         {\n             term :  \u092e\u0930\u093e\u0920\u0940 ,\n             frequency_base : 1.0,\n             frequency_stem : 1.0,\n             vector : [1.0, 2.0, 3.0],\n             synonyms :\n            {\n                 bla1 : 0.1,\n                 bla2 : 0.2\n            },\n             antonyms :\n            {\n                 bla3 : 0.1,\n                 bla4 : 0.2\n            },\n             tags :  tag1 tag2 ,\n             features :\n            {\n                 NUM :  S ,\n                 GEN :  M \n            }\n            },\n            {\n             term :  term2 ,\n             frequency_base : 1.0,\n             frequency_stem : 1.0,\n             vector : [1.0, 2.0, 3.0],\n             synonyms :\n            {\n                 bla1 : 0.1,\n                 bla2 : 0.2\n            },\n             antonyms :\n            {\n                 bla3 : 0.1,\n                 bla4 : 0.2\n            },\n             tags :  tag1 tag2 ,\n             features :\n            {\n                 NUM :  P ,\n                 GEN :  F \n            }\n            }\n   ]\n}'  Sample output  {\n    data  : [\n      {\n          version  : 1,\n          created  : true,\n          dtype  :  term ,\n          index  :  jenny-en-0 ,\n          id  :  \u092e\u0930\u093e\u0920\u0940 \n      },\n      {\n          dtype  :  term ,\n          created  : true,\n          version  : 1,\n          id  :  term2 ,\n          index  :  jenny-en-0 \n      }\n   ]\n}", 
            "title": "200"
        }, 
        {
            "location": "/apis/#post-termget", 
            "text": "Get one or more terms entry.", 
            "title": "POST /term/get"
        }, 
        {
            "location": "/apis/#return-codes_21", 
            "text": "", 
            "title": "Return codes"
        }, 
        {
            "location": "/apis/#200_18", 
            "text": "Sample call  curl -v -H  Content-Type: application/json  -X POST http://localhost:8888/term/get -d '{\n      ids : [ \u092e\u0930\u093e\u0920\u0940 ,  term2 ]\n}'  Sample output  {\n    terms  : [\n      {\n          vector  : [\n            1,\n            2,\n            3\n         ],\n         frequency_base : 1.0,\n         frequency_stem : 1.0,\n          term  :  \u092e\u0930\u093e\u0920\u0940 ,\n          antonyms  : {\n             bla4  : 0.2,\n             bla3  : 0.1\n         },\n          features  : {\n             NUM  :  S ,\n             GEN  :  M \n         },\n          synonyms  : {\n             bla2  : 0.2,\n             bla1  : 0.1\n         },\n          tags  :  tag1 tag2 \n      },\n      {\n          antonyms  : {\n             bla3  : 0.1,\n             bla4  : 0.2\n         },\n          features  : {\n             NUM  :  P ,\n             GEN  :  F \n         },\n          term  :  term2 ,\n          frequency_base : 1.0,\n          frequency_stem : 1.0,\n          vector  : [\n            1,\n            2,\n            3\n         ],\n          synonyms  : {\n             bla1  : 0.1,\n             bla2  : 0.2\n         },\n          tags  :  tag1 tag2 \n      }\n   ]\n}", 
            "title": "200"
        }, 
        {
            "location": "/apis/#delete-term", 
            "text": "Delete the term.", 
            "title": "DELETE /term"
        }, 
        {
            "location": "/apis/#return-codes_22", 
            "text": "", 
            "title": "Return codes"
        }, 
        {
            "location": "/apis/#200_19", 
            "text": "Sample call  curl -v -H  Content-Type: application/json  -X DELETE http://localhost:8888/term -d '{\n      ids : [ \u092e\u0930\u093e\u0920\u0940 ,  term2 ]\n}'  Sample output  {\n    data  : [\n      {\n          dtype  :  term ,\n          version  : 2,\n          id  :  \u092e\u0930\u093e\u0920\u0940 ,\n          index  :  jenny-en-0 ,\n          found  : true\n      },\n      {\n          dtype  :  term ,\n          id  :  term2 ,\n          version  : 2,\n          found  : true,\n          index  :  jenny-en-0 \n      }\n   ]\n}", 
            "title": "200"
        }, 
        {
            "location": "/apis/#put-term", 
            "text": "Update the entry.", 
            "title": "PUT /term"
        }, 
        {
            "location": "/apis/#return-codes_23", 
            "text": "", 
            "title": "Return codes"
        }, 
        {
            "location": "/apis/#200_20", 
            "text": "Sample call  curl -v -H  Content-Type: application/json  -X PUT http://localhost:8888/term -d '{\n      terms : [\n         {\n             term :  \u092e\u0930\u093e\u0920\u0940 ,\n             frequency_base : 1.0,\n             frequency_stem : 1.0,\n             vector : [1.0, 2.0, 3.0, 4.0],\n             synonyms :\n            {\n                 bla1 : 0.1,\n                 bla2 : 0.2\n            },\n             antonyms :\n            {\n                 term2 : 0.1,\n                 bla4 : 0.2\n            },\n             tags :  tag1 tag2 ,\n             features :\n            {\n                 FEATURE_NEW1 :  V ,\n                 GEN :  M \n            }\n            },\n            {\n             term :  term2 ,\n             frequency_base : 1.0,\n             frequency_stem : 1.0,\n             vector : [1.0, 2.0, 3.0, 5.0],\n             synonyms :\n            {\n                 bla1 : 0.1,\n                 bla2 : 0.2\n            },\n             antonyms :\n            {\n                 bla3 : 0.1,\n                 bla4 : 0.2\n            },\n             tags :  tag1 tag2 ,\n             features :\n            {\n                 FEATURE_NEW1 :  N ,\n                 GEN :  F \n            }\n            }\n   ]\n}'  Sample output  {\n    data  : [\n      {\n          version  : 2,\n          id  :  \u092e\u0930\u093e\u0920\u0940 ,\n          index  :  jenny-en-0 ,\n          created  : false,\n          dtype  :  term \n      },\n      {\n          index  :  jenny-en-0 ,\n          id  :  term2 ,\n          version  : 2,\n          dtype  :  term ,\n          created  : false\n      }\n   ]\n}", 
            "title": "200"
        }, 
        {
            "location": "/apis/#get-termterm", 
            "text": "Search for term (using Elasticsearch).", 
            "title": "GET /term/term"
        }, 
        {
            "location": "/apis/#return-codes_24", 
            "text": "", 
            "title": "Return codes"
        }, 
        {
            "location": "/apis/#200_21", 
            "text": "Sample call  curl -v -H  Content-Type: application/json  -X GET http://localhost:8888/term/term -d '{\n     term :  \u092e\u0930\u093e\u0920\u0940 \n}'  Sample output  {\n    hits  : {\n       terms  : [\n         {\n             vector  : [\n               1.2,\n               2.3,\n               3.4,\n               4.5\n            ],\n             antonyms  : {\n                bla4  : 0.2,\n                term2  : 0.1\n            },\n             frequency_base : 1.0,\n             frequency_stem : 1.0,\n             features  : {\n                FEATURE_NEW1  :  V ,\n                GEN  :  M \n            },\n             score  : 0.6931471824646,\n             tags  :  tag1 tag2 ,\n             term  :  \u092e\u0930\u093e\u0920\u0940 ,\n             synonyms  : {\n                bla2  : 0.2,\n                bla1  : 0.1\n            }\n         }\n      ]\n   },\n    total  : 1,\n    max_score  : 0.6931471824646\n}", 
            "title": "200"
        }, 
        {
            "location": "/apis/#get-termtext", 
            "text": "Search for all the terms in the text and return the entries.", 
            "title": "GET /term/text"
        }, 
        {
            "location": "/apis/#return-codes_25", 
            "text": "", 
            "title": "Return codes"
        }, 
        {
            "location": "/apis/#200_22", 
            "text": "Sample call  curl -v -H  Content-Type: application/json  -X GET http://localhost:8888/term/text -d 'term2 \u092e\u0930\u093e\u0920\u0940'  Sample output  {\n    max_score  : 0.6931471824646,\n    hits  : {\n       terms  : [\n         {\n             term  :  \u092e\u0930\u093e\u0920\u0940 ,\n             score  : 0.6931471824646,\n             tags  :  tag1 tag2 ,\n             vector  : [\n               1.2,\n               2.3,\n               3.4,\n               4.5\n            ],\n             features  : {\n                GEN  :  M ,\n                FEATURE_NEW1  :  V \n            },\n             antonyms  : {\n                bla4  : 0.2,\n                term2  : 0.1\n            },\n             synonyms  : {\n                bla2  : 0.2,\n                bla1  : 0.1\n            },\n             frequency_base : 1.0,\n             frequency_stem : 1.0\n         },\n         {\n             term  :  term2 ,\n             tags  :  tag1 tag2 ,\n             score  : 0.6931471824646,\n             features  : {\n                FEATURE_NEW1  :  N ,\n                GEN  :  F \n            },\n             vector  : [\n               1.6,\n               2.7,\n               3.8,\n               5.9\n            ],\n             antonyms  : {\n                bla3  : 0.1,\n                bla4  : 0.2\n            },\n             frequency_base : 1.0,\n             frequency_stem : 1.0,\n             synonyms  : {\n                bla1  : 0.1,\n                bla2  : 0.2\n            }\n         }\n      ]\n   },\n    total  : 2\n}", 
            "title": "200"
        }, 
        {
            "location": "/apis/#get-tokenizers", 
            "text": "Show a list of supported methods for tokenization and stemming", 
            "title": "GET /tokenizers"
        }, 
        {
            "location": "/apis/#return-codes_26", 
            "text": "", 
            "title": "Return codes"
        }, 
        {
            "location": "/apis/#200_23", 
            "text": "Sample call  curl -v -H  Content-Type: application/json  -X GET  http://localhost:8888/tokenizers   Sample output  {\n    shingles2  :  2 words shingles ,\n    shingles3  :  3 words shingles ,\n    shingles2_10  :  from 2 to 10 shingles ,\n    base_stem  :  lowercase + stemming ,\n    base  :  lowercase ,\n    stop  :  lowercase + stopwords elimination ,\n    shingles4  :  4 words shingles ,\n    stop_stem  :  lowercase + stopwords elimination + stemming \n}", 
            "title": "200"
        }, 
        {
            "location": "/apis/#post-tokenizers", 
            "text": "get a list of token using the selected analyzer", 
            "title": "POST /tokenizers"
        }, 
        {
            "location": "/apis/#return-codes_27", 
            "text": "", 
            "title": "Return codes"
        }, 
        {
            "location": "/apis/#200_24", 
            "text": "Sample call  curl -v -H  Content-Type: application/json  -X POST  http://localhost:8888/tokenizers  -d  \n{\n    \\ text\\ : \\ good morning, may I ask you a question?\\ ,\n          \\ tokenizer\\ : \\ stop\\ \n          }   Sample output  {\n    tokens  : [\n      {\n          start_offset  : 0,\n          end_offset  : 4,\n          token_type  :  word ,\n          token  :  good ,\n          position  : 0\n      },\n      {\n          token  :  morning ,\n          position  : 1,\n          token_type  :  word ,\n          end_offset  : 12,\n          start_offset  : 5\n      },\n      {\n          start_offset  : 14,\n          end_offset  : 17,\n          token_type  :  word ,\n          token  :  may ,\n          position  : 2\n      },\n      {\n          token_type  :  word ,\n          token  :  i ,\n          position  : 3,\n          start_offset  : 18,\n          end_offset  : 19\n      },\n      {\n          end_offset  : 23,\n          start_offset  : 20,\n          position  : 4,\n          token  :  ask ,\n          token_type  :  word \n      },\n      {\n          end_offset  : 27,\n          start_offset  : 24,\n          position  : 5,\n          token  :  you ,\n          token_type  :  word \n      },\n      {\n          end_offset  : 38,\n          start_offset  : 30,\n          token  :  question ,\n          position  : 7,\n          token_type  :  word \n      }\n   ]\n}", 
            "title": "200"
        }, 
        {
            "location": "/apis/#post-analyzers_playground", 
            "text": "used to test analyzers on the fly", 
            "title": "POST /analyzers_playground"
        }, 
        {
            "location": "/apis/#return-codes_28", 
            "text": "", 
            "title": "Return codes"
        }, 
        {
            "location": "/apis/#200_25", 
            "text": "Sample call  ANALYZER= keyword(\\\\\\ test\\\\\\ ) \nQUERY= this is a test \ncurl -v -H  Content-Type: application/json  -X POST  http://localhost:8888/analyzers_playground  -d  \n{\n        \\ analyzer\\ : \\ ${ANALYZER}\\ ,\n            \\ query\\ : \\ ${QUERY}\\ \n        }   Sample output  {\n    value  : 0.25,\n    build_message  :  success ,\n    build  : true\n}  Sample of pattern extraction through analyzers  curl -v -H 'Content-Type: application/json' -X POST http://localhost:8888/analyzers_playground -d' \n{\n         analyzer :  band(keyword(\\ on\\ ), matchPatternRegex(\\ [day,month,year](?:(0[1-9]|[12][0-9]|3[01])(?:[- \\\\\\/\\\\.])(0[1-9]|1[012])(?:[- \\\\\\/\\\\.])((?:19|20)\\\\d\\\\d))\\ )) ,\n         query :  on 31-11-1900 \n}'```\n\nSample output\n\n```json\n{\n    build_message  :  success ,\n    variables  : {\n       month.0  :  11 ,\n       day.0  :  31 ,\n       year.0  :  1900 \n   },\n    build  : true,\n    value  : 1\n}", 
            "title": "200"
        }, 
        {
            "location": "/apis/#post-spellcheckterms", 
            "text": "terms spellchecker based on knowledgebase text", 
            "title": "POST /spellcheck/terms"
        }, 
        {
            "location": "/apis/#return-codes_29", 
            "text": "", 
            "title": "Return codes"
        }, 
        {
            "location": "/apis/#200_26", 
            "text": "Sample call  QUERY=${1:- this is a tes for splellchecker }\ncurl -v -H  Content-Type: application/json  -X POST http://localhost:8888/spellcheck/terms -d  {\n  \\ text\\ : \\ ${QUERY}\\ ,\n    \\ prefix_length\\ : 3,\n      \\ min_doc_freq\\ : 1\n      }   {\n    tokens  : [\n      {\n          offset  : 0,\n          options  : [\n            {\n                freq  : 1284,\n                score  : 0.800000011920929,\n                text  :  hello \n            },\n            {\n                text  :  hella ,\n                score  : 0.800000011920929,\n                freq  : 2\n            },\n            {\n                freq  : 2,\n                score  : 0.800000011920929,\n                text  :  helle \n            },\n            {\n                text  :  help ,\n                score  : 0.75,\n                freq  : 35395\n            },\n            {\n                score  : 0.75,\n                freq  : 5,\n                text  :  hell \n            }\n         ],\n          length  : 5,\n          text  :  hellp \n      },\n      {\n          length  : 4,\n          options  : [],\n          offset  : 7,\n          text  :  this \n      },\n      {\n          length  : 2,\n          options  : [],\n          offset  : 12,\n          text  :  is \n      },\n      {\n          length  : 1,\n          offset  : 15,\n          options  : [],\n          text  :  a \n      },\n      {\n          length  : 4,\n          offset  : 17,\n          options  : [\n            {\n                text  :  test ,\n                score  : 0.75,\n                freq  : 191\n            },\n            {\n                freq  : 10,\n                score  : 0.5,\n                text  :  tessa \n            },\n            {\n                text  :  tesco ,\n                score  : 0.5,\n                freq  : 9\n            },\n            {\n                text  :  tesia ,\n                score  : 0.5,\n                freq  : 2\n            },\n            {\n                freq  : 2,\n                score  : 0.5,\n                text  :  tester \n            }\n         ],\n          text  :  tesr \n      }\n   ]\n}", 
            "title": "200"
        }, 
        {
            "location": "/about/", 
            "text": "GetJenny\n\n\nGetJenny\n, the company behind StarChat, is a Finnish startup which provides automated systems for customer services.\n\n\nThrough StarChat, GetJenny provides the backend engine able to manage conversations or to recommend answers based on past conversations and integrate it into its customers' brand-to-consumer communication platform.\n\n\nAlthough all the integration software is closed source, the backend, StarChat, is open source. People can download, modify and use it.\n\n\nTry it at \ngit.io/*chat\n!", 
            "title": "About"
        }, 
        {
            "location": "/about/#getjenny", 
            "text": "GetJenny , the company behind StarChat, is a Finnish startup which provides automated systems for customer services.  Through StarChat, GetJenny provides the backend engine able to manage conversations or to recommend answers based on past conversations and integrate it into its customers' brand-to-consumer communication platform.  Although all the integration software is closed source, the backend, StarChat, is open source. People can download, modify and use it.  Try it at  git.io/*chat !", 
            "title": "GetJenny"
        }
    ]
}