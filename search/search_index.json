{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome! This is the official repository for StarChat --an Open Source, scalable conversational engine for B2B applications. You can find the code on our github repository . How to contribute To contribute to StarChat, please send us a pull request from your fork of this repository. Our concise contribution guideline contains the bare minumum requirements of the code contributions. Before contributing (or opening issues), you might want send us an email at starchat@getjenny.com. Quick Start Requirements The easiest way is to install StarChat using two docker images. You only need: sbt docker docker compose In this way, you will put all the indices in the Elasticsearch (version 6.1) image, and StarChat itself in the Java (8) image. If you do not use docker you therefore need on your machine: Scala 12.2 Elasticsearch 5.4 Setup with Docker (recommended) 1. Launch Docker containers We have made available all the containers needed for having StarChat up and running without local compiling. To use them, you need to download Starchat Docker or simply type: git clone https://github.com/GetJenny/starchat-docker.git Get into the starchat-docker directory and: docker-compose up -d If you get an ERROR: Version in \"./docker-compose.yml\" is unsupported. you need to update docker-compose to the version indicated in the docker-compose.yml file. Note that it might not be available on ubuntu (we need to use a very recent one). If that's the case see eg stackoverflow . Now you should have a running instance on port 8888. (If you want to change ports, eg because you have other services on 8888/9200/9300, change the values in docker-compose.yml) (Problems like elastisearch exited with code 78 ? have a look at troubleshooting !) Change Manaus Language In the file docker-compose.yml change: command: [ /manaus/scripts/wait-for-it.sh , getjenny-es , 9200 , 5 , /manaus/bin/continuous-keywords-update , --temp_data_folder , /manaus/data , --host_map , getjenny-es=9300 , --interval_sec , 14400 , --word_frequencies , /manaus/statistics_data/english/word_frequency.tsv , --cluster_name , starchat , --index_name , jenny-en-0 ] to command: [ /manaus/scripts/wait-for-it.sh , getjenny-es , 9200 , 5 , /manaus/bin/continuous-keywords-update , --temp_data_folder , /manaus/data , --host_map , getjenny-es=9300 , --interval_sec , 14400 , --word_frequencies , /manaus/statistics_data/***italian***/word_frequency.tsv , --cluster_name , starchat , --index_name , ***jenny-it-0*** ] 2. Create Elasticsearch indices Run from a terminal: # create the system indices in Elasticsearch PORT=${1:-8888} curl -v -H Authorization: Basic `echo -n 'admin:adminp4ssw0rd' | base64` \\ -H Content-Type: application/json -X POST http://localhost:${PORT}/system_index_management/create If you are using another language than English, replace english in the name of the index: # create the application indices on Elasticsearch PORT=${1:-8888} INDEX_NAME=${2:-index_getjenny_english_0} curl -v -H Authorization: Basic `echo -n 'admin:adminp4ssw0rd' | base64` \\ -H Content-Type: application/json -X POST http://localhost:${PORT}/${INDEX_NAME}/index_management/create # add a user to the system associated to the application index index_getjenny_english_0 previously created PORT=${1:-8888} curl -v -H Authorization: Basic `echo -n 'admin:adminp4ssw0rd' | base64` \\ -H Content-Type: application/json -X POST http://localhost:${PORT}/user -d '{ id : test_user , password : 3c98bf19cb962ac4cd0227142b3495ab1be46534061919f792254b80c0f3e566f7819cae73bdc616af0ff555f7460ac96d88d56338d659ebd93e2be858ce1cf9 , salt : salt , permissions : { index_getjenny_english_0 : [ read , write ] } }' 3. Load the configuration file Now you have to load the configuration file for the actual chat, aka decision table . We have provided an example configuration file in English , therefore: cd $STARCHAT # so we have doc/decision_table_starchat_doc.csv PORT=${1:-8888} INDEX_NAME=${2:-'index_getjenny_english_0'} FILENAME=${3:- `readlink -e doc/decision_table_starchat_doc.csv` } curl -v -H Authorization: Basic `echo -n 'test_user:p4ssw0rd' | base64` \\ --form csv=@${FILENAME} http://localhost:${PORT}/${INDEX_NAME}/decisiontable_upload_csv and then you need to index the analyzer: PORT=${1:-8888} INDEX_NAME=${2:-index_getjenny_english_0} curl -v -H Authorization: Basic `echo -n 'test_user:p4ssw0rd' | base64` \\ -H Content-Type: application/json -X POST http://localhost:${PORT}/${INDEX_NAME}/decisiontable_analyzer In case you want to delete all states previously loaded, this endpoint deletes all the states: PORT=${1:-8888} INDEX_NAME=${2:-index_getjenny_english_0} curl -v -H Authorization: Basic `echo -n 'test_user:p4ssw0rd' | base64` \\ -H Content-Type: application/json -X DELETE http://localhost:${PORT}/${INDEX_NAME}/decisiontable 4. Load external corpus (optional) To have a good words' statistics, and consequent improved matching, you might want to index a corpus which is hidden from results. For instance, you can index various sentences as hidden using the POST /knowledgebase endpoint with doctype: \"hidden\" . 5. Index the FAQs (optional) TODO: You might want to activate the knowledge base for simple Question and Anwer. Install without Docker Note: we do not support this installation. Clone the repository and enter the starchat directory. Initialize the Elasticsearch instance (see above for Docker) Run the service: sbt compile run The service binds on the port 8888 by default. Install local Docker (for testing branches) Generate a packet distribution. In StarChat directory: sbt dist Enter the directory docker-starchat: cd docker-starchat You will get a message like Your package is ready in ...../target/universal/starchat-4ee.... .zip . Extract the packet into the docker-starchat folder: unzip ../target/universal/starchat-4eee.....zip ln -s starchat-4ee..../ starchat The zip packet contains: a set of scripts to test the endpoints and as a complement for the documentation: starchat/scripts/api_test/ a set of command line programs starchat/bin to run starchat and other tools. delete-decision-table: application to delete items from the decision table index-corpus-on-knowledge-base: application to index a corpus on knowledge base as hidden (to improve the language model) index-decision-table: application to index data on the decision table from a csv index-knowledge-base: application to index data into the knowledge base index-terms: application to index terms vectors starchat: start starchat Review the configuration files starchat/config/application.conf and configure the language if needed (by default you have index_language = \"english\" ) (If you are re-installing StarChat, and want to start from scratch see start from scratch .) Start both startchat and elasticsearch: docker-compose up -d (Problems like elastisearch exited with code 78 ? have a look at troubleshooting !) Test the installation Is the service working? But first: did you load a configuration file ? If yes, try: curl -X GET localhost:8888 | python -mjson.tool Get the test_state PORT=${2:-8888} INDEX_NAME=${3:-index_getjenny_english_0} curl -v -H Authorization: Basic `echo -n 'test_user:p4ssw0rd' | base64` \\ -H Content-Type: application/json -X POST http://localhost:${PORT}/${INDEX_NAME}/get_next_response -d '{ conversation_id : 1234 , user_input : { text : install starchat }, values : { return_value : , data : {} } }' You should get: [ { state : install , data : {}, action : , success_value : , state_data : {}, score : 1, conversation_id : 1234 , traversed_states : [ install ], max_state_count : 0, action_input : {}, analyzer : band(bor(keyword(\\ setup\\ ), keyword(\\ install.*\\ )), bnot(bor(keyword(\\ standalone\\ ), keyword(\\ docker\\ )))) , bubble : Just choose one of the two:\\n ul \\n li docker install (recommended) /li \\n li standalone install /li \\n /ul , failure_value : } ] If you look at the \"analyzer\" field, you'll see that this state is triggered when the user types the test and either get or send . Try with \"text\": \"Please dont send me the test state\" and StarChat will send an empty message. Configuration of the chatbot (Decision Table) With StarChat's Decision Table you can easily implement workflow-based chatbots. After the installation (see above) you only have to configure a conversation flow and eventually a front-end client. NLP processing NLP processing is of course the core of any chatbot. As you have noted in the CSV provided in the doc/ directory there are two fields defining when StarChat should trigger a state - analyzer and queries . Queries If the analyzer field is empty, StarChat will query Elasticsearch for the state containing the most similar sentence in the field queries . We have carefully configured Elasticsearch in order to provide good answers (e.g. boosting results where the same words appear etc), and results are... acceptable. But you are encouraged to use the analyzer field, documented below. Analyzer The analyzers are a Domain Specific Language which allow to put together various functions using logical operators. Through the analyzers , you can leverage on various NLP algorithms included in StarChat and combine the results of those algorithms with other rules. For instance you might want to get into the state which asks for the email only if a variable \"email\" is not set. Or you want to escalate to a human operator after you detect swearing for three times. Or you want to escalate only on working days. You can do all that with the analyzers . We can have a look at the simple example included in the CSV provided in the doc/ directory for the state forgot_password : booleanAnd(keyword( password ),booleanOr(keyword( reset ),keyword( forgot ))) The analyzer above says the state must be triggered if the term \"password\" is detected together with either \"reset\" or \"forgot\". Another example. Imagine we have a state called send-updates . In this state StarChat proposes the question \"Where can we send you updates?\". In the config file: state | ... | bubble | ... send-updates | ... | Where can we send you updates? | In another state, called send-email , we have the anlyzer field with: booleanAnd(lastTravStateIs( send-updates ), matchEmailAddress( verification_ )) this means send-email will be triggered only after send-updates (because of lastTravStateIs ) and if an email address is detected (because of matchEmailAddress ). This will also set the variable verification_email because the expression matchEmailAddress in case of success always sets such variable, with the expression's argument as prefix. In addition to that, the expression sendVerificationEmail could be developed (we haven't) which accepts others arguments, for example: sendVerificationEmail(\"verification_\", \"Email about Verification\", \"Here is your verification link %__temp__verification_link%) In this case, the expression would extract an email address from the user's query set a variable verification_email with such address retrieve a verification link from some API put that link into the temporary variable __temp__verification_link . send an email with subject \"Email about Verification\" and body \"Here is your...\" return 1 in case of success TODO It is fundamental here to build a set of metadata which allows any other component to receive all needed information about the analyzer. For instance, the sendVerificationEmail could have something like: [ documentation : Send an email with subject and body. If successful returns 1.0 and sets the variables. If not returns 0 and does not set the variables. argument_list : [ 'prefix' of the variable 'prefix_email' , Subject of the email to be sent , Body of the mail ], created_variables : { // Variables it creates __temp__verification_link : Link provided by the brand's API , //will after usage because starts with __temp__ prefix_email : email address }, used_variables : { // Variables it expects to find in the state (none here) } How the analyzers are organized The analyzer DSL building blocks are the expression . For instance, or , and , keyword are all expressions . Espressions are then divided into operators ( or ...) and atoms ( keyword ). Expressions: Atoms Presently, the keyword(\"reset\") in the example provides a very simple score: occurrence of the word reset in the user's query divided by the total number of words. If evaluated agains the sentence \"Want to reset my password\", keyword(\"reset\") will currently return 0.2. TODO : This is just a temporary score used while our NLP library manaus is not integrated into the decision table. These are currently the expression you can use to evaluate the goodness of a query (see DefaultFactoryAtomic and StarchatFactoryAtomic : keyword(\"pass.*\") : as explained above, detects any word starting with \"pass\". Normalized. regex(regex) : evaluate a regular expression, not normalized search(state-name) : take a state name as argument, queries elastic search and returns the score of the most similar query in the field queries of the argument's state. In other words, it does what it would do without any analyzer, only with a normalized score -e.g. search(\"lost_password_state\") matchPatternRegex(regex) : A generic pattern extraction analyzer, it extract named patterns matching a given regex e.g. the following will match tree numbers separated by semicolumn: [first,second,third](?:([0-9]+:[0-9]:[0-9]+) if the regex matches it will create the entries into the state variables dictionary e.g.: 10:11:12 will result in Map(\"first.0\" - \"10\", \"second.0\" - \"11\", \"third.0\" - \"12\") the number at the end of the name is an index incremented for multiple occurrences of the pattern in the query matchDateDDMMYYYY(prefix) : parse a date in DDMMYYYY format and set prefixday.0 , prefixmonth.0 , prefixyear.0 . existsVariable(variable-name) : check whether a variable exists or not hasTravState(state-name) : check if a state_name is present into the history of traversed states lastTravStateIs(state-name) : check if the last traversed state is state_name prevTravStateIs(state-name) : check if the last but one traversed state is state_name distance(\"forget. \", ..., \"pass. \") : score based on the (cosine) distance between the query and the list of words in the argument. checkDayOfMonth : Check if the current time is Equal, LessOrEqual, Less, Greater, GreaterOrEqual to the argument which is an integer between 1 and 31 first argument is the day of the month: a number between 1 and 31 second argument is the operator: any of Equal, LessOrEqual, Less, Greater, GreaterOrEqual third argument is the timezone: UTC, GMT, UT, CET, UTC+ , UTC- , GMT+ , GMT- , UT+ or UT- where N is a number between -18 and +18. Default is CET checkDayOfWeek : Check if the current time is Equal, LessOrEqual, Less, Greater, GreaterOrEqual to the argument which is an integer between 1 (MONDAY) and 7 (SUNDAY) first argument is the day of the week: a number between 1 and 7 second argument is the operator: any of Equal, LessOrEqual, Less, Greater, GreaterOrEqual third argument is the timezone: UTC, GMT, UT, CET, UTC+ , UTC- , GMT+ , GMT- , UT+ or UT- where N is a number between -18 and +18. Default is CET checkHour : Check if the current time is Equal, LessOrEqual, Less, Greater, GreaterOrEqual to the argument time in EPOC first argument is the hour: a number between 0 and 23 second argument is the operator: any of Equal, LessOrEqual, Less, Greater, GreaterOrEqual third argument is the timezone: UTC, GMT, UT, CET, UTC+ , UTC- , GMT+ , GMT- , UT+ or UT- where N is a number between -18 and +18. Default is CET checkMinute : Check if the current minutes are Equal, LessOrEqual, Less, Greater, GreaterOrEqual to the first argument first argument is the minute: a number between 0 and 59 second argument is the operator: any of Equal, LessOrEqual, Less, Greater, GreaterOrEqual third argument is the timezone: UTC, GMT, UT, CET, UTC+ , UTC- , GMT+ , GMT- , UT+ or UT- where N is a number between -18 and +18. Default is CET checkMonth : Check if the current month is Equal, LessOrEqual, Less, Greater, GreaterOrEqual to the argument which is an integer between 1 (JANUARY) and 12 (DECEMBER) first argument is the month's number: an integer between 1 and 12 second argument is the operator: any of Equal, LessOrEqual, Less, Greater, GreaterOrEqual third argument is the timezone: UTC, GMT, UT, CET, UTC+ , UTC- , GMT+ , GMT- , UT+ or UT- where N is a number between -18 and +18. Default is CET checkTimestamp : Check if the current time is Equal, LessOrEqual, Less, Greater, GreaterOrEqual to the argument time in EPOC first argument is the timestamp: a timestamp in EPOC (in seconds) second argument is the operator: any of Equal, LessOrEqual, Less, Greater, GreaterOrEqual double : transform a string into a double, useful for score comparison (see, eq, lt, gt, lte, gte operators) Expressions: Operators Operators evaluate the output of one or more expression and return a value. Currently, the following operators are implemented (the the source code ): boolean or : calles matches of all the exprassions it contains and returns true or false. It can be called using bor boolean and : as above, it's called with band boolean not : ditto, bnot conjunction : if the evaluation of the expressions it contains is normalized, and they can be seen as probabilities of them being true, this is the probability that all the expressions are all true ( P(A)*P(B) ) disjunction : as above, the probability that at least one is true ( 1-(1-P(A))*(1-P(B)) ) max : takes the max score of returned by the expression arguments reinfConjunction : conjuction which uses a 1.1 value instead of 1 as boolean true binarize : take the result of an expression output 1.0 if the score is 0, 0.0 otherwise eq compare the score of two expression, output 1.0 if they are the same, 0.0 otherwise lt compare the score of two expression, output 1.0 if the first arg is less than the second, 0.0 otherwise gt compare the score of two expression, output 1.0 if the first arg is greater than the second, 0.0 otherwise lte compare the score of two expression, output 1.0 if the first arg is less or equal than the second, 0.0 otherwise gte compare the score of two expression, output 1.0 if the first arg is greater or equal than the second, 0.0 otherwise Technical corner: expressions Expressions , like keywords in the example, are called atoms , and have the following methods/members: def evaluate(query: String): Double : produce a score. It might be normalized to 1 or not (set val isEvaluateNormalized: Boolean accordingly) val match_threshold This is the threshold above which the expression is considered true when matches is called. NB The default value is 0.0, which is normally not ideal. def matches(query: String): Boolean : calles evaluate and check agains the threshold... val rx : the name of the atom, as it should be used in the analyzer field. Configuration of the answer recommender (Knowledge Base) Through the /knowledgebase endpoint you can add, edit and remove pairs of question and answers used by StarChat to recommend possible answers when a question arrives. Documents containing Q A must be structured like that: { id : 0 , // id of the pair conversation : id:1000 , // id of the conversation. This can be useful to external services index_in_conversation : 1, // when the pair appears inside the conversation, as above question : thank you , // The question to be matched answer : you are welcome! , // The answer to be recommended question_scored_terms : [ // A list of keyword and score. You can use your own keyword extractor or our Manaus (see later) [ thank , 1.9 ] ], verified : true, // A variable used in some call centers topics : t1 t2 , // Eventual topics to be associated dclass : , // Optional field as a searchable class for answer doctype : normal , state : , status : 0 } See POST /knowledgebase for an example with curl . Other calls ( GET, DELETE, PUT ) are used to get the state, delete it or update it. Test the knowledge base Just run the example in POST /knowledgebase_search . Manaus In the Q A pair above you saw the field question_scored_terms . Having good keywords improves enormously the quality of the answer. You can of course put them by hand, or run a software which extracts the keywords from the question. If you prefer the latter, but don't have any, we provide Manaus . Manaus is still under development, but it's already included in the Docker's installation of StarChat. When you launch docker-compose up -d , you also launch a container with Manaus which analyzes all the Q A in the Knowledge Base, produces keywords and updates the field question_scored_terms for all documents. The process is repeated evert 4 hour. Manaus configuration Have a look at the file docker-starchat/docker-compose.yml . For Manaus to have good performance, you need to provide decent language statistics. Update the file /manaus/statistics_data/english/word_frequency.tsv with a word-frequency file with the following format: 1 you 1222421 2 I 1052546 3 to 823661 .... We have frequency file for more than 50 languages, but consider that the choice of good \"prior distribution\" of word frequency is crucial for any NLP task. Technology StarChat was design with the following goals in mind: easy deployment multi-tenancy: starchat can handle different KnowledBase and DecisionTable configurations horizontally scalability without any service interruption. modularity statelessness How does StarChat work? Workflow Components StarChat uses Elasticsearch as NoSQL database and, as said above, NLP preprocessor, for indexing, sentence cleansing, and tokenization. Services StarChat consists of the following REST resources. Root The root endpoint provides just an health check endpoint SystemIndexManagement The SystemIndexManagement set of endpoints provides a means to set up and manage the system tables. IndexManagement The IndexManagement REST endpoints allows to create new indexes for new instances (StarChat is multitenant). LanguageGuesser Offers endpoints to guess the language given a text. QuestionAnswer type (same API syntax and semantic): The following REST endpoints have the same syntax and semantic but they serve different needs. KnowledgeBase For quick setup based on real Q A logs. It stores question and answers pairs. Given a text as input it proposes the pair with the closest match on the question field. At the moment the KnowledBase supports only Analyzers implemented on Elasticsearch. PriorData The prior data contains text to be used for extraction of statistics about terms and text. The data are used primarity for terms extraction (Manaus) ConversationLogs Endpoint to collect and store the conversation logs. Tokenizer Endpoint which exposes text tokenization functionalities. Spellcheck Endpoint which exposes spellcheck functionalities, the terms statistics are taken from the KnowledgeBase. Term Endpoint to store informations about terms: synonyms, antonyms and vectorial representation. TermsExtraction Exposes Manaus functionalities to extract significant terms from the text. It need data from the PriorData and the domain specific dataset (KnowledgeBase). AnalyzersPlayground Exposes REST endpoints to test the analyzers on the fly. DecisionTable The conversational engine itself. For the usage, see below. Configuration of the DecisionTable You configure the DecisionTable through CSV file. Please have a look at the CSV provided in the doc/ directory . Fields in the configuration file are of three types: (R) : Return value: the field is returned by the API (T) : Triggers to the state: when should we enter this state? (I) : Internal: a field not exposed to the API And the fields are: state : a unique name of the state (e.g. forgot_password ) execution_order : specify an order of evaluation for analyzers the lower is the number earlier is the evaluation of the state max_state_count : defines how many times StarChat can repropose the state during a conversation. analyzer (T,I) : specify an analyzer expression which triggers the state query (T,I) : list of sentences whose meaning identify the state bubble (R) : content, if any, to be shown to the user. It may contain variables like %email% or %link%. action (R) : a function to be called on the client side. StarChat developer must provide types of input and output (like an abstract method), and the GUI developer is responsible for the actual implementation (e.g. show_button ) action_input (R) : input passed to action 's function (e.g., for show_buttons can be a list of pairs (\"text to be shown on button\", state_to_go_when_clicked) state_data (R) : a dictionary of strings with arbitrary data to pass along success_value (R) : output to return in case of success failure_value (R) : output to return in case of failure Client functions In StarChat configuration, the developer can specify which function the front-end should execute when a certain state is triggered, together with input parameters. Any function implemented on the front-end can be called. Example show button Action: show_buttons Action input: {\"buttons\": [(\"Forgot Password\", \"forgot_password\"), (\"Account locked\", \"account_locked\")]} The frontend will call function: show_buttons(buttons={\"Forgot Password\": \"forgot_password\",\"Account locked\": \"account_locked\") Example \"buttons\": the front-end implements the function show_buttons and uses \"action input\" to call it. It will show two buttons, where the first returns forgot_password and the second account_locked. Example send email Action: send_password_link Action input: { \"template\": \"Reset your password here: example.com\",\"email\": \"%email%\",\"subject\": \"New password\" } The frontend will call function: send_password_link(template=\"Reset your password here: example.com.\",email= \"john@foo.com\", subject=\"New password\") Example \"send email\": the front-end implements the function send_password_link and uses \"action input\" to call it. The variable %email% is automatically substituted by the variable email if available in the JSON passed to the StarchatResource. functions for the sample csv For the CSV in the example above, the client will have to implement the following set of functions: show_buttons: tell the client to render a multiple choice button input: a key/value pair with the key indicating the text to be shown in the button, and the value indicating the state to follow e.g.: {\"Forgot Password\": \"forgot_password\", \"Account locked\": \"account_locked\", \"Specify your problem\": \"specify_problem\", \"I want to call an operator\": \"call_operator\", \"None of the above\": \"start\"} output: the choice related to the button clicked by the user e.g.: \"account_locked\" input_form: render an input form or collect the input following a specific format input: a dictionary with the list of fields and the type of fields, at least \"email\" must be supported: e.g.: { \"email\": \"email\" } where the key is the name and the value is the type output: a dictionary with the input values e.g.: { \"email\": \"foo@example.com\" } send_password_generation_link: send an email with instructions to regenerate the password input: a valid email address e.g.: \"foo@example.com\" output: a dictionary with the response fields e.g.: { \"user_id\": \"123\", \"current_state\": \"forgot_password\", \"status\": \"true\" } Ref: sample_state_machine_specification.csv . Mechanics The client implements the functions which appear in the action field of the spreadsheet. We will provide interfaces. The client call the rest API \"decisiontable\" endpoint communicating a state if any, the user input data and other state variables The client receive a response with guidance on what to return to the user and what are the possible next steps The client render the message to the user and eventually collect the input, then call again the system to get instructions on what to do next When the \"decisiontable\" functions does not return any result the user can call the \"knowledgebase\" endpoint which contains all the conversations. Scalability StarChat consists of two different services: StarChat itself and an Elasticsearch cluster. Scaling StarChat instances Since StarChat is stateless it can scale horizontally by replication. All the instances can access to all the configured indexes on ElasticSearch and can answer to the APIs call enforcing authentication and authorization rules. A load balancer will be responsible of scheduling the requests to the instances transparently. In the diagram below, a load balancer forward requests coming from the front-end to StarChat instances which access to the indices created on the Elasticsearch cluster. Scaling Elasticsearch Similarly, Elasticsearch can easily scale horizontally adding new nodes to the cluster, as explained in Elasticsearch Documentation . Security StarChat is a backend service which supports authentication and authorization with salted SHA512 hashed password and differentiated permissions. The admin hashed password and salt are stored on the StarChat configuration file, the user credentials (hashed password, salt, permissions) are instead saved on ElasticSearch (further backend for authentication/authorization can be implemented by specialization of the Auth. classes). StarChat support TLS connections, the configuration file allow to choose if the service should expose an https connection or an http connection or both. In order to use the https connection the user must do the following things: obtain a pkcs12 server certificate from a certification authority or create a self signed certificate save the certificate inside the folder config/tls/certs/ e.g. config/tls/certs/server.p12 set the password for the certificate inside the configuration file enable the https connection setting to true the https.enable property of the configuration file optionally disable the http connection setting to false the http.enable property of the configuration file Follows the block of the configuration file which is to be modified as described above in order to use https: https { host = 0.0.0.0 host = ${?HOST} port = 8443 port = ${?PORT} certificate = server.p12 password = uma7KnKwvh enable = false } http { host = 0.0.0.0 host = ${?HOST} port = 8888 port = ${?PORT} enable = true } StarChat come with a default self-signed certificate for testing, using it for production or sensitive environment is highly discouraged as well as useless from a security point of view. Indexing terms on term table The following program index term vectors on the vector table: sbt run-main com.getjenny.command.IndexTerms --inputfile terms.txt --vecsize 300 The format for each row of an input file with 5 dimension vectors is: hello 1.0 2.0 3.0 4.0 0.0 You can use your ad-hoc trained vector model (as we do) otherwise you can use the google word2vec models trained on google news. You can find a copy of the elasticsearch index with a pre-loaded google news terms . Test Unit tests A set of unit test is available using docker-compose to set up a backend, the command to run tests is: sbt dockerComposeUp ; sbt test ; sbt dockerComposeStop test scripts with sample API calls A set of test script is present inside scripts/api_test Troubleshooting Docker: start from scratch You might want to start from scratch, and delete all docker images. If you do so ( docker images and then docker rmi -f java/elasticsearch ids ) remember that all data for the Elasticsearch docker are local, and mounted only when the container is up. Therefore you need to: cd docker-starchat rm -rf elasticsearch/data/nodes/ docker-compose: Analyzers are not loaded StarChat is started immediately after elasticsearch and it is possible that elasticsearch is not ready to respond to REST calls from StarChat (i.e. an index not found error could be raised in this case). Sample error on the logs: 2017-06-15 10:37:22,993 10:37:22.992UTC ERROR c.g.s.s.AnalyzerService(akka://starchat-service) com.getjenny.starchat.services.AnalyzerService(akka://starchat-service) - can't load analyzers: [jenny-en-0] IndexNotFoundException[no such index] In order to avoid this problem you can call the services one by one: docker-compose up elasticsearch # here wait elasticsearch is up and running docker-compose up starchat # starchat will retrieve the Analyzers from elasticsearch In alternative is possible to call the command to load/refresh the Analyzers after the docker-compose command: curl -v -H Content-Type: application/json -X POST http://localhost:8888/decisiontable_analyzer Docker: Size of virtual memory If elasticsearch complain about the size of the virtual memory: max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144] elastisearch exited with code 78 run: sysctl -w vm.max_map_count=262144","title":"Home"},{"location":"#welcome","text":"This is the official repository for StarChat --an Open Source, scalable conversational engine for B2B applications. You can find the code on our github repository .","title":"Welcome!"},{"location":"#how-to-contribute","text":"To contribute to StarChat, please send us a pull request from your fork of this repository. Our concise contribution guideline contains the bare minumum requirements of the code contributions. Before contributing (or opening issues), you might want send us an email at starchat@getjenny.com.","title":"How to contribute"},{"location":"#quick-start","text":"","title":"Quick Start"},{"location":"#requirements","text":"The easiest way is to install StarChat using two docker images. You only need: sbt docker docker compose In this way, you will put all the indices in the Elasticsearch (version 6.1) image, and StarChat itself in the Java (8) image. If you do not use docker you therefore need on your machine: Scala 12.2 Elasticsearch 5.4","title":"Requirements"},{"location":"#setup-with-docker-recommended","text":"","title":"Setup with Docker (recommended)"},{"location":"#1-launch-docker-containers","text":"We have made available all the containers needed for having StarChat up and running without local compiling. To use them, you need to download Starchat Docker or simply type: git clone https://github.com/GetJenny/starchat-docker.git Get into the starchat-docker directory and: docker-compose up -d If you get an ERROR: Version in \"./docker-compose.yml\" is unsupported. you need to update docker-compose to the version indicated in the docker-compose.yml file. Note that it might not be available on ubuntu (we need to use a very recent one). If that's the case see eg stackoverflow . Now you should have a running instance on port 8888. (If you want to change ports, eg because you have other services on 8888/9200/9300, change the values in docker-compose.yml) (Problems like elastisearch exited with code 78 ? have a look at troubleshooting !)","title":"1. Launch Docker containers"},{"location":"#change-manaus-language","text":"In the file docker-compose.yml change: command: [ /manaus/scripts/wait-for-it.sh , getjenny-es , 9200 , 5 , /manaus/bin/continuous-keywords-update , --temp_data_folder , /manaus/data , --host_map , getjenny-es=9300 , --interval_sec , 14400 , --word_frequencies , /manaus/statistics_data/english/word_frequency.tsv , --cluster_name , starchat , --index_name , jenny-en-0 ] to command: [ /manaus/scripts/wait-for-it.sh , getjenny-es , 9200 , 5 , /manaus/bin/continuous-keywords-update , --temp_data_folder , /manaus/data , --host_map , getjenny-es=9300 , --interval_sec , 14400 , --word_frequencies , /manaus/statistics_data/***italian***/word_frequency.tsv , --cluster_name , starchat , --index_name , ***jenny-it-0*** ]","title":"Change Manaus Language"},{"location":"#2-create-elasticsearch-indices","text":"Run from a terminal: # create the system indices in Elasticsearch PORT=${1:-8888} curl -v -H Authorization: Basic `echo -n 'admin:adminp4ssw0rd' | base64` \\ -H Content-Type: application/json -X POST http://localhost:${PORT}/system_index_management/create If you are using another language than English, replace english in the name of the index: # create the application indices on Elasticsearch PORT=${1:-8888} INDEX_NAME=${2:-index_getjenny_english_0} curl -v -H Authorization: Basic `echo -n 'admin:adminp4ssw0rd' | base64` \\ -H Content-Type: application/json -X POST http://localhost:${PORT}/${INDEX_NAME}/index_management/create # add a user to the system associated to the application index index_getjenny_english_0 previously created PORT=${1:-8888} curl -v -H Authorization: Basic `echo -n 'admin:adminp4ssw0rd' | base64` \\ -H Content-Type: application/json -X POST http://localhost:${PORT}/user -d '{ id : test_user , password : 3c98bf19cb962ac4cd0227142b3495ab1be46534061919f792254b80c0f3e566f7819cae73bdc616af0ff555f7460ac96d88d56338d659ebd93e2be858ce1cf9 , salt : salt , permissions : { index_getjenny_english_0 : [ read , write ] } }'","title":"2. Create Elasticsearch indices"},{"location":"#3-load-the-configuration-file","text":"Now you have to load the configuration file for the actual chat, aka decision table . We have provided an example configuration file in English , therefore: cd $STARCHAT # so we have doc/decision_table_starchat_doc.csv PORT=${1:-8888} INDEX_NAME=${2:-'index_getjenny_english_0'} FILENAME=${3:- `readlink -e doc/decision_table_starchat_doc.csv` } curl -v -H Authorization: Basic `echo -n 'test_user:p4ssw0rd' | base64` \\ --form csv=@${FILENAME} http://localhost:${PORT}/${INDEX_NAME}/decisiontable_upload_csv and then you need to index the analyzer: PORT=${1:-8888} INDEX_NAME=${2:-index_getjenny_english_0} curl -v -H Authorization: Basic `echo -n 'test_user:p4ssw0rd' | base64` \\ -H Content-Type: application/json -X POST http://localhost:${PORT}/${INDEX_NAME}/decisiontable_analyzer In case you want to delete all states previously loaded, this endpoint deletes all the states: PORT=${1:-8888} INDEX_NAME=${2:-index_getjenny_english_0} curl -v -H Authorization: Basic `echo -n 'test_user:p4ssw0rd' | base64` \\ -H Content-Type: application/json -X DELETE http://localhost:${PORT}/${INDEX_NAME}/decisiontable","title":"3. Load the configuration file"},{"location":"#4-load-external-corpus-optional","text":"To have a good words' statistics, and consequent improved matching, you might want to index a corpus which is hidden from results. For instance, you can index various sentences as hidden using the POST /knowledgebase endpoint with doctype: \"hidden\" .","title":"4. Load external corpus (optional)"},{"location":"#5-index-the-faqs-optional","text":"TODO: You might want to activate the knowledge base for simple Question and Anwer.","title":"5. Index the FAQs (optional)"},{"location":"#install-without-docker","text":"Note: we do not support this installation. Clone the repository and enter the starchat directory. Initialize the Elasticsearch instance (see above for Docker) Run the service: sbt compile run The service binds on the port 8888 by default.","title":"Install without Docker"},{"location":"#install-local-docker-for-testing-branches","text":"Generate a packet distribution. In StarChat directory: sbt dist Enter the directory docker-starchat: cd docker-starchat You will get a message like Your package is ready in ...../target/universal/starchat-4ee.... .zip . Extract the packet into the docker-starchat folder: unzip ../target/universal/starchat-4eee.....zip ln -s starchat-4ee..../ starchat The zip packet contains: a set of scripts to test the endpoints and as a complement for the documentation: starchat/scripts/api_test/ a set of command line programs starchat/bin to run starchat and other tools. delete-decision-table: application to delete items from the decision table index-corpus-on-knowledge-base: application to index a corpus on knowledge base as hidden (to improve the language model) index-decision-table: application to index data on the decision table from a csv index-knowledge-base: application to index data into the knowledge base index-terms: application to index terms vectors starchat: start starchat Review the configuration files starchat/config/application.conf and configure the language if needed (by default you have index_language = \"english\" ) (If you are re-installing StarChat, and want to start from scratch see start from scratch .) Start both startchat and elasticsearch: docker-compose up -d (Problems like elastisearch exited with code 78 ? have a look at troubleshooting !)","title":"Install local Docker (for testing branches)"},{"location":"#test-the-installation","text":"Is the service working? But first: did you load a configuration file ? If yes, try: curl -X GET localhost:8888 | python -mjson.tool Get the test_state PORT=${2:-8888} INDEX_NAME=${3:-index_getjenny_english_0} curl -v -H Authorization: Basic `echo -n 'test_user:p4ssw0rd' | base64` \\ -H Content-Type: application/json -X POST http://localhost:${PORT}/${INDEX_NAME}/get_next_response -d '{ conversation_id : 1234 , user_input : { text : install starchat }, values : { return_value : , data : {} } }' You should get: [ { state : install , data : {}, action : , success_value : , state_data : {}, score : 1, conversation_id : 1234 , traversed_states : [ install ], max_state_count : 0, action_input : {}, analyzer : band(bor(keyword(\\ setup\\ ), keyword(\\ install.*\\ )), bnot(bor(keyword(\\ standalone\\ ), keyword(\\ docker\\ )))) , bubble : Just choose one of the two:\\n ul \\n li docker install (recommended) /li \\n li standalone install /li \\n /ul , failure_value : } ] If you look at the \"analyzer\" field, you'll see that this state is triggered when the user types the test and either get or send . Try with \"text\": \"Please dont send me the test state\" and StarChat will send an empty message.","title":"Test the installation"},{"location":"#configuration-of-the-chatbot-decision-table","text":"With StarChat's Decision Table you can easily implement workflow-based chatbots. After the installation (see above) you only have to configure a conversation flow and eventually a front-end client.","title":"Configuration of the chatbot (Decision Table)"},{"location":"#nlp-processing","text":"NLP processing is of course the core of any chatbot. As you have noted in the CSV provided in the doc/ directory there are two fields defining when StarChat should trigger a state - analyzer and queries .","title":"NLP processing"},{"location":"#queries","text":"If the analyzer field is empty, StarChat will query Elasticsearch for the state containing the most similar sentence in the field queries . We have carefully configured Elasticsearch in order to provide good answers (e.g. boosting results where the same words appear etc), and results are... acceptable. But you are encouraged to use the analyzer field, documented below.","title":"Queries"},{"location":"#analyzer","text":"The analyzers are a Domain Specific Language which allow to put together various functions using logical operators. Through the analyzers , you can leverage on various NLP algorithms included in StarChat and combine the results of those algorithms with other rules. For instance you might want to get into the state which asks for the email only if a variable \"email\" is not set. Or you want to escalate to a human operator after you detect swearing for three times. Or you want to escalate only on working days. You can do all that with the analyzers . We can have a look at the simple example included in the CSV provided in the doc/ directory for the state forgot_password : booleanAnd(keyword( password ),booleanOr(keyword( reset ),keyword( forgot ))) The analyzer above says the state must be triggered if the term \"password\" is detected together with either \"reset\" or \"forgot\". Another example. Imagine we have a state called send-updates . In this state StarChat proposes the question \"Where can we send you updates?\". In the config file: state | ... | bubble | ... send-updates | ... | Where can we send you updates? | In another state, called send-email , we have the anlyzer field with: booleanAnd(lastTravStateIs( send-updates ), matchEmailAddress( verification_ )) this means send-email will be triggered only after send-updates (because of lastTravStateIs ) and if an email address is detected (because of matchEmailAddress ). This will also set the variable verification_email because the expression matchEmailAddress in case of success always sets such variable, with the expression's argument as prefix. In addition to that, the expression sendVerificationEmail could be developed (we haven't) which accepts others arguments, for example: sendVerificationEmail(\"verification_\", \"Email about Verification\", \"Here is your verification link %__temp__verification_link%) In this case, the expression would extract an email address from the user's query set a variable verification_email with such address retrieve a verification link from some API put that link into the temporary variable __temp__verification_link . send an email with subject \"Email about Verification\" and body \"Here is your...\" return 1 in case of success TODO It is fundamental here to build a set of metadata which allows any other component to receive all needed information about the analyzer. For instance, the sendVerificationEmail could have something like: [ documentation : Send an email with subject and body. If successful returns 1.0 and sets the variables. If not returns 0 and does not set the variables. argument_list : [ 'prefix' of the variable 'prefix_email' , Subject of the email to be sent , Body of the mail ], created_variables : { // Variables it creates __temp__verification_link : Link provided by the brand's API , //will after usage because starts with __temp__ prefix_email : email address }, used_variables : { // Variables it expects to find in the state (none here) }","title":"Analyzer"},{"location":"#how-the-analyzers-are-organized","text":"The analyzer DSL building blocks are the expression . For instance, or , and , keyword are all expressions . Espressions are then divided into operators ( or ...) and atoms ( keyword ).","title":"How the analyzers are organized"},{"location":"#expressions-atoms","text":"Presently, the keyword(\"reset\") in the example provides a very simple score: occurrence of the word reset in the user's query divided by the total number of words. If evaluated agains the sentence \"Want to reset my password\", keyword(\"reset\") will currently return 0.2. TODO : This is just a temporary score used while our NLP library manaus is not integrated into the decision table. These are currently the expression you can use to evaluate the goodness of a query (see DefaultFactoryAtomic and StarchatFactoryAtomic : keyword(\"pass.*\") : as explained above, detects any word starting with \"pass\". Normalized. regex(regex) : evaluate a regular expression, not normalized search(state-name) : take a state name as argument, queries elastic search and returns the score of the most similar query in the field queries of the argument's state. In other words, it does what it would do without any analyzer, only with a normalized score -e.g. search(\"lost_password_state\") matchPatternRegex(regex) : A generic pattern extraction analyzer, it extract named patterns matching a given regex e.g. the following will match tree numbers separated by semicolumn: [first,second,third](?:([0-9]+:[0-9]:[0-9]+) if the regex matches it will create the entries into the state variables dictionary e.g.: 10:11:12 will result in Map(\"first.0\" - \"10\", \"second.0\" - \"11\", \"third.0\" - \"12\") the number at the end of the name is an index incremented for multiple occurrences of the pattern in the query matchDateDDMMYYYY(prefix) : parse a date in DDMMYYYY format and set prefixday.0 , prefixmonth.0 , prefixyear.0 . existsVariable(variable-name) : check whether a variable exists or not hasTravState(state-name) : check if a state_name is present into the history of traversed states lastTravStateIs(state-name) : check if the last traversed state is state_name prevTravStateIs(state-name) : check if the last but one traversed state is state_name distance(\"forget. \", ..., \"pass. \") : score based on the (cosine) distance between the query and the list of words in the argument. checkDayOfMonth : Check if the current time is Equal, LessOrEqual, Less, Greater, GreaterOrEqual to the argument which is an integer between 1 and 31 first argument is the day of the month: a number between 1 and 31 second argument is the operator: any of Equal, LessOrEqual, Less, Greater, GreaterOrEqual third argument is the timezone: UTC, GMT, UT, CET, UTC+ , UTC- , GMT+ , GMT- , UT+ or UT- where N is a number between -18 and +18. Default is CET checkDayOfWeek : Check if the current time is Equal, LessOrEqual, Less, Greater, GreaterOrEqual to the argument which is an integer between 1 (MONDAY) and 7 (SUNDAY) first argument is the day of the week: a number between 1 and 7 second argument is the operator: any of Equal, LessOrEqual, Less, Greater, GreaterOrEqual third argument is the timezone: UTC, GMT, UT, CET, UTC+ , UTC- , GMT+ , GMT- , UT+ or UT- where N is a number between -18 and +18. Default is CET checkHour : Check if the current time is Equal, LessOrEqual, Less, Greater, GreaterOrEqual to the argument time in EPOC first argument is the hour: a number between 0 and 23 second argument is the operator: any of Equal, LessOrEqual, Less, Greater, GreaterOrEqual third argument is the timezone: UTC, GMT, UT, CET, UTC+ , UTC- , GMT+ , GMT- , UT+ or UT- where N is a number between -18 and +18. Default is CET checkMinute : Check if the current minutes are Equal, LessOrEqual, Less, Greater, GreaterOrEqual to the first argument first argument is the minute: a number between 0 and 59 second argument is the operator: any of Equal, LessOrEqual, Less, Greater, GreaterOrEqual third argument is the timezone: UTC, GMT, UT, CET, UTC+ , UTC- , GMT+ , GMT- , UT+ or UT- where N is a number between -18 and +18. Default is CET checkMonth : Check if the current month is Equal, LessOrEqual, Less, Greater, GreaterOrEqual to the argument which is an integer between 1 (JANUARY) and 12 (DECEMBER) first argument is the month's number: an integer between 1 and 12 second argument is the operator: any of Equal, LessOrEqual, Less, Greater, GreaterOrEqual third argument is the timezone: UTC, GMT, UT, CET, UTC+ , UTC- , GMT+ , GMT- , UT+ or UT- where N is a number between -18 and +18. Default is CET checkTimestamp : Check if the current time is Equal, LessOrEqual, Less, Greater, GreaterOrEqual to the argument time in EPOC first argument is the timestamp: a timestamp in EPOC (in seconds) second argument is the operator: any of Equal, LessOrEqual, Less, Greater, GreaterOrEqual double : transform a string into a double, useful for score comparison (see, eq, lt, gt, lte, gte operators)","title":"Expressions: Atoms"},{"location":"#expressions-operators","text":"Operators evaluate the output of one or more expression and return a value. Currently, the following operators are implemented (the the source code ): boolean or : calles matches of all the exprassions it contains and returns true or false. It can be called using bor boolean and : as above, it's called with band boolean not : ditto, bnot conjunction : if the evaluation of the expressions it contains is normalized, and they can be seen as probabilities of them being true, this is the probability that all the expressions are all true ( P(A)*P(B) ) disjunction : as above, the probability that at least one is true ( 1-(1-P(A))*(1-P(B)) ) max : takes the max score of returned by the expression arguments reinfConjunction : conjuction which uses a 1.1 value instead of 1 as boolean true binarize : take the result of an expression output 1.0 if the score is 0, 0.0 otherwise eq compare the score of two expression, output 1.0 if they are the same, 0.0 otherwise lt compare the score of two expression, output 1.0 if the first arg is less than the second, 0.0 otherwise gt compare the score of two expression, output 1.0 if the first arg is greater than the second, 0.0 otherwise lte compare the score of two expression, output 1.0 if the first arg is less or equal than the second, 0.0 otherwise gte compare the score of two expression, output 1.0 if the first arg is greater or equal than the second, 0.0 otherwise","title":"Expressions: Operators"},{"location":"#technical-corner-expressions","text":"Expressions , like keywords in the example, are called atoms , and have the following methods/members: def evaluate(query: String): Double : produce a score. It might be normalized to 1 or not (set val isEvaluateNormalized: Boolean accordingly) val match_threshold This is the threshold above which the expression is considered true when matches is called. NB The default value is 0.0, which is normally not ideal. def matches(query: String): Boolean : calles evaluate and check agains the threshold... val rx : the name of the atom, as it should be used in the analyzer field.","title":"Technical corner: expressions"},{"location":"#configuration-of-the-answer-recommender-knowledge-base","text":"Through the /knowledgebase endpoint you can add, edit and remove pairs of question and answers used by StarChat to recommend possible answers when a question arrives. Documents containing Q A must be structured like that: { id : 0 , // id of the pair conversation : id:1000 , // id of the conversation. This can be useful to external services index_in_conversation : 1, // when the pair appears inside the conversation, as above question : thank you , // The question to be matched answer : you are welcome! , // The answer to be recommended question_scored_terms : [ // A list of keyword and score. You can use your own keyword extractor or our Manaus (see later) [ thank , 1.9 ] ], verified : true, // A variable used in some call centers topics : t1 t2 , // Eventual topics to be associated dclass : , // Optional field as a searchable class for answer doctype : normal , state : , status : 0 } See POST /knowledgebase for an example with curl . Other calls ( GET, DELETE, PUT ) are used to get the state, delete it or update it.","title":"Configuration of the answer recommender (Knowledge Base)"},{"location":"#test-the-knowledge-base","text":"Just run the example in POST /knowledgebase_search .","title":"Test the knowledge base"},{"location":"#manaus","text":"In the Q A pair above you saw the field question_scored_terms . Having good keywords improves enormously the quality of the answer. You can of course put them by hand, or run a software which extracts the keywords from the question. If you prefer the latter, but don't have any, we provide Manaus . Manaus is still under development, but it's already included in the Docker's installation of StarChat. When you launch docker-compose up -d , you also launch a container with Manaus which analyzes all the Q A in the Knowledge Base, produces keywords and updates the field question_scored_terms for all documents. The process is repeated evert 4 hour.","title":"Manaus"},{"location":"#manaus-configuration","text":"Have a look at the file docker-starchat/docker-compose.yml . For Manaus to have good performance, you need to provide decent language statistics. Update the file /manaus/statistics_data/english/word_frequency.tsv with a word-frequency file with the following format: 1 you 1222421 2 I 1052546 3 to 823661 .... We have frequency file for more than 50 languages, but consider that the choice of good \"prior distribution\" of word frequency is crucial for any NLP task.","title":"Manaus configuration"},{"location":"#technology","text":"StarChat was design with the following goals in mind: easy deployment multi-tenancy: starchat can handle different KnowledBase and DecisionTable configurations horizontally scalability without any service interruption. modularity statelessness","title":"Technology"},{"location":"#how-does-starchat-work","text":"","title":"How does StarChat work?"},{"location":"#workflow","text":"","title":"Workflow"},{"location":"#components","text":"StarChat uses Elasticsearch as NoSQL database and, as said above, NLP preprocessor, for indexing, sentence cleansing, and tokenization.","title":"Components"},{"location":"#services","text":"StarChat consists of the following REST resources.","title":"Services"},{"location":"#root","text":"The root endpoint provides just an health check endpoint","title":"Root"},{"location":"#systemindexmanagement","text":"The SystemIndexManagement set of endpoints provides a means to set up and manage the system tables.","title":"SystemIndexManagement"},{"location":"#indexmanagement","text":"The IndexManagement REST endpoints allows to create new indexes for new instances (StarChat is multitenant).","title":"IndexManagement"},{"location":"#languageguesser","text":"Offers endpoints to guess the language given a text.","title":"LanguageGuesser"},{"location":"#questionanswer-type-same-api-syntax-and-semantic","text":"The following REST endpoints have the same syntax and semantic but they serve different needs.","title":"QuestionAnswer type (same API syntax and semantic):"},{"location":"#knowledgebase","text":"For quick setup based on real Q A logs. It stores question and answers pairs. Given a text as input it proposes the pair with the closest match on the question field. At the moment the KnowledBase supports only Analyzers implemented on Elasticsearch.","title":"KnowledgeBase"},{"location":"#priordata","text":"The prior data contains text to be used for extraction of statistics about terms and text. The data are used primarity for terms extraction (Manaus)","title":"PriorData"},{"location":"#conversationlogs","text":"Endpoint to collect and store the conversation logs.","title":"ConversationLogs"},{"location":"#tokenizer","text":"Endpoint which exposes text tokenization functionalities.","title":"Tokenizer"},{"location":"#spellcheck","text":"Endpoint which exposes spellcheck functionalities, the terms statistics are taken from the KnowledgeBase.","title":"Spellcheck"},{"location":"#term","text":"Endpoint to store informations about terms: synonyms, antonyms and vectorial representation.","title":"Term"},{"location":"#termsextraction","text":"Exposes Manaus functionalities to extract significant terms from the text. It need data from the PriorData and the domain specific dataset (KnowledgeBase).","title":"TermsExtraction"},{"location":"#analyzersplayground","text":"Exposes REST endpoints to test the analyzers on the fly.","title":"AnalyzersPlayground"},{"location":"#decisiontable","text":"The conversational engine itself. For the usage, see below.","title":"DecisionTable"},{"location":"#configuration-of-the-decisiontable","text":"You configure the DecisionTable through CSV file. Please have a look at the CSV provided in the doc/ directory . Fields in the configuration file are of three types: (R) : Return value: the field is returned by the API (T) : Triggers to the state: when should we enter this state? (I) : Internal: a field not exposed to the API And the fields are: state : a unique name of the state (e.g. forgot_password ) execution_order : specify an order of evaluation for analyzers the lower is the number earlier is the evaluation of the state max_state_count : defines how many times StarChat can repropose the state during a conversation. analyzer (T,I) : specify an analyzer expression which triggers the state query (T,I) : list of sentences whose meaning identify the state bubble (R) : content, if any, to be shown to the user. It may contain variables like %email% or %link%. action (R) : a function to be called on the client side. StarChat developer must provide types of input and output (like an abstract method), and the GUI developer is responsible for the actual implementation (e.g. show_button ) action_input (R) : input passed to action 's function (e.g., for show_buttons can be a list of pairs (\"text to be shown on button\", state_to_go_when_clicked) state_data (R) : a dictionary of strings with arbitrary data to pass along success_value (R) : output to return in case of success failure_value (R) : output to return in case of failure","title":"Configuration of the DecisionTable"},{"location":"#client-functions","text":"In StarChat configuration, the developer can specify which function the front-end should execute when a certain state is triggered, together with input parameters. Any function implemented on the front-end can be called.","title":"Client functions"},{"location":"#example-show-button","text":"Action: show_buttons Action input: {\"buttons\": [(\"Forgot Password\", \"forgot_password\"), (\"Account locked\", \"account_locked\")]} The frontend will call function: show_buttons(buttons={\"Forgot Password\": \"forgot_password\",\"Account locked\": \"account_locked\") Example \"buttons\": the front-end implements the function show_buttons and uses \"action input\" to call it. It will show two buttons, where the first returns forgot_password and the second account_locked.","title":"Example show button"},{"location":"#example-send-email","text":"Action: send_password_link Action input: { \"template\": \"Reset your password here: example.com\",\"email\": \"%email%\",\"subject\": \"New password\" } The frontend will call function: send_password_link(template=\"Reset your password here: example.com.\",email= \"john@foo.com\", subject=\"New password\") Example \"send email\": the front-end implements the function send_password_link and uses \"action input\" to call it. The variable %email% is automatically substituted by the variable email if available in the JSON passed to the StarchatResource.","title":"Example send email"},{"location":"#functions-for-the-sample-csv","text":"For the CSV in the example above, the client will have to implement the following set of functions: show_buttons: tell the client to render a multiple choice button input: a key/value pair with the key indicating the text to be shown in the button, and the value indicating the state to follow e.g.: {\"Forgot Password\": \"forgot_password\", \"Account locked\": \"account_locked\", \"Specify your problem\": \"specify_problem\", \"I want to call an operator\": \"call_operator\", \"None of the above\": \"start\"} output: the choice related to the button clicked by the user e.g.: \"account_locked\" input_form: render an input form or collect the input following a specific format input: a dictionary with the list of fields and the type of fields, at least \"email\" must be supported: e.g.: { \"email\": \"email\" } where the key is the name and the value is the type output: a dictionary with the input values e.g.: { \"email\": \"foo@example.com\" } send_password_generation_link: send an email with instructions to regenerate the password input: a valid email address e.g.: \"foo@example.com\" output: a dictionary with the response fields e.g.: { \"user_id\": \"123\", \"current_state\": \"forgot_password\", \"status\": \"true\" } Ref: sample_state_machine_specification.csv .","title":"functions for the sample csv"},{"location":"#mechanics","text":"The client implements the functions which appear in the action field of the spreadsheet. We will provide interfaces. The client call the rest API \"decisiontable\" endpoint communicating a state if any, the user input data and other state variables The client receive a response with guidance on what to return to the user and what are the possible next steps The client render the message to the user and eventually collect the input, then call again the system to get instructions on what to do next When the \"decisiontable\" functions does not return any result the user can call the \"knowledgebase\" endpoint which contains all the conversations.","title":"Mechanics"},{"location":"#scalability","text":"StarChat consists of two different services: StarChat itself and an Elasticsearch cluster.","title":"Scalability"},{"location":"#scaling-starchat-instances","text":"Since StarChat is stateless it can scale horizontally by replication. All the instances can access to all the configured indexes on ElasticSearch and can answer to the APIs call enforcing authentication and authorization rules. A load balancer will be responsible of scheduling the requests to the instances transparently. In the diagram below, a load balancer forward requests coming from the front-end to StarChat instances which access to the indices created on the Elasticsearch cluster.","title":"Scaling StarChat instances"},{"location":"#scaling-elasticsearch","text":"Similarly, Elasticsearch can easily scale horizontally adding new nodes to the cluster, as explained in Elasticsearch Documentation .","title":"Scaling Elasticsearch"},{"location":"#security","text":"StarChat is a backend service which supports authentication and authorization with salted SHA512 hashed password and differentiated permissions. The admin hashed password and salt are stored on the StarChat configuration file, the user credentials (hashed password, salt, permissions) are instead saved on ElasticSearch (further backend for authentication/authorization can be implemented by specialization of the Auth. classes). StarChat support TLS connections, the configuration file allow to choose if the service should expose an https connection or an http connection or both. In order to use the https connection the user must do the following things: obtain a pkcs12 server certificate from a certification authority or create a self signed certificate save the certificate inside the folder config/tls/certs/ e.g. config/tls/certs/server.p12 set the password for the certificate inside the configuration file enable the https connection setting to true the https.enable property of the configuration file optionally disable the http connection setting to false the http.enable property of the configuration file Follows the block of the configuration file which is to be modified as described above in order to use https: https { host = 0.0.0.0 host = ${?HOST} port = 8443 port = ${?PORT} certificate = server.p12 password = uma7KnKwvh enable = false } http { host = 0.0.0.0 host = ${?HOST} port = 8888 port = ${?PORT} enable = true } StarChat come with a default self-signed certificate for testing, using it for production or sensitive environment is highly discouraged as well as useless from a security point of view.","title":"Security"},{"location":"#indexing-terms-on-term-table","text":"The following program index term vectors on the vector table: sbt run-main com.getjenny.command.IndexTerms --inputfile terms.txt --vecsize 300 The format for each row of an input file with 5 dimension vectors is: hello 1.0 2.0 3.0 4.0 0.0 You can use your ad-hoc trained vector model (as we do) otherwise you can use the google word2vec models trained on google news. You can find a copy of the elasticsearch index with a pre-loaded google news terms .","title":"Indexing terms on term table"},{"location":"#test","text":"","title":"Test"},{"location":"#unit-tests","text":"A set of unit test is available using docker-compose to set up a backend, the command to run tests is: sbt dockerComposeUp ; sbt test ; sbt dockerComposeStop","title":"Unit tests"},{"location":"#test-scripts-with-sample-api-calls","text":"A set of test script is present inside scripts/api_test","title":"test scripts with sample API calls"},{"location":"#troubleshooting","text":"","title":"Troubleshooting"},{"location":"#docker-start-from-scratch","text":"You might want to start from scratch, and delete all docker images. If you do so ( docker images and then docker rmi -f java/elasticsearch ids ) remember that all data for the Elasticsearch docker are local, and mounted only when the container is up. Therefore you need to: cd docker-starchat rm -rf elasticsearch/data/nodes/","title":"Docker: start from scratch"},{"location":"#docker-compose-analyzers-are-not-loaded","text":"StarChat is started immediately after elasticsearch and it is possible that elasticsearch is not ready to respond to REST calls from StarChat (i.e. an index not found error could be raised in this case). Sample error on the logs: 2017-06-15 10:37:22,993 10:37:22.992UTC ERROR c.g.s.s.AnalyzerService(akka://starchat-service) com.getjenny.starchat.services.AnalyzerService(akka://starchat-service) - can't load analyzers: [jenny-en-0] IndexNotFoundException[no such index] In order to avoid this problem you can call the services one by one: docker-compose up elasticsearch # here wait elasticsearch is up and running docker-compose up starchat # starchat will retrieve the Analyzers from elasticsearch In alternative is possible to call the command to load/refresh the Analyzers after the docker-compose command: curl -v -H Content-Type: application/json -X POST http://localhost:8888/decisiontable_analyzer","title":"docker-compose: Analyzers are not loaded"},{"location":"#docker-size-of-virtual-memory","text":"If elasticsearch complain about the size of the virtual memory: max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144] elastisearch exited with code 78 run: sysctl -w vm.max_map_count=262144","title":"Docker: Size of virtual memory"},{"location":"about/","text":"GetJenny GetJenny , the company behind StarChat, is a Finnish startup which provides automated systems for customer services. Through StarChat, GetJenny provides the backend engine able to manage conversations or to recommend answers based on past conversations and integrate it into its customers' brand-to-consumer communication platform. Although all the integration software is closed source, the backend, StarChat, is open source. People can download, modify and use it. Try it at git.io/*chat !","title":"About"},{"location":"about/#getjenny","text":"GetJenny , the company behind StarChat, is a Finnish startup which provides automated systems for customer services. Through StarChat, GetJenny provides the backend engine able to manage conversations or to recommend answers based on past conversations and integrate it into its customers' brand-to-consumer communication platform. Although all the integration software is closed source, the backend, StarChat, is open source. People can download, modify and use it. Try it at git.io/*chat !","title":"GetJenny"},{"location":"apis/","text":"APIs the api's are now documented using swagger , the documentation below is obsolete and will be deleted after the release of the version v5.0.0 SystemIndexManagement POST /system_index_management/create Create a new system index, this operation init. a new system index and is required to start using starchat. Output JSON Requirements The function requires \"admin\" credentials Sample call PORT= ${1:-8888} curl -v -H Authorization: Basic `echo -n 'admin:adminp4ssw0rd' | base64` \\ -H Content-Type: application/json -X POST http://localhost:${PORT}/system_index_management/create Sample response: { message : IndexCreation: user(starchat_system_0.user, true) refresh_decisiontable(starchat_system_0.refresh_decisiontable, true) } GET /system_index_management Fetch and returns the informations about the system index Output JSON Requirements The function requires \"admin\" credentials Sample call PORT= ${1:-8888} curl -v -H Authorization: Basic `echo -n 'admin:adminp4ssw0rd' | base64` \\ -H Content-Type: application/json -X GET http://localhost:${PORT}/system_index_management Sample response: { message : IndexCheck: user(starchat_system_0.user, true) refresh_decisiontable(starchat_system_0.refresh_decisiontable, true) } DELETE /system_index_management Delete a system index, this operation destroy any user created Output JSON Requirements The function requires \"admin\" credentials Sample call PORT= ${1:-8888} curl -v -H Authorization: Basic `echo -n 'admin:adminp4ssw0rd' | base64` \\ -H Content-Type: application/json -X DELETE http://localhost:${PORT}/system_index_management Sample response: { message : IndexDeletion: user(starchat_system_0.user, true) refresh_decisiontable(starchat_system_0.refresh_decisiontable, true) } User POST /user Insert a new user to the system, the user record can be generated using the '/user_gen/test_user' endpoint Output JSON Requirements The function requires \"admin\" credentials Sample call PORT= ${1:-8888} curl -v -H Authorization: Basic `echo -n 'admin:adminp4ssw0rd' | base64` \\ -H Content-Type: application/json -X POST http://localhost:${PORT}/user -d '{ id : test_user , password : 3c98bf19cb962ac4cd0227142b3495ab1be46534061919f792254b80c0f3e566f7819cae73bdc616af0ff555f7460ac96d88d56338d659ebd93e2be858ce1cf9 , salt : salt , permissions : { index_getjenny_english_0 : [ read , write ] } }' Sample response: { version : 1, created : true, index : starchat_system_0.user , dtype : user , id : test_user } GET /user Fetch the informations about a user Output JSON Requirements The function requires \"admin\" credentials Sample call PORT= ${1:-8888} USERNAME=${2:- admin } curl -v -H Authorization: Basic `echo -n 'admin:adminp4ssw0rd' | base64` \\ -H Content-Type: application/json -X GET http://localhost:${PORT}/user/${USERNAME} Sample response: { permissions : { admin : [ admin ] }, salt : salt2 , id : admin , password : ce822ea3bd2ac45ed908f0fac0c81d95df7e59ad554ebed5e173113f5fb97a6c585803233136dd6b16b02742f50dd8cff6fac97ff827394e694f63198618e02c } PUT /user Update a user record Output JSON Requirements The function requires \"admin\" credentials Sample call PORT= ${1:-8888} curl -v -H Authorization: Basic `echo -n 'admin:adminp4ssw0rd' | base64` \\ -H Content-Type: application/json -X PUT http://localhost:${PORT}/user/test_user -d '{ permissions : { index_getjenny_english_0 : [ read ] } }' Sample response: { version : 2, created : false, dtype : user , index : starchat_system_0.user , id : test_user } DELETE /user/user_id Delete an existing user Output JSON Requirements The function requires \"admin\" credentials Sample call PORT= ${1:-8888} curl -v -H Authorization: Basic `echo -n 'admin:adminp4ssw0rd' | base64` \\ -H Content-Type: application/json -X DELETE http://localhost:${PORT}/user/test_user Sample response: { version : 10, dtype : user , id : test_user , index : starchat_system_0.user , found : true } POST /user_gen/test_user Generate the record for a user with hashed password and a randomly generated salt. The user must be then inserted into the system. Output JSON Requirements The function requires \"admin\" credentials Sample call PORT=${1:-8888} curl -v -H Authorization: Basic `echo -n 'admin:adminp4ssw0rd' | base64` \\ -H Content-Type: application/json -X POST http://localhost:${PORT}/user_gen/test_user -d '{ password : plain text password , permissions : { index_getjenny_english_0 : [ read ], index_finnish_1 : [ read , write ] } }' Sample response: { password : d4cc0586d5d9116e755f5011d2c03e627821c2596820236ef230ff094176586d05fbfa98a198aaa08935df2849196d2648012f1e40ff2e40ca8c3f627b41e9db , salt : qoKJUyUwpvWM53PI , id : test_user , permissions : { index_finnish_1 : [ read , write ], index_getjenny_english_0 : [ read ] } } DecisionTable POST /get_next_response Tell StarChat about the user actions (wrote something, clicked a button etc) and receives instruction about the next state. Data to post: { conversation_id : 1234 , user_input : { text : the text typed by the user }, // optional values : { return_value : the value either in success_value or in failure_value (Optional) , data : {} // all the variables, e.g. for the STRING TEMPLATEs (Optional) }, threshold : 0.0, // the minimum match threshold max_results : 4 // the max number of result to return } Requirements Index must exists The function requires user credentials with read permissions on the index Return codes 200 Similar Json, see examples below Example 1 User input is \"how to install starchat\": QUERY=${1:- how to install starchat } PORT=${2:-8888} INDEX_NAME=${3:-index_getjenny_english_0} curl -v -H Authorization: Basic `echo -n 'test_user:p4ssw0rd' | base64` \\ -H Content-Type: application/json -X POST http://localhost:${PORT}/${INDEX_NAME}/get_next_response -d { \\ conversation_id\\ : \\ 1234\\ , \\ user_input\\ : { \\ text\\ : \\ ${QUERY}\\ }, \\ values\\ : { \\ return_value\\ : \\ \\ , \\ data\\ : {\\ varname1\\ : \\ value1\\ , \\ varname2\\ : \\ value2\\ } }, \\ threshold\\ : 0.0, \\ max_results\\ : 4 } returns: [ { bubble : Just choose one of the two:\\n ul \\n li docker install (recommended) /li \\n li standalone install /li \\n /ul , analyzer : band(bor(keyword(\\ setup\\ ), keyword(\\ install.*\\ )), bnot(bor(keyword(\\ standalone\\ ), keyword(\\ docker\\ )))) , state_data : {}, data : { varname1 : value1 , varname2 : value2 }, failure_value : , state : install , traversed_states : [ install ], conversation_id : 1234 , action : , action_input : {}, score : 1, max_state_count : 0, success_value : } ] Example 2 User input is: \"how can I contribute to starchat?\" QUERY=${1:- how can I contribute to starchat? } PORT=${2:-8888} INDEX_NAME=${3:-index_getjenny_english_0} curl -v -H Authorization: Basic `echo -n 'test_user:p4ssw0rd' | base64` \\ -H Content-Type: application/json -X POST http://localhost:${PORT}/${INDEX_NAME}/get_next_response -d { \\ conversation_id\\ : \\ 1234\\ , \\ user_input\\ : { \\ text\\ : \\ ${QUERY}\\ }, \\ values\\ : { \\ return_value\\ : \\ \\ , \\ data\\ : {\\ varname1\\ : \\ value1\\ , \\ varname2\\ : \\ value2\\ } }, \\ threshold\\ : 0.0, \\ max_results\\ : 4 } and gets: [ { analyzer : bor(keyword(\\ contribute\\ )) , state_data : {}, data : { varname2 : value2 , varname1 : value1 }, traversed_states : [ contribute ], conversation_id : 1234 , bubble : To contribute to a href=\\ http://git.io/*chat\\ StarChat /a , please send us a pull request from your fork of this repository.\\n br Our concise contribution guideline contains the bare minimum requirements of the code contributions.\\n br Before contributing (or opening issues), you might want to email us at starchat@getjenny.com. , action : , state : contribute , max_state_count : 0, score : 1, failure_value : , action_input : {}, success_value : } ] 204 No response was found 500 (error) Internal server error 400 (error) Bad request: meaning: the input data structure is not valid output data: no data returned 422 (error) meaning: bad request data, the input data is formally valid but there is some issue with data interpretation output data: the output data structure is a json dictionary with two fields: code and message. The following code are supported: code: 100 message: \"error evaluating the template strings, bad values\" 404 (error) meaning: not found output data: no data returned GET /decisiontable Get a document by ID Output JSON Requirements Index must exists The function requires user credentials with read permissions on the index Return codes 200 Sample call # retrieve one or more entries with given ids; ids can be specified multiple times PORT=${1:-8888} INDEX_NAME=${2:-index_getjenny_english_0} # retrieve one or more entries with given ids; ids can be specified multiple times curl -v -H Authorization: Basic `echo -n 'test_user:p4ssw0rd' | base64` \\ -H Content-Type: application/json http://localhost:${PORT}/${INDEX_NAME}/decisiontable?ids=further_details_access_question Sample output { total : 1, hits : [ { document : { failure_value : dont_understand , state : further_details_access_question , bubble : Can you specify which of the following problems you have? [NB works only if buttons can be shown!] , success_value : eval(show_buttons) , action_input : { I want to call an operator : call_operator , Forgot Password : forgot_password , Specify your problem : specify_problem , None of the above : start , Account locked : account_locked }, max_state_count : 0, analyzer : or(and(or(keyword(\\ problem.*\\ ),keyword(\\ issue.*\\ ),keyword(\\ trouble.*\\ )),keyword(\\ account\\ ))) , queries : [ cannot access account , problem access account ], action : show_buttons , state_data : { verification : did you mean you can't access to your account? }, execution_order : 1 }, score : 0 } ], max_score : 0 } PUT /decisiontable Output JSON Requirements Index must exists The function requires user credentials with read permissions on the index Return codes 201 Sample call # update the further_details_access_question entry in the DT PORT=${1:-8888} INDEX_NAME=${2:-index_getjenny_english_0} # update the further_details_access_question entry in the DT curl -v -H Authorization: Basic `echo -n 'test_user:p4ssw0rd' | base64` \\ -H Content-Type: application/json -X PUT http://localhost:${PORT}/${INDEX_NAME}/decisiontable/further_details_access_question -d '{ queries : [ cannot access account , problem access account , unable to access to my account , completely forgot my password ] }' Sample output { dtype : state , created : false, index : index_getjenny_english_0.state , version : 2, id : further_details_access_question } POST /decisiontable Insert a new document. Output JSON Requirements Index must exists The function requires user credentials with write permissions on the index Return codes 201 Sample call PORT=${1:-8888} INDEX_NAME=${2:-index_getjenny_english_0} curl -v -H Authorization: Basic `echo -n 'test_user:p4ssw0rd' | base64` \\ -H Content-Type: application/json -X POST http://localhost:${PORT}/${INDEX_NAME}/decisiontable -d '{ state : further_details_access_question , max_state_count : 0, execution_order : 0, analyzer : , queries : [ cannot access account , problem access account ], bubble : What seems to be the problem exactly? , action : show_buttons , action_input : { Forgot Password : forgot_password , Account locked : account_locked , Payment problem : payment_problem , Specify your problem : specify_problem , I want to call an operator : call_operator , None of the above : start }, state_data : {}, success_value : eval(show_buttons) , failure_value : dont_understand }' Sample output { created : true, dtype : state , id : further_details_access_question , index : index_getjenny_english_0.state , version : 1 } DELETE /decisiontable Delete a document by ID Output JSON Requirements Index must exists The function requires user credentials with write permissions on the index Return codes 200 Sample call PORT=${1:-8888} INDEX_NAME=${2:-index_getjenny_english_0} curl -v -H Authorization: Basic `echo -n 'test_user:p4ssw0rd' | base64` \\ -H Content-Type: application/json -X DELETE http://localhost:${PORT}/${INDEX_NAME}/decisiontable/further_details_access_question Sample output { dtype : state , version : 7, found : true, id : further_details_access_question , index : index_getjenny_english_0.state } Sample call: delete all PORT=${1:-8888} INDEX_NAME=${2:-index_getjenny_english_0} curl -v -H Authorization: Basic `echo -n 'test_user:p4ssw0rd' | base64` \\ -H Content-Type: application/json -X DELETE http://localhost:${PORT}/${INDEX_NAME}/decisiontable Sample output: delete all { message : delete , deleted : 18 } POST /decisiontable_upload_csv upload load a csv file on decisiontable Output JSON Requirements Index must exists The function requires user credentials with write permissions on the index Return codes 201 Sample call PORT=${1:-8888} INDEX_NAME=${2:-'index_getjenny_english_0'} FILENAME=${3:- `readlink -e ../../doc/decision_table_starchat_doc.csv` } curl -v -H Authorization: Basic `echo -n 'test_user:p4ssw0rd' | base64` \\ -X POST --form csv=@${FILENAME} http://localhost:8888/${INDEX_NAME}/decisiontable_upload_csv Sample output { data : [ { index : index_getjenny_english_0.state , id : help , created : true, dtype : state , version : 1 }, { dtype : state , version : 1, created : true, id : further_details_access_question , index : index_getjenny_english_0.state }, { id : contribute , created : true, index : index_getjenny_english_0.state , dtype : state , version : 1 }, { version : 1, dtype : state , index : index_getjenny_english_0.state , created : true, id : quickstart }, { dtype : state , version : 1, index : index_getjenny_english_0.state , created : true, id : docker_install }, { dtype : state , version : 1, index : index_getjenny_english_0.state , id : create_es_indices , created : true }, { dtype : state , version : 1, id : delete_es_indexes , created : true, index : index_getjenny_english_0.state }, { version : 1, dtype : state , index : index_getjenny_english_0.state , created : true, id : create_es_indexes }, { created : true, id : index_data , index : index_getjenny_english_0.state , dtype : state , version : 1 }, { version : 1, dtype : state , id : index_analyzer , created : true, index : index_getjenny_english_0.state }, { index : index_getjenny_english_0.state , id : load_conf_file , created : true, dtype : state , version : 1 }, { dtype : state , version : 1, created : true, id : install , index : index_getjenny_english_0.state }, { index : index_getjenny_english_0.state , id : standalone_install , created : true, dtype : state , version : 1 }, { dtype : state , version : 1, index : index_getjenny_english_0.state , id : code_78 , created : true }, { index : index_getjenny_english_0.state , id : licence , created : true, dtype : state , version : 1 }, { index : index_getjenny_english_0.state , created : true, id : terrible_feedback , version : 1, dtype : state }, { id : call_operator , created : true, index : index_getjenny_english_0.state , dtype : state , version : 1 }, { version : 1, dtype : state , id : any_further , created : true, index : index_getjenny_english_0.state }, { index : index_getjenny_english_0.state , id : dont_understand , created : true, version : 1, dtype : state } ] } POST /decisiontable_search Update a document Output JSON Requirements Index must exists The function requires user credentials with read permissions on the index Return codes 200 Sample call Q= ${1:-'cannot access my account'} S= ${2:-0.0} B= ${3:-100.0} PORT=${4:-8888} INDEX_NAME=${5:-index_getjenny_english_0} curl -v -H Authorization: Basic `echo -n 'test_user:p4ssw0rd' | base64` \\ -H Content-Type: application/json -X POST http://localhost:${PORT}/${INDEX_NAME}/decisiontable_search -d { \\ queries\\ : \\ ${Q}\\ , \\ min_score\\ : ${S}, \\ boost_exact_match_factor\\ : ${B}, \\ from\\ : 0, \\ size\\ : 10 } Sample response { max_score : 140.38037109375, total : 1, hits : [ { score : 140.38037109375, document : { action : show_buttons , state_data : { verification : did you mean you can't access to your account? }, success_value : eval(show_buttons) , execution_order : 1, bubble : Can you specify which of the following problems you have? [NB works only if buttons can be shown!] , action_input : { None of the above : start , Forgot Password : forgot_password , I want to call an operator : call_operator , Specify your problem : specify_problem , Account locked : account_locked }, queries : [ cannot access account , problem access account ], failure_value : dont_understand , max_state_count : 0, analyzer : or(and(or(keyword(\\ problem.*\\ ),keyword(\\ issue.*\\ ),keyword(\\ trouble.*\\ )),keyword(\\ account\\ ))) , state : further_details_access_question } } ] } GET /decisiontable_analyzer Get and return the map of analyzer for each state Output JSON Requirements Index must exists The function requires user credentials with read permissions on the index Return codes 200 Sample call PORT=${1:-8888} INDEX_NAME=${2:-index_getjenny_english_0} curl -v -H Authorization: Basic `echo -n 'test_user:p4ssw0rd' | base64` \\ -H Content-Type: application/json -X GET http://localhost:${PORT}/${INDEX_NAME}/decisiontable_analyzer Sample response { analyzer_map : { help : { execution_order : 1, build : true, analyzer : band(keyword(\\ help\\ )) }, contribute : { build : true, analyzer : bor(keyword(\\ contribute\\ )) , execution_order : 1 }, index_analyzer : { analyzer : band(bor(keyword(\\ index\\ ),keyword(\\ load\\ )), keyword(\\ analyzer\\ )) , build : true, execution_order : 1 }, further_details_access_question : { analyzer : or(and(or(keyword(\\ problem.*\\ ),keyword(\\ issue.*\\ ),keyword(\\ trouble.*\\ )),keyword(\\ account\\ ))) , build : true, execution_order : 1 }, create_es_indices : { analyzer : band(keyword(\\ create\\ ), keyword(\\ elastic.*\\ ), bor(keyword(\\ index\\ ), keyword(\\ indices\\ ), keyword(\\ indeces\\ ), keyword(\\ indexes\\ ))) , build : true, execution_order : 1 }, create_es_indexes : { build : true, analyzer : band(keyword(\\ create\\ ), bor(keyword(\\ index.*\\ ), keyword(\\ indic.*\\ ))) , execution_order : 1 }, call_operator : { analyzer : band(bor(keyword(\\ call\\ ),keyword(\\ talk\\ ),keyword(\\ speak\\ )),keyword(\\ operator\\ )) , build : true, execution_order : 1 }, index_data : { execution_order : 1, analyzer : band(keyword(\\ index\\ ), keyword(\\ data\\ )) , build : true }, install : { execution_order : 1, build : true, analyzer : band(bor(keyword(\\ setup\\ ), keyword(\\ install.*\\ )), bnot(bor(keyword(\\ standalone\\ ), keyword(\\ docker\\ )))) }, load_conf_file : { execution_order : 1, analyzer : band(keyword(\\ load.*\\ ), bor(keyword(\\ config.*\\ ), band(keyword(\\ decision\\ ), keyword(\\ table\\ ))), keyword(\\ file.*\\ )) , build : true }, docker_install : { execution_order : 1, analyzer : band(keyword(\\ docker\\ ), keyword(\\ install.*\\ )) , build : true }, delete_es_indexes : { execution_order : 1, build : true, analyzer : band(keyword(\\ delete\\ ), bor(keyword(\\ index.*\\ ), keyword(\\ indic.*\\ ))) }, code_78 : { analyzer : band(keyword(\\ code\\ ),keyword(\\ 78\\ )) , build : true, execution_order : 1 }, terrible_feedback : { execution_order : 1, build : true, analyzer : booleanor(keyword(\\ idiot\\ ), keyword(\\ fuck.*\\ ), keyword(\\ screw\\ ), keyword(\\ damn.*\\ ), keyword(\\ asshole\\ )) }, standalone_install : { analyzer : band(keyword(\\ standal.*\\ ), keyword(\\ install\\ )) , build : true, execution_order : 1 }, quickstart : { execution_order : 1, build : true, analyzer : band(bor(keyword(\\ start\\ ), keyword(\\ quickstart\\ )), keyword(\\ starchat\\ )) }, licence : { build : true, analyzer : bor(band(keyword(\\ open\\ ), keyword(\\ source\\ )), keyword(\\ opensource\\ ), keyword(\\ licence\\ )) , execution_order : 1 } } } POST /decisiontable_analyzer trigger a syncronous load/reload the analyzers map from ES Output JSON Requirements Index must exists The function requires user credentials with write permissions on the index Return codes 200 Sample call PORT=${1:-8888} INDEX_NAME=${2:-index_getjenny_english_0} curl -v -H Authorization: Basic `echo -n 'test_user:p4ssw0rd' | base64` \\ -H Content-Type: application/json -X POST http://localhost:${PORT}/${INDEX_NAME}/decisiontable_analyzer Sample response { num_of_entries : 17 } POST /decisiontable_async_reload trigger an asyncronous load/reload the analyzers map from ES Output JSON Requirements Index must exists The function requires user credentials with write permissions on the index Return codes 200 Sample call PORT=${1:-8888} INDEX_NAME=${2:-index_getjenny_english_0} curl -v -H Authorization: Basic `echo -n 'test_user:p4ssw0rd' | base64` \\ -H Content-Type: application/json -X POST https://starchat-cluster-0.getjenny.com/${INDEX_NAME}/decisiontable_async_reload Sample response { timestamp : 1540281692630, indexName : index_getjenny_english_0 } QuestionAnswer (KnowledgeBase, PriorData, ConversationLogs) The following REST endpoints have the same syntax and semantic for KnowledgeBase, PriorData, ConversationLogs. The only difference is the route path component: KnowledgeBase: \"knowledgebase\" Priodata: \"prior_data\" * ConversationLogs: \"conversation_logs\" In the API description we will refer to this path component as GET / Return a document by ID Output JSON Requirements Index must exists The function requires user credentials with read permissions on the index Return codes 200 Sample call ID=${1:-0} PORT=${2:-8888} INDEX_NAME=${3:-index_getjenny_english_0} # retrieve one or more entries with given ids; ids can be specified multiple times curl -v -H Authorization: Basic `echo -n 'test_user:p4ssw0rd' | base64` \\ -H Content-Type: application/json http://localhost:${PORT}/${INDEX_NAME}/knowledgebase?ids=${ID} Sample response { max_score : 0, total : 1, hits : [ { score : 0, document : { conversation : id:1000 , id : 0 , status : 0, question_scored_terms : [ [ thank , 1.09 ] ], verified : true, answer : you are welcome! , topics : t1 t2 , doctype : normal , index_in_conversation : 1, question : thank you , question_negative : [ thank you anyway ], state : } } ] } POST / Insert a new document Requirements Index must exists The function requires user credentials with write permissions on the index Return codes 201 PORT=${1:-8888} INDEX_NAME=${2:-index_getjenny_english_0} curl -v -H Authorization: Basic `echo -n 'test_user:p4ssw0rd' | base64` \\ -H Content-Type: application/json -X POST http://localhost:${PORT}/${INDEX_NAME}/knowledgebase -d '{ id : 0 , conversation : id:1000 , index_in_conversation : 1, question : thank you , question_negative : [ ok, I will not talk with you anymore , thank you anyway ], answer : you are welcome! , question_scored_terms : [ [ currently , 1.0901874131103333 ], [ installing , 2.11472759638322 ], [ mac , 9.000484252244254 ], [ reset , 4.34483238516225 ], [ app , 1.2219061535961406 ], [ device , 2.1679468390743414E-213 ], [ devices , 4.1987625801077624E-268 ] ], verified : true, topics : t1 t2 , doctype : normal , state : , status : 0 }' Sample response { created : true, dtype : question , version : 1, index : index_getjenny_english_0.question , id : 0 } DELETE / Delete a document by ID Output JSON Requirements Index must exists The function requires user credentials with write permissions on the index Return codes 200 Sample call PORT=${1:-8888} INDEX_NAME=${2:-index_getjenny_english_0} curl -v -H Authorization: Basic `echo -n 'test_user:p4ssw0rd' | base64` \\ -H Content-Type: application/json -X DELETE http://localhost:${PORT}/${INDEX_NAME}/knowledgebase/0 Sample output { dtype : question , version : 5, found : false, id : 0 , index : index_getjenny_english_0.question } Sample call: delete all PORT=${1:-8888} INDEX_NAME=${2:-index_getjenny_english_0} curl -v -H Authorization: Basic `echo -n 'test_user:p4ssw0rd' | base64` \\ -H Content-Type: application/json -X DELETE http://localhost:${PORT}/${INDEX_NAME}/knowledgebase Sample output: delete all { message : delete , deleted : 2 } PUT / Update an existing document Output JSON Requirements Index must exists The function requires user credentials with write permissions on the index Return codes 200 Sample call PORT=${1:-8888} INDEX_NAME=${2:-index_getjenny_english_0} curl -v -H Authorization: Basic `echo -n 'test_user:p4ssw0rd' | base64` \\ -H Content-Type: application/json -X PUT http://localhost:${PORT}/${INDEX_NAME}/knowledgebase/0 -d '{ conversation : id:1001 , question : thank you , answer : you are welcome! , verified : true, topics : t1 t2 , doctype : normal , state : , status : 0 }' Sample response { dtype : question , index : index_getjenny_english_0.question , id : 0 , version : 4, created : false } POST / _search Output JSON Requirements Index must exists The function requires user credentials with read permissions on the index Return codes 200 Sample call QUERY=${1:- how are you? } PORT=${2:-8888} INDEX_NAME=${3:-index_getjenny_english_0} curl -v -H Authorization: Basic `echo -n 'test_user:p4ssw0rd' | base64` \\ -H Content-Type: application/json -X POST http://localhost:${PORT}/${INDEX_NAME}/knowledgebase_search -d { \\ question\\ : \\ ${QUERY}\\ , \\ doctype\\ : \\ normal\\ , \\ min_score\\ : 0.0 } Sample output { hits : [ { document : { question_scored_terms : [ [ currently , 1.09018741311033 ], [ installing , 2.11472759638322 ], [ mac , 9.00048425224425 ], [ reset , 4.34483238516225 ], [ app , 1.22190615359614 ], [ device , 2.16794683907434e-213 ], [ devices , 4.19876258010776e-268 ] ], question : thank you , id : 0 , state : , conversation : id:1001 , answer : you are welcome! , topics : t1 t2 , index_in_conversation : 1, doctype : normal , status : 0, verified : true, question_negative : [ ok, I will not talk with you anymore , thank you anyway ] }, score : 0.287682086229324 } ], total : 1, max_score : 0.287682086229324 } GET /term_count/ Count the occurrence of a term. The endpoint supports the following query arguments: field: can be \"answer\" or \"question\" (optional, default question) stale: represent the max stale time in millis ; 0 means no cache (Optional) * term: the term to count (mandatory) Output JSON Requirements Index must exists The function requires user credentials with read permissions on the index Return codes 200 Sample call TERM=${1:- hello } ROUTE=${2:-knowledgebase} INDEX_NAME=${3:-index_getjenny_english_0} FIELD=${4:- question } PORT=${5:-8888} curl -v -H Authorization: Basic $(echo -n 'test_user:p4ssw0rd' | base64) \\ -H Content-Type: application/json -X GET http://localhost:${PORT}/${INDEX_NAME}/term_count/${ROUTE}?field=${FIELD} term=${TERM} Sample response { numDocs : 994, count : 1037 } GET /dict_size/ Measure the dictionary size: number of unique terms on question and answer field The endpoint supports the following query arguments: * stale: represent the max stale time in millis ; 0 means no cache (Optional) Output JSON Requirements Index must exists The function requires user credentials with read permissions on the index Return codes 200 Sample call PORT=${1:-8888} DATATYPE=${2:-knowledgebase} INDEX_NAME=${3:-index_getjenny_english_0} curl -v -H Authorization: Basic $(echo -n 'test_user:p4ssw0rd' | base64) \\ -H Content-Type: application/json -X GET http://localhost:${PORT}/${INDEX_NAME}/dict_size/${DATATYPE} Sample response { numDocs : 135865, answer : 9171, question : 25200, total : 29258 } GET /total_terms/ calculate the total number of terms The endpoint supports the following query arguments: * stale: represent the max stale time in millis ; 0 means no cache (Optional) Output JSON Requirements Index must exists The function requires user credentials with read permissions on the index Return codes 200 Sample call PORT=${1:-8888} INDEX_NAME=${2:-index_getjenny_english_0} DATATYPE=${3:-knowledgebase} curl -v -H Authorization: Basic $(echo -n 'test_user:p4ssw0rd' | base64) \\ -H Content-Type: application/json -X GET http://localhost:${PORT}/${INDEX_NAME}/total_terms/${DATATYPE} Sample response { question : 821982, numDocs : 135865, answer : 1098490 } GET /cache/ return the cache counter parameters and the number of elements in cache Output JSON Requirements Index must exists The function requires user credentials with read permissions on the index Return codes 200 Sample call INDEX_NAME=${1:-index_getjenny_english_0} PORT=${2:-8888} ROUTE=${3:-knowledgebase} curl -v -H Authorization: Basic $(echo -n 'admin:adminp4ssw0rd' | base64) \\ -H Content-Type: application/json -X GET http://localhost:${PORT}/${INDEX_NAME}/cache/${ROUTE} Sample response [ { totalTermsCacheMaxSize : 1000, countTermCacheMaxSize : 100000, dictSizeCacheMaxSize : 1000, cacheStealTimeMillis : 43200000 }, { countTermCacheSize : 0, dictSizeCacheSize : 0, totalTermsCacheSize : 0 } ] POST /cache/ set the cache counter parameters Output JSON Requirements Index must exists The function requires user credentials with read permissions on the index Return codes 200 Sample call INDEX_NAME=${1:-index_getjenny_english_0} PORT=${2:-8888} ROUTE=${3:-knowledgebase} curl -v -H Authorization: Basic $(echo -n 'admin:adminp4ssw0rd' | base64) \\ -H Content-Type: application/json -X POST http://localhost:${PORT}/${INDEX_NAME}/cache/${ROUTE} -d'{ dictSizeCacheMaxSize : 1000, totalTermsCacheMaxSize : 1000, countTermCacheMaxSize : 100000, cacheStealTimeMillis : 43200000 }' Sample response { totalTermsCacheMaxSize : 1000, dictSizeCacheMaxSize : 1000, countTermCacheMaxSize : 100000, cacheStealTimeMillis : 43200000 } DELETE /cache/ reset the cache for counters Output JSON Requirements Index must exists The function requires user credentials with read permissions on the index Return codes 200 Sample call INDEX_NAME=${1:-index_getjenny_english_0} PORT=${2:-8888} ROUTE=${3:-knowledgebase} curl -v -H Authorization: Basic $(echo -n 'admin:adminp4ssw0rd' | base64) \\ -H Content-Type: application/json -X DELETE http://localhost:${PORT}/${INDEX_NAME}/cache/${ROUTE} Sample response [ { countTermCacheMaxSize : 100000, totalTermsCacheMaxSize : 1000, dictSizeCacheMaxSize : 1000, cacheStealTimeMillis : 43200000 }, { totalTermsCacheSize : 0, dictSizeCacheSize : 0, countTermCacheSize : 0 } ] PUT /updateTerms/ update the manaus terms for a QuestionAnswer document Output JSON Requirements Index must exists The document to update must exists The function requires user credentials with read permissions on the index Return codes 200 Sample call DOCID=${1:-0} PORT=${2:-8888} INDEX_NAME=${3:-index_getjenny_english_0} ROUTE=${4:-knowledgebase} curl -v -H Authorization: Basic $(echo -n 'test_user:p4ssw0rd' | base64) \\ -H Content-Type: application/json -X PUT http://localhost:${PORT}/${INDEX_NAME}/updateTerms/${ROUTE} -d { \\ id\\ : \\ ${DOCID}\\ } Sample response [ { id : 0 , created : false, dtype : question_answer , version : 2, index : index_getjenny_english_0.question_answer } ] GET /updateTerms/ update the manaus terms for all the QuestionAnswer documents Output JSON Requirements Index must exists The user has stream permissions on the index The function requires user credentials with read permissions on the index Return codes 200 Sample call PORT=${1:-8888} INDEX_NAME=${2:-index_getjenny_english_0} ROUTE=${3:-knowledgebase} curl -v -H Authorization: Basic $(echo -n 'test_user:p4ssw0rd' | base64) \\ -H Content-Type: application/json -X GET http://localhost:${PORT}/${INDEX_NAME}/updateTerms/${ROUTE} -d'{ id : }' Sample response { dtype : question_answer , version :2, id : 3bcafc79400f201bcbb2e9290d60231fb096845d97cd3a83b032eab90a9b6f8f , index : index_getjenny_english_0.question_answer , created :false} { dtype : question_answer , version :2, id : f5239013416fc98c558560659b00ec96e694df243aace574e9dd32166e982ccd , index : index_getjenny_english_0.question_answer , created :false} { dtype : question_answer , version :2, id : 23cb4dc14284b278867b743d6e7387a3ba20e96afb4a34ddf58a8397b173a24f , index : index_getjenny_english_0.question_answer , created :false} { dtype : question_answer , version :2, id : 5f948728fbca7617907ab4ad031020f9da214926f2fbe272295c799d568a3491 , index : index_getjenny_english_0.question_answer , created :false} { dtype : question_answer , version :2, id : cfb544023bcc1378a59695bc6135fb7b71bfcdaba6fb2429e151aba73b2774b8 , index : index_getjenny_english_0.question_answer , created :false} { dtype : question_answer , version :2, id : cce15f6984f473fe7534f9e0f699e5e11a61e39cbe82989818a023d626ea5e1f , index : index_getjenny_english_0.question_answer , created :false} { dtype : question_answer , version :2, id : b37db2bef879f22d3792840efa1a41b1d46cdbee4af5ccb1b935b3c944732544 , index : index_getjenny_english_0.question_answer , created :false} TermsExtraction POST /extraction/frequencies Extract term frequencies from a sentence The fields of the data structure have the following meaning: commonOrSpecificSearchPrior: specify if the prior_data table is from the common index or is index specific. Values are COMMON or IDXSPECIFIC commonOrSpecificSearchObserved: specify if the knowledgebase table is from the common index or is index specific. Values are COMMON or IDXSPECIFIC observedDataSource: specify which table should be considered for observed data, values are KNOWLEDGEBASE or CONV_LOGS fieldsPrior: specify the fields which must be considered, values are question, answer, all fieldsObserved: specify the fields which must be considered, values are question, answer, all Output JSON Requirements Index must exists The function requires user credentials with read permissions on the index Return codes 200 Sample call QUERY=${1:- good morning, may I ask you a question? } PORT=${2:-8888} INDEX_NAME=${4:-index_getjenny_english_0} curl -v -H Authorization: Basic $(echo -n 'test_user:p4ssw0rd' | base64) \\ -H Content-Type: application/json -X POST http://localhost:${PORT}/${INDEX_NAME}/extraction/frequencies -d { \\ text\\ : \\ ${QUERY}\\ , \\ commonOrSpecificSearchPrior\\ : \\ COMMON\\ , \\ commonOrSpecificSearchObserved\\ : \\ IDXSPECIFIC\\ , \\ observedDataSource\\ : \\ KNOWLEDGEBASE\\ , \\ fieldsPrior\\ : \\ all\\ , \\ fieldsObserved\\ : \\ all\\ , \\ tokenizer\\ : \\ space_punctuation\\ } Sample output { observedTotalTerms : 1920472, priorTotalTerms : 2311033, tokensFreq : [ { observedFrequency : 1187, token : good , priorFrequency : 7024 }, { priorFrequency : 1228, token : morning , observedFrequency : 246 }, { priorFrequency : 1343, observedFrequency : 4185, token : may }, { observedFrequency : 68554, token : i , priorFrequency : 79384 }, { priorFrequency : 1377, observedFrequency : 471, token : ask }, { priorFrequency : 93571, observedFrequency : 79470, token : you }, { priorFrequency : 47701, token : a , observedFrequency : 25688 }, { observedFrequency : 539, token : question , priorFrequency : 525 } ] } POST /extraction/frequencies Extract manaus terms from a sentence The fields of the data structure have the following meaning: commonOrSpecificSearchPrior: specify if the prior_data table is from the common index or is index specific. Values are COMMON or IDXSPECIFIC commonOrSpecificSearchObserved: specify if the knowledgebase table is from the common index or is index specific. Values are COMMON or IDXSPECIFIC observedDataSource: specify which table should be considered for observed data, values are KNOWLEDGEBASE or CONV_LOGS fieldsPrior: specify the fields which must be considered, values are question, answer, all fieldsObserved: specify the fields which must be considered, values are question, answer, all Output JSON Requirements Index must exists The function requires user credentials with read permissions on the index Return codes 200 Sample call QUERY=${1:- good morning, may I ask you a question? } PORT=${2:-8888} INDEX_NAME=${4:-index_getjenny_english_0} curl -v -H Authorization: Basic $(echo -n 'test_user:p4ssw0rd' | base64) \\ -H Content-Type: application/json -X POST http://localhost:${PORT}/${INDEX_NAME}/extraction/keywords -d { \\ text\\ : \\ ${QUERY}\\ , \\ commonOrSpecificSearchPrior\\ : \\ COMMON\\ , \\ commonOrSpecificSearchObserved\\ : \\ IDXSPECIFIC\\ , \\ observedDataSource\\ : \\ KNOWLEDGEBASE\\ , \\ fieldsPrior\\ : \\ all\\ , \\ fieldsObserved\\ : \\ all\\ , \\ minWordsPerSentence\\ : 5, \\ pruneTermsThreshold\\ : 100000, \\ misspellMaxOccurrence\\ : 10, \\ activePotentialDecay\\ : 1, \\ activePotential\\ : true, \\ totalInfo\\ : true } Sample output { question : 0.229660917208135 } POST /extraction/synonyms Tokenize a sentence, extract terms and decorate each term with manaus informations and the possible synonyms using a vector model. The fields of the data structure have the following meaning: text: the text to analyze tokenizer: the tokenizer, default is \"base\" sentencesThreshold: discard sentences if the sentence with the synonym is below the threshold, default us 0.0 synonymsThreshold: discard the synonyms if the distance is below the threshold, default is 0.0 distanceFunction: a distance function values are SUMCOSINE (sum of word vectors) or EMDCOSINE (Earth movers distance) commonOrSpecificSearchTerms: specify if the terms table is from the common index or is index specific. Values are COMMON or IDXSPECIFIC commonOrSpecificSearchPrior: specify if the prior_data table is from the common index or is index specific. Values are COMMON or IDXSPECIFIC commonOrSpecificSearchObserved: specify if the knowledgebase table is from the common index or is index specific. Values are COMMON or IDXSPECIFIC observedDataSource: specify which table should be considered for observed data, values are KNOWLEDGEBASE or CONV_LOGS fieldsPrior: specify the fields which must be considered, values are question, answer, all fieldsObserved: specify the fields which must be considered, values are question, answer, all minWordsPerSentence: manaus parameter, ignore sentences with less than N terms, default is 10 pruneTermsThreshold: manaus parameter, a threshold on the number of terms for trigger pruning, default value is 100000 misspellMaxOccurrence: manaus parameter, discard terms with a frequency below the threshold, default is 5 activePotentialDecay: manaus parameter, a decay value for the active potential activePotential: manaus parameter, tell wether to calculate the active potential or not, default is true minSentenceInfoBit: min number of information bits for the sentence minKeywordInfo: min number of information bits for a word totalInfo: manaus parameter, tell wether to consider the total info or not, default is true Output JSON Requirements Index must exists The function requires user credentials with read permissions on the index Return codes 200 Sample call QUERY=${1:- good morning, may I ask you a question? } PORT=${2:-8888} INDEX_NAME=${4:-index_getjenny_english_0} curl -v -H Authorization: Basic $(echo -n 'test_user:p4ssw0rd' | base64) \\ -H Content-Type: application/json -X POST http://localhost:${PORT}/${INDEX_NAME}/extraction/synonyms -d { \\ text\\ : \\ ${QUERY}\\ , \\ tokenizer\\ : \\ base\\ , \\ sentencesThreshold\\ : 0.9, \\ synonymsThreshold\\ : 0.3, \\ distanceFunction\\ : \\ EMDCOSINE\\ , \\ commonOrSpecificSearchPrior\\ : \\ COMMON\\ , \\ commonOrSpecificSearchObserved\\ : \\ IDXSPECIFIC\\ , \\ observedDataSource\\ : \\ KNOWLEDGEBASE\\ , \\ fieldsPrior\\ : \\ all\\ , \\ fieldsObserved\\ : \\ all\\ , \\ minWordsPerSentence\\ : 5, \\ pruneTermsThreshold\\ : 100000, \\ misspellMaxOccurrence\\ : 10, \\ activePotentialDecay\\ : 1, \\ activePotential\\ : true, \\ totalInfo\\ : true } Sample output [ { synonymItem : [ { termSimilarityScore : 0.303461623209445, synonym : serious , synonymScore : 0.988391942416316, textDistanceWithSynonym : 0.988391942416316 }, { textDistanceWithSynonym : 0.98686397528116, synonymScore : 0.98686397528116, synonym : safe , termSimilarityScore : 0.310671998517923 }, { textDistanceWithSynonym : 0.986168126185455, synonymScore : 0.986168126185455, synonym : effective , termSimilarityScore : 0.337205437720856 }, { textDistanceWithSynonym : 0.985984970241292, synonymScore : 0.985984970241292, termSimilarityScore : 0.30013467985373, synonym : salutary }, { textDistanceWithSynonym : 0.985895039899644, synonymScore : 0.985895039899644, termSimilarityScore : 0.301306430755499, synonym : dear }, { termSimilarityScore : 0.319592899798586, synonym : estimable , synonymScore : 0.985759252837724, textDistanceWithSynonym : 0.985759252837724 }, { textDistanceWithSynonym : 0.985249380845675, synonymScore : 0.985249380845675, synonym : thoroughly , termSimilarityScore : 0.337964488042003 }, { termSimilarityScore : 0.360057098563907, synonym : right , synonymScore : 0.984778611750602, textDistanceWithSynonym : 0.984778611750602 }, { textDistanceWithSynonym : 0.984227558357218, synonymScore : 0.984227558357218, synonym : adept , termSimilarityScore : 0.330252861229703 }, { termSimilarityScore : 0.360657543519664, synonym : expert , synonymScore : 0.984204967194361, textDistanceWithSynonym : 0.984204967194361 }, { synonymScore : 0.9839801846329, textDistanceWithSynonym : 0.9839801846329, termSimilarityScore : 0.387968844459879, synonym : full }, { synonymScore : 0.983341764529566, textDistanceWithSynonym : 0.983341764529566, termSimilarityScore : 0.307056458999165, synonym : skilful }, { synonym : secure , termSimilarityScore : 0.386750372411043, synonymScore : 0.9828697525105, textDistanceWithSynonym : 0.9828697525105 }, { termSimilarityScore : 0.436633496912848, synonym : near , textDistanceWithSynonym : 0.9823153867721, synonymScore : 0.9823153867721 }, { textDistanceWithSynonym : 0.98229857645758, synonymScore : 0.98229857645758, termSimilarityScore : 0.387852275460498, synonym : soundly }, { textDistanceWithSynonym : 0.981854513089778, synonymScore : 0.981854513089778, termSimilarityScore : 0.375971735071977, synonym : sound }, { textDistanceWithSynonym : 0.981012225642823, synonymScore : 0.981012225642823, termSimilarityScore : 0.349548530861366, synonym : unspoiled }, { textDistanceWithSynonym : 0.980134947418645, synonymScore : 0.980134947418645, synonym : honorable , termSimilarityScore : 0.36656103347195 }, { synonym : ripe , termSimilarityScore : 0.361927513363036, synonymScore : 0.979828029318668, textDistanceWithSynonym : 0.979828029318668 }, { termSimilarityScore : 0.354594107764147, synonym : proficient , synonymScore : 0.97897497858666, textDistanceWithSynonym : 0.97897497858666 }, { synonym : commodity , termSimilarityScore : 0.400576579081682, synonymScore : 0.978353047238428, textDistanceWithSynonym : 0.978353047238428 }, { textDistanceWithSynonym : 0.978097513490299, synonymScore : 0.978097513490299, synonym : practiced , termSimilarityScore : 0.417713639606198 }, { synonym : unspoilt , termSimilarityScore : 0.344935826089365, textDistanceWithSynonym : 0.977965860781802, synonymScore : 0.977965860781802 }, { textDistanceWithSynonym : 0.977574200871494, synonymScore : 0.977574200871494, termSimilarityScore : 0.368691045104583, synonym : upright } ], isKeywordToken : false, keywordExtractionScore : 0, token : { position : 0, token : good , token_type : ALPHANUM , start_offset : 0, end_offset : 4 } }, { keywordExtractionScore : 0, token : { position : 1, end_offset : 12, token : morning , token_type : ALPHANUM , start_offset : 5 }, synonymItem : [ { synonymScore : 0.982435251017214, textDistanceWithSynonym : 0.982435251017214, termSimilarityScore : 0.328796456566772, synonym : dawning }, { termSimilarityScore : 0.320363553861273, synonym : sunup , textDistanceWithSynonym : 0.981187446721127, synonymScore : 0.981187446721127 }, { synonymScore : 0.980827133578433, textDistanceWithSynonym : 0.980827133578433, termSimilarityScore : 0.351556981730201, synonym : cockcrow }, { synonym : dayspring , termSimilarityScore : 0.348148650582253, textDistanceWithSynonym : 0.98000434808506, synonymScore : 0.98000434808506 }, { synonym : morn , termSimilarityScore : 0.310762418953851, textDistanceWithSynonym : 0.979694497080588, synonymScore : 0.979694497080588 }, { synonymScore : 0.975365086887233, textDistanceWithSynonym : 0.975365086887233, synonym : aurora , termSimilarityScore : 0.403555992661807 }, { synonym : first_light , termSimilarityScore : 0.389117497640442, synonymScore : 0.973279032352032, textDistanceWithSynonym : 0.973279032352032 } ], isKeywordToken : false }, { keywordExtractionScore : 0, token : { position : 2, end_offset : 17, token : may , token_type : ALPHANUM , start_offset : 14 }, synonymItem : [ { textDistanceWithSynonym : 0.977735408571704, synonymScore : 0.977735408571704, termSimilarityScore : 0.430110506850729, synonym : whitethorn } ], isKeywordToken : false }, { keywordExtractionScore : 0, token : { position : 3, end_offset : 19, token_type : ALPHANUM , start_offset : 18, token : i }, synonymItem : [ { synonymScore : 0.990079660169983, textDistanceWithSynonym : 0.990079660169983, termSimilarityScore : 0.33685060765497, synonym : one }, { termSimilarityScore : 0.402164830285073, synonym : single , textDistanceWithSynonym : 0.982443662914587, synonymScore : 0.982443662914587 }, { synonymScore : 0.978915403087889, textDistanceWithSynonym : 0.978915403087889, termSimilarityScore : 0.421938029658631, synonym : unity }, { synonymScore : 0.976796274715053, textDistanceWithSynonym : 0.976796274715053, termSimilarityScore : 0.411104820586555, synonym : ace }, { termSimilarityScore : 0.409793052227205, synonym : iodine , synonymScore : 0.971809310282386, textDistanceWithSynonym : 0.971809310282386 }, { synonymScore : 0.970492090788282, textDistanceWithSynonym : 0.970492090788282, synonym : ane , termSimilarityScore : 0.426139287692068 } ], isKeywordToken : false }, { isKeywordToken : false, synonymItem : [ { termSimilarityScore : 0.344875478792656, synonym : involve , synonymScore : 0.985084402822893, textDistanceWithSynonym : 0.985084402822893 }, { synonym : require , termSimilarityScore : 0.313982723187962, synonymScore : 0.985048997600635, textDistanceWithSynonym : 0.985048997600635 }, { synonym : demand , termSimilarityScore : 0.340885896054422, textDistanceWithSynonym : 0.984973652020142, synonymScore : 0.984973652020142 }, { textDistanceWithSynonym : 0.984179229975704, synonymScore : 0.984179229975704, termSimilarityScore : 0.348080045767017, synonym : necessitate }, { termSimilarityScore : 0.363270794438576, synonym : postulate , synonymScore : 0.980113837090212, textDistanceWithSynonym : 0.980113837090212 } ], keywordExtractionScore : 0, token : { position : 4, end_offset : 23, token : ask , start_offset : 20, token_type : ALPHANUM } }, { token : { position : 5, end_offset : 27, token : you , token_type : ALPHANUM , start_offset : 24 }, keywordExtractionScore : 0, synonymItem : [], isKeywordToken : false }, { isKeywordToken : false, synonymItem : [ { synonym : angstrom , termSimilarityScore : 0.389515130731534, synonymScore : 0.981827876880409, textDistanceWithSynonym : 0.981827876880409 }, { synonym : amp , termSimilarityScore : 0.410951525810052, synonymScore : 0.978805416352854, textDistanceWithSynonym : 0.978805416352854 }, { termSimilarityScore : 0.399132821680172, synonym : ampere , synonymScore : 0.978184525582464, textDistanceWithSynonym : 0.978184525582464 }, { textDistanceWithSynonym : 0.970833723014969, synonymScore : 0.970833723014969, synonym : adenine , termSimilarityScore : 0.417303913993053 } ], keywordExtractionScore : 0, token : { end_offset : 29, start_offset : 28, token_type : ALPHANUM , token : a , position : 6 } }, { token : { token_type : ALPHANUM , start_offset : 30, token : question , end_offset : 38, position : 7 }, keywordExtractionScore : 0, isKeywordToken : false, synonymItem : [ { termSimilarityScore : 0.302928140147459, synonym : doubtfulness , textDistanceWithSynonym : 0.986332041308894, synonymScore : 0.986332041308894 }, { textDistanceWithSynonym : 0.984752050785226, synonymScore : 0.984752050785226, synonym : interview , termSimilarityScore : 0.337223120697986 }, { synonym : enquiry , termSimilarityScore : 0.30268890030876, textDistanceWithSynonym : 0.983960314458422, synonymScore : 0.983960314458422 }, { synonym : interrogate , termSimilarityScore : 0.347190376576428, synonymScore : 0.982717754194259, textDistanceWithSynonym : 0.982717754194259 }, { termSimilarityScore : 0.402127027019405, synonym : head , textDistanceWithSynonym : 0.981584262241235, synonymScore : 0.981584262241235 }, { termSimilarityScore : 0.353450470156032, synonym : interrogation , textDistanceWithSynonym : 0.980529096104673, synonymScore : 0.980529096104673 }, { termSimilarityScore : 0.386000200471808, synonym : motion , textDistanceWithSynonym : 0.978495629389701, synonymScore : 0.978495629389701 }, { synonym : inquiry , termSimilarityScore : 0.314067668506634, textDistanceWithSynonym : 0.977996268442931, synonymScore : 0.977996268442931 } ] } ] LanguageGuesser POST /language_guesser Output JSON Requirements Index must exists The function requires user credentials with read permissions on the index Return codes 200 Sample call QUERY=${1:- good morning, may I ask you a question? } PORT=${2:-8888} INDEX_NAME=${3:-index_getjenny_english_0} curl -v -H Authorization: Basic `echo -n 'test_user:p4ssw0rd' | base64` \\ -H Content-Type: application/json -X POST http://localhost:${PORT}/${INDEX_NAME}/language_guesser -d { \\ input_text\\ : \\ ${QUERY}\\ } Sample output { enhough_text : false, language : en , confidence : MEDIUM , score : 0.571426689624786 } GET /language_guesser Check if a language is recognizable by the guesser Output JSON Requirements Index must exists The function requires user credentials with read permissions on the index Return codes 200 Sample call LANG=${1:-en} PORT=${2:-8888} INDEX_NAME=${3:-index_getjenny_english_0} curl -v -H Authorization: Basic `echo -n 'test_user:p4ssw0rd' | base64` \\ -H Content-Type: application/json -X GET http://localhost:${PORT}/${INDEX_NAME}/language_guesser/${LANG} Sample output { supported_languages : { languages : { en : true } } } IndexManagement POST /index_management/create Output JSON Requirements Index name must start with the \"index_\" prefix followed by a language, and a sequence of alphanumeric characters separated by underscore e.g. index_ _ The function requires \"admin\" credentials Return codes 200 Sample call PORT=${1:-8888} INDEX_NAME=${2:-index_getjenny_english_0} curl -v -H Authorization: Basic `echo -n 'admin:adminp4ssw0rd' | base64` \\ -H Content-Type: application/json -X POST http://localhost:${PORT}/${INDEX_NAME}/index_management/create Sample output { message : IndexCreation: state(index_getjenny_english_0.state, true) question(index_getjenny_english_0.question, true) term(index_getjenny_english_0.term, true) } POST /index_management/refresh Output JSON Requirements The index must exists The function requires user credentials with write permissions on the index Return codes 200 Sample call PORT=${1:-8888} INDEX_NAME=${2:-index_getjenny_english_0} curl -v -H Authorization: Basic `echo -n 'test_user:p4ssw0rd' | base64` \\ -H Content-Type: application/json -X POST http://localhost:${PORT}/${INDEX_NAME}/index_management/refresh Sample output { results : [ { failed_shards : [], successful_shards_n : 5, failed_shards_n : 0, index_name : index_getjenny_english_0.state , total_shards_n : 10 }, { failed_shards : [], total_shards_n : 10, index_name : index_getjenny_english_0.question , failed_shards_n : 0, successful_shards_n : 5 }, { failed_shards : [], successful_shards_n : 5, index_name : index_getjenny_english_0.term , failed_shards_n : 0, total_shards_n : 10 } ] } GET /index_management Output JSON Requirements The index must exists The function requires user credentials with read permissions on the index Return codes 200 Sample call PORT=${1:-8888} INDEX_NAME=${2:-index_getjenny_english_0} curl -v -H Authorization: Basic `echo -n 'test_user:p4ssw0rd' | base64` \\ -H Content-Type: application/json -X GET http://localhost:${PORT}/${INDEX_NAME}/index_management Sample output { message : IndexCheck: state(index_getjenny_english_0.state, true) question(index_getjenny_english_0.question, true) term(index_getjenny_english_0.term, true) } PUT /index_management Output JSON Requirements Index must exists The function requires \"admin\" credentials Return codes 200 Sample call PORT=${1:-8888} INDEX_NAME=${2:-index_getjenny_english_0} LANGUAGE=${3:-english} curl -v -H Authorization: Basic `echo -n 'admin:adminp4ssw0rd' | base64` \\ -H Content-Type: application/json -X PUT http://localhost:${PORT}/${INDEX_NAME}/${LANGUAGE}/index_management Sample output { message : IndexCheck: state(index_getjenny_english_0.state, true) question(index_getjenny_english_0.question, true) term(index_getjenny_english_0.term, true) } DELETE /index_management Output JSON Requirements The index must exists The function requires admin credentials Return codes 200 Sample call PORT=${1:-8888} INDEX_NAME=${2:-index_getjenny_english_0} curl -v -H Authorization: Basic `echo -n 'admin:adminp4ssw0rd' | base64` \\ -H Content-Type: application/json -X DELETE http://localhost:${PORT}/${INDEX_NAME}/index_management Sample output { message : IndexDeletion: state(index_getjenny_english_0.state, true) question(index_getjenny_english_0.question, true) term(index_getjenny_english_0.term, true) } Term POST /term/index Index the term as indicated in the JSON. Requirements The index must exists The function requires user credentials with write permissions on the index Return codes 200 Sample call PORT=${1:-8888} INDEX_NAME=${2:-index_getjenny_english_0} curl -v -H Authorization: Basic `echo -n 'test_user:p4ssw0rd' | base64` \\ -H Content-Type: application/json -X POST http://localhost:${PORT}/${INDEX_NAME}/term/index -d '{ terms : [ { term : \u092e\u0930\u093e\u0920\u0940 , frequency_base : 1.0, frequency_stem : 1.0, vector : [1.0, 2.0, 3.0], synonyms : { bla1 : 0.1, bla2 : 0.2 }, antonyms : { bla3 : 0.1, bla4 : 0.2 }, tags : tag1 tag2 , features : { NUM : S , GEN : M } }, { term : term2 , frequency_base : 1.0, frequency_stem : 1.0, vector : [1.0, 2.0, 3.0], synonyms : { bla1 : 0.1, bla2 : 0.2 }, antonyms : { bla3 : 0.1, bla4 : 0.2 }, tags : tag1 tag2 , features : { NUM : P , GEN : F } } ] }' Sample output { data : [ { version : 1, created : true, dtype : term , index : jenny-en-0 , id : \u092e\u0930\u093e\u0920\u0940 }, { dtype : term , created : true, version : 1, id : term2 , index : jenny-en-0 } ] } POST /term/index_default_synonyms Index a set of default synonyms provided with starchat. Requirements The index must exists The function requires user credentials with write permissions on the index Return codes 200 Sample call PORT=${1:-8888} INDEX_NAME=${2:-index_getjenny_english_0} GROUP_SIZE=${3:-1000} curl --max-time 600 -v -H Authorization: Basic $(echo -n 'admin:adminp4ssw0rd' | base64) \\ -H Content-Type: application/json -X POST http://localhost:${PORT}/${INDEX_NAME}/term/index_default_synonyms?groupsize=${GROUP_SIZE} Sample output { message : Indexed synonyms, blocks of 1000 items = success(124) failures(0) , code : 100 } POST /term/get Get one or more terms entry. Requirements The index must exists The function requires user credentials with read permissions on the index Return codes 200 Sample call QUERY=${1:- \\ term\\ } PORT=${2:-8888} INDEX_NAME=${3:-index_getjenny_english_0} curl -v -H Authorization: Basic `echo -n 'test_user:p4ssw0rd' | base64` \\ -H Content-Type: application/json -X POST http://localhost:${PORT}/${INDEX_NAME}/term/get -d { \\ ids\\ : [${QUERY}] } Sample output { terms : [ { vector : [ 1, 2, 3 ], frequency_base : 1.0, frequency_stem : 1.0, term : \u092e\u0930\u093e\u0920\u0940 , antonyms : { bla4 : 0.2, bla3 : 0.1 }, features : { NUM : S , GEN : M }, synonyms : { bla2 : 0.2, bla1 : 0.1 }, tags : tag1 tag2 }, { antonyms : { bla3 : 0.1, bla4 : 0.2 }, features : { NUM : P , GEN : F }, term : term2 , frequency_base : 1.0, frequency_stem : 1.0, vector : [ 1, 2, 3 ], synonyms : { bla1 : 0.1, bla2 : 0.2 }, tags : tag1 tag2 } ] } DELETE /term Delete the term. Requirements The index must exists The function requires user credentials with write permissions on the index Return codes 200 Sample call PORT=${1:-8888} INDEX_NAME=${2:-index_getjenny_english_0} curl -v -H Authorization: Basic `echo -n 'test_user:p4ssw0rd' | base64` \\ -H Content-Type: application/json -X DELETE http://localhost:${PORT}/${INDEX_NAME}/term -d '{ ids : [ \u092e\u0930\u093e\u0920\u0940 , term2 ] }' Sample output { data : [ { dtype : term , version : 2, id : \u092e\u0930\u093e\u0920\u0940 , index : jenny-en-0 , found : true }, { dtype : term , id : term2 , version : 2, found : true, index : jenny-en-0 } ] } Sample call: delete all PORT=${1:-8888} INDEX_NAME=${2:-index_getjenny_english_0} curl -v -H Authorization: Basic `echo -n 'test_user:p4ssw0rd' | base64` \\ -H Content-Type: application/json -X DELETE http://localhost:${PORT}/${INDEX_NAME}/term -d'{ ids : [] }' Sample call: delete all { message : delete , deleted :2 } PUT /term Update the entry. Requirements The index must exists The function requires user credentials with write permissions on the index Return codes 200 Sample call PORT=${1:-8888} INDEX_NAME=${2:-index_getjenny_english_0} curl -v -H Authorization: Basic `echo -n 'test_user:p4ssw0rd' | base64` \\ -H Content-Type: application/json -X PUT http://localhost:${PORT}/${INDEX_NAME}/term -d '{ terms : [ { term : \u092e\u0930\u093e\u0920\u0940 , frequency_base : 1.0, frequency_stem : 1.0, vector : [1.2, 2.3, 3.4, 4.5], synonyms : { bla1 : 0.1, bla2 : 0.2 }, antonyms : { term2 : 0.1, bla4 : 0.2 }, tags : tag1 tag2 , features : { FEATURE_NEW1 : V , GEN : M } }, { term : term2 , frequency_base : 1.0, frequency_stem : 1.0, vector : [1.6, 2.7, 3.8, 5.9], synonyms : { bla1 : 0.1, bla2 : 0.2 }, antonyms : { bla3 : 0.1, bla4 : 0.2 }, tags : tag1 tag2 , features : { FEATURE_NEW1 : N , GEN : F } } ] }' Sample output { data : [ { version : 2, id : \u092e\u0930\u093e\u0920\u0940 , index : jenny-en-0 , created : false, dtype : term }, { index : jenny-en-0 , id : term2 , version : 2, dtype : term , created : false } ] } GET /term/term Search for term (using Elasticsearch). Requirements The index must exists The function requires user credentials with read permissions on the index Return codes 200 Sample call QUERY=${1:- term2 } PORT=${2:-8888} INDEX_NAME=${3:-index_getjenny_english_0} curl -v -H Authorization: Basic `echo -n 'test_user:p4ssw0rd' | base64` \\ -H Content-Type: application/json -X GET http://localhost:${PORT}/${INDEX_NAME}/term/term -d { \\ term\\ : \\ ${QUERY}\\ } Sample output { hits : { terms : [ { vector : [ 1.2, 2.3, 3.4, 4.5 ], antonyms : { bla4 : 0.2, term2 : 0.1 }, frequency_base : 1.0, frequency_stem : 1.0, features : { FEATURE_NEW1 : V , GEN : M }, score : 0.6931471824646, tags : tag1 tag2 , term : \u092e\u0930\u093e\u0920\u0940 , synonyms : { bla2 : 0.2, bla1 : 0.1 } } ] }, total : 1, max_score : 0.6931471824646 } GET /term/text Search for all the terms in the text and return the entries. Requirements The index must exists The function requires user credentials with read permissions on the index Return codes 200 Sample call PORT=${1:-8888} INDEX_NAME=${2:-index_getjenny_english_0} curl -v -H Authorization: Basic `echo -n 'test_user:p4ssw0rd' | base64` \\ -H Content-Type: application/json -X GET http://localhost:${PORT}/${INDEX_NAME}/term/text -d 'term2 \u092e\u0930\u093e\u0920\u0940' Sample output { max_score : 0.6931471824646, hits : { terms : [ { term : \u092e\u0930\u093e\u0920\u0940 , score : 0.6931471824646, tags : tag1 tag2 , vector : [ 1.2, 2.3, 3.4, 4.5 ], features : { GEN : M , FEATURE_NEW1 : V }, antonyms : { bla4 : 0.2, term2 : 0.1 }, synonyms : { bla2 : 0.2, bla1 : 0.1 }, frequency_base : 1.0, frequency_stem : 1.0 }, { term : term2 , tags : tag1 tag2 , score : 0.6931471824646, features : { FEATURE_NEW1 : N , GEN : F }, vector : [ 1.6, 2.7, 3.8, 5.9 ], antonyms : { bla3 : 0.1, bla4 : 0.2 }, frequency_base : 1.0, frequency_stem : 1.0, synonyms : { bla1 : 0.1, bla2 : 0.2 } } ] }, total : 2 } Tokenizers GET /tokenizers Show a list of supported methods for tokenization and stemming Requirements The index must exists The function requires user credentials with read permissions on the index Return codes 200 Sample call PORT=${1:-8888} INDEX_NAME=${2:-index_getjenny_english_0} curl -v -H Authorization: Basic `echo -n 'test_user:p4ssw0rd' | base64` \\ -H Content-Type: application/json -X GET http://localhost:${PORT}/${INDEX_NAME}/tokenizers Sample output { shingles2 : 2 words shingles , shingles3 : 3 words shingles , shingles2_10 : from 2 to 10 shingles , base_stem : lowercase + stemming , base : lowercase , stop : lowercase + stopwords elimination , shingles4 : 4 words shingles , stop_stem : lowercase + stopwords elimination + stemming } POST /tokenizers get a list of token using the selected analyzer Requirements The index must exists The function requires user credentials with read permissions on the index Return codes 200 Sample call ANALYZER=${1:- stop } QUERY=${2:- good morning, may I ask you a question? } PORT=${3:-8888} INDEX_NAME=${4:-index_getjenny_english_0} curl -v -H Authorization: Basic `echo -n 'test_user:p4ssw0rd' | base64` \\ -H Content-Type: application/json -X POST http://localhost:${PORT}/${INDEX_NAME}/tokenizers -d { \\ text\\ : \\ ${QUERY}\\ , \\ tokenizer\\ : \\ ${ANALYZER}\\ } Sample output { tokens : [ { start_offset : 0, end_offset : 4, token_type : word , token : good , position : 0 }, { token : morning , position : 1, token_type : word , end_offset : 12, start_offset : 5 }, { start_offset : 14, end_offset : 17, token_type : word , token : may , position : 2 }, { token_type : word , token : i , position : 3, start_offset : 18, end_offset : 19 }, { end_offset : 23, start_offset : 20, position : 4, token : ask , token_type : word }, { end_offset : 27, start_offset : 24, position : 5, token : you , token_type : word }, { end_offset : 38, start_offset : 30, token : question , position : 7, token_type : word } ] } AnalyzersPlayground POST /analyzers_playground used to test analyzers on the fly Requirements The index must exists The function requires user credentials with read permissions on the index Return codes 200 Sample call keyword ANALYZER=${1:- keyword(\\\\\\ test\\\\\\ ) } QUERY=${2:- this is a test } DATA=${3:- {\\ traversed_states\\ : [], \\ extracted_variables\\ :{}} } PORT=${4:-8888} INDEX_NAME=${5:-index_getjenny_english_0} curl -H Authorization: Basic `echo -n 'test_user:p4ssw0rd' | base64` \\ -H Content-Type: application/json -X POST http://localhost:${PORT}/${INDEX_NAME}/analyzers_playground -d { \\ analyzer\\ : \\ ${ANALYZER}\\ , \\ query\\ : \\ ${QUERY}\\ , \\ data\\ : ${DATA} } Sample output keyword { build_message : success , build : true, value : 0.25 } Sample states analyzers curl -H Authorization: Basic `echo -n 'test_user:p4ssw0rd' | base64` \\ -H 'Content-Type: application/json' -X POST http://localhost:${PORT}/${INDEX_NAME}/analyzers_playground -d ' { analyzer : hasTravState(\\ one\\ ) , query : query , data : { traversed_states : [ one , two ], extracted_variables :{}} } ' Sample output states analyzers { build_message : success , build : true, value : 1 } Sample of pattern extraction through analyzers curl -H Authorization: Basic `echo -n 'test_user:p4ssw0rd' | base64` \\ -H 'Content-Type: application/json' -X POST http://localhost:${PORT}/${INDEX_NAME}/analyzers_playground -d ' { analyzer : band(keyword(\\ on\\ ), matchPatternRegex(\\ [day,month,year](?:(0[1-9]|[12][0-9]|3[01])(?:[- \\\\\\/\\\\.])(0[1-9]|1[012])(?:[- \\\\\\/\\\\.])((?:19|20)\\\\d\\\\d))\\ )) , query : on 31-11-1900 }' Sample output { build_message : success , data : { traversed_states : [], extracted_variables : { month.0 : 11 , year.0 : 1900 , day.0 : 31 } }, value : 1, build : true } SpellCheck POST /spellcheck/terms terms spellchecker based on knowledgebase text Requirements The index must exists The function requires user credentials with read permissions on the index the knowledge base must contain data Return codes 200 Sample call QUERY=${1:- this is a tes for splellchecker } PORT=${2:-8888} INDEX_NAME=${3:-index_getjenny_english_0} curl -v -H Authorization: Basic `echo -n 'test_user:p4ssw0rd' | base64` \\ -H Content-Type: application/json -X POST http://localhost:${PORT}/${INDEX_NAME}/spellcheck/terms -d { \\ text\\ : \\ ${QUERY}\\ , \\ prefix_length\\ : 3, \\ min_doc_freq\\ : 1 } { tokens : [ { offset : 0, options : [ { freq : 1284, score : 0.800000011920929, text : hello }, { text : hella , score : 0.800000011920929, freq : 2 }, { freq : 2, score : 0.800000011920929, text : helle }, { text : help , score : 0.75, freq : 35395 }, { score : 0.75, freq : 5, text : hell } ], length : 5, text : hellp }, { length : 4, options : [], offset : 7, text : this }, { length : 2, options : [], offset : 12, text : is }, { length : 1, offset : 15, options : [], text : a }, { length : 4, offset : 17, options : [ { text : test , score : 0.75, freq : 191 }, { freq : 10, score : 0.5, text : tessa }, { text : tesco , score : 0.5, freq : 9 }, { text : tesia , score : 0.5, freq : 2 }, { freq : 2, score : 0.5, text : tester } ], text : tesr } ] }","title":"APIs"},{"location":"apis/#apis","text":"the api's are now documented using swagger , the documentation below is obsolete and will be deleted after the release of the version v5.0.0","title":"APIs"},{"location":"apis/#systemindexmanagement","text":"","title":"SystemIndexManagement"},{"location":"apis/#post-system_index_managementcreate","text":"Create a new system index, this operation init. a new system index and is required to start using starchat. Output JSON","title":"POST /system_index_management/create"},{"location":"apis/#requirements","text":"The function requires \"admin\" credentials","title":"Requirements"},{"location":"apis/#sample-call","text":"PORT= ${1:-8888} curl -v -H Authorization: Basic `echo -n 'admin:adminp4ssw0rd' | base64` \\ -H Content-Type: application/json -X POST http://localhost:${PORT}/system_index_management/create Sample response: { message : IndexCreation: user(starchat_system_0.user, true) refresh_decisiontable(starchat_system_0.refresh_decisiontable, true) }","title":"Sample call"},{"location":"apis/#get-system_index_management","text":"Fetch and returns the informations about the system index Output JSON","title":"GET /system_index_management"},{"location":"apis/#requirements_1","text":"The function requires \"admin\" credentials","title":"Requirements"},{"location":"apis/#sample-call_1","text":"PORT= ${1:-8888} curl -v -H Authorization: Basic `echo -n 'admin:adminp4ssw0rd' | base64` \\ -H Content-Type: application/json -X GET http://localhost:${PORT}/system_index_management Sample response: { message : IndexCheck: user(starchat_system_0.user, true) refresh_decisiontable(starchat_system_0.refresh_decisiontable, true) }","title":"Sample call"},{"location":"apis/#delete-system_index_management","text":"Delete a system index, this operation destroy any user created Output JSON","title":"DELETE /system_index_management"},{"location":"apis/#requirements_2","text":"The function requires \"admin\" credentials","title":"Requirements"},{"location":"apis/#sample-call_2","text":"PORT= ${1:-8888} curl -v -H Authorization: Basic `echo -n 'admin:adminp4ssw0rd' | base64` \\ -H Content-Type: application/json -X DELETE http://localhost:${PORT}/system_index_management Sample response: { message : IndexDeletion: user(starchat_system_0.user, true) refresh_decisiontable(starchat_system_0.refresh_decisiontable, true) }","title":"Sample call"},{"location":"apis/#user","text":"","title":"User"},{"location":"apis/#post-user","text":"Insert a new user to the system, the user record can be generated using the '/user_gen/test_user' endpoint Output JSON","title":"POST /user"},{"location":"apis/#requirements_3","text":"The function requires \"admin\" credentials","title":"Requirements"},{"location":"apis/#sample-call_3","text":"PORT= ${1:-8888} curl -v -H Authorization: Basic `echo -n 'admin:adminp4ssw0rd' | base64` \\ -H Content-Type: application/json -X POST http://localhost:${PORT}/user -d '{ id : test_user , password : 3c98bf19cb962ac4cd0227142b3495ab1be46534061919f792254b80c0f3e566f7819cae73bdc616af0ff555f7460ac96d88d56338d659ebd93e2be858ce1cf9 , salt : salt , permissions : { index_getjenny_english_0 : [ read , write ] } }' Sample response: { version : 1, created : true, index : starchat_system_0.user , dtype : user , id : test_user }","title":"Sample call"},{"location":"apis/#get-user","text":"Fetch the informations about a user Output JSON","title":"GET /user"},{"location":"apis/#requirements_4","text":"The function requires \"admin\" credentials","title":"Requirements"},{"location":"apis/#sample-call_4","text":"PORT= ${1:-8888} USERNAME=${2:- admin } curl -v -H Authorization: Basic `echo -n 'admin:adminp4ssw0rd' | base64` \\ -H Content-Type: application/json -X GET http://localhost:${PORT}/user/${USERNAME} Sample response: { permissions : { admin : [ admin ] }, salt : salt2 , id : admin , password : ce822ea3bd2ac45ed908f0fac0c81d95df7e59ad554ebed5e173113f5fb97a6c585803233136dd6b16b02742f50dd8cff6fac97ff827394e694f63198618e02c }","title":"Sample call"},{"location":"apis/#put-user","text":"Update a user record Output JSON","title":"PUT /user"},{"location":"apis/#requirements_5","text":"The function requires \"admin\" credentials","title":"Requirements"},{"location":"apis/#sample-call_5","text":"PORT= ${1:-8888} curl -v -H Authorization: Basic `echo -n 'admin:adminp4ssw0rd' | base64` \\ -H Content-Type: application/json -X PUT http://localhost:${PORT}/user/test_user -d '{ permissions : { index_getjenny_english_0 : [ read ] } }' Sample response: { version : 2, created : false, dtype : user , index : starchat_system_0.user , id : test_user }","title":"Sample call"},{"location":"apis/#delete-useruser_id","text":"Delete an existing user Output JSON","title":"DELETE /user/user_id"},{"location":"apis/#requirements_6","text":"The function requires \"admin\" credentials","title":"Requirements"},{"location":"apis/#sample-call_6","text":"PORT= ${1:-8888} curl -v -H Authorization: Basic `echo -n 'admin:adminp4ssw0rd' | base64` \\ -H Content-Type: application/json -X DELETE http://localhost:${PORT}/user/test_user Sample response: { version : 10, dtype : user , id : test_user , index : starchat_system_0.user , found : true }","title":"Sample call"},{"location":"apis/#post-user_gentest_user","text":"Generate the record for a user with hashed password and a randomly generated salt. The user must be then inserted into the system. Output JSON","title":"POST /user_gen/test_user"},{"location":"apis/#requirements_7","text":"The function requires \"admin\" credentials","title":"Requirements"},{"location":"apis/#sample-call_7","text":"PORT=${1:-8888} curl -v -H Authorization: Basic `echo -n 'admin:adminp4ssw0rd' | base64` \\ -H Content-Type: application/json -X POST http://localhost:${PORT}/user_gen/test_user -d '{ password : plain text password , permissions : { index_getjenny_english_0 : [ read ], index_finnish_1 : [ read , write ] } }' Sample response: { password : d4cc0586d5d9116e755f5011d2c03e627821c2596820236ef230ff094176586d05fbfa98a198aaa08935df2849196d2648012f1e40ff2e40ca8c3f627b41e9db , salt : qoKJUyUwpvWM53PI , id : test_user , permissions : { index_finnish_1 : [ read , write ], index_getjenny_english_0 : [ read ] } }","title":"Sample call"},{"location":"apis/#decisiontable","text":"","title":"DecisionTable"},{"location":"apis/#post-get_next_response","text":"Tell StarChat about the user actions (wrote something, clicked a button etc) and receives instruction about the next state. Data to post: { conversation_id : 1234 , user_input : { text : the text typed by the user }, // optional values : { return_value : the value either in success_value or in failure_value (Optional) , data : {} // all the variables, e.g. for the STRING TEMPLATEs (Optional) }, threshold : 0.0, // the minimum match threshold max_results : 4 // the max number of result to return }","title":"POST /get_next_response"},{"location":"apis/#requirements_8","text":"Index must exists The function requires user credentials with read permissions on the index","title":"Requirements"},{"location":"apis/#return-codes","text":"","title":"Return codes"},{"location":"apis/#200","text":"Similar Json, see examples below","title":"200"},{"location":"apis/#example-1","text":"User input is \"how to install starchat\": QUERY=${1:- how to install starchat } PORT=${2:-8888} INDEX_NAME=${3:-index_getjenny_english_0} curl -v -H Authorization: Basic `echo -n 'test_user:p4ssw0rd' | base64` \\ -H Content-Type: application/json -X POST http://localhost:${PORT}/${INDEX_NAME}/get_next_response -d { \\ conversation_id\\ : \\ 1234\\ , \\ user_input\\ : { \\ text\\ : \\ ${QUERY}\\ }, \\ values\\ : { \\ return_value\\ : \\ \\ , \\ data\\ : {\\ varname1\\ : \\ value1\\ , \\ varname2\\ : \\ value2\\ } }, \\ threshold\\ : 0.0, \\ max_results\\ : 4 } returns: [ { bubble : Just choose one of the two:\\n ul \\n li docker install (recommended) /li \\n li standalone install /li \\n /ul , analyzer : band(bor(keyword(\\ setup\\ ), keyword(\\ install.*\\ )), bnot(bor(keyword(\\ standalone\\ ), keyword(\\ docker\\ )))) , state_data : {}, data : { varname1 : value1 , varname2 : value2 }, failure_value : , state : install , traversed_states : [ install ], conversation_id : 1234 , action : , action_input : {}, score : 1, max_state_count : 0, success_value : } ]","title":"Example 1"},{"location":"apis/#example-2","text":"User input is: \"how can I contribute to starchat?\" QUERY=${1:- how can I contribute to starchat? } PORT=${2:-8888} INDEX_NAME=${3:-index_getjenny_english_0} curl -v -H Authorization: Basic `echo -n 'test_user:p4ssw0rd' | base64` \\ -H Content-Type: application/json -X POST http://localhost:${PORT}/${INDEX_NAME}/get_next_response -d { \\ conversation_id\\ : \\ 1234\\ , \\ user_input\\ : { \\ text\\ : \\ ${QUERY}\\ }, \\ values\\ : { \\ return_value\\ : \\ \\ , \\ data\\ : {\\ varname1\\ : \\ value1\\ , \\ varname2\\ : \\ value2\\ } }, \\ threshold\\ : 0.0, \\ max_results\\ : 4 } and gets: [ { analyzer : bor(keyword(\\ contribute\\ )) , state_data : {}, data : { varname2 : value2 , varname1 : value1 }, traversed_states : [ contribute ], conversation_id : 1234 , bubble : To contribute to a href=\\ http://git.io/*chat\\ StarChat /a , please send us a pull request from your fork of this repository.\\n br Our concise contribution guideline contains the bare minimum requirements of the code contributions.\\n br Before contributing (or opening issues), you might want to email us at starchat@getjenny.com. , action : , state : contribute , max_state_count : 0, score : 1, failure_value : , action_input : {}, success_value : } ]","title":"Example 2"},{"location":"apis/#204","text":"No response was found","title":"204"},{"location":"apis/#500-error","text":"Internal server error","title":"500 (error)"},{"location":"apis/#400-error","text":"Bad request: meaning: the input data structure is not valid output data: no data returned","title":"400 (error)"},{"location":"apis/#422-error","text":"meaning: bad request data, the input data is formally valid but there is some issue with data interpretation output data: the output data structure is a json dictionary with two fields: code and message. The following code are supported: code: 100 message: \"error evaluating the template strings, bad values\"","title":"422 (error)"},{"location":"apis/#404-error","text":"meaning: not found output data: no data returned","title":"404 (error)"},{"location":"apis/#get-decisiontable","text":"Get a document by ID Output JSON","title":"GET /decisiontable"},{"location":"apis/#requirements_9","text":"Index must exists The function requires user credentials with read permissions on the index","title":"Requirements"},{"location":"apis/#return-codes_1","text":"","title":"Return codes"},{"location":"apis/#200_1","text":"Sample call # retrieve one or more entries with given ids; ids can be specified multiple times PORT=${1:-8888} INDEX_NAME=${2:-index_getjenny_english_0} # retrieve one or more entries with given ids; ids can be specified multiple times curl -v -H Authorization: Basic `echo -n 'test_user:p4ssw0rd' | base64` \\ -H Content-Type: application/json http://localhost:${PORT}/${INDEX_NAME}/decisiontable?ids=further_details_access_question Sample output { total : 1, hits : [ { document : { failure_value : dont_understand , state : further_details_access_question , bubble : Can you specify which of the following problems you have? [NB works only if buttons can be shown!] , success_value : eval(show_buttons) , action_input : { I want to call an operator : call_operator , Forgot Password : forgot_password , Specify your problem : specify_problem , None of the above : start , Account locked : account_locked }, max_state_count : 0, analyzer : or(and(or(keyword(\\ problem.*\\ ),keyword(\\ issue.*\\ ),keyword(\\ trouble.*\\ )),keyword(\\ account\\ ))) , queries : [ cannot access account , problem access account ], action : show_buttons , state_data : { verification : did you mean you can't access to your account? }, execution_order : 1 }, score : 0 } ], max_score : 0 }","title":"200"},{"location":"apis/#put-decisiontable","text":"Output JSON","title":"PUT /decisiontable"},{"location":"apis/#requirements_10","text":"Index must exists The function requires user credentials with read permissions on the index","title":"Requirements"},{"location":"apis/#return-codes_2","text":"","title":"Return codes"},{"location":"apis/#201","text":"Sample call # update the further_details_access_question entry in the DT PORT=${1:-8888} INDEX_NAME=${2:-index_getjenny_english_0} # update the further_details_access_question entry in the DT curl -v -H Authorization: Basic `echo -n 'test_user:p4ssw0rd' | base64` \\ -H Content-Type: application/json -X PUT http://localhost:${PORT}/${INDEX_NAME}/decisiontable/further_details_access_question -d '{ queries : [ cannot access account , problem access account , unable to access to my account , completely forgot my password ] }' Sample output { dtype : state , created : false, index : index_getjenny_english_0.state , version : 2, id : further_details_access_question }","title":"201"},{"location":"apis/#post-decisiontable","text":"Insert a new document. Output JSON","title":"POST /decisiontable"},{"location":"apis/#requirements_11","text":"Index must exists The function requires user credentials with write permissions on the index","title":"Requirements"},{"location":"apis/#return-codes_3","text":"","title":"Return codes"},{"location":"apis/#201_1","text":"Sample call PORT=${1:-8888} INDEX_NAME=${2:-index_getjenny_english_0} curl -v -H Authorization: Basic `echo -n 'test_user:p4ssw0rd' | base64` \\ -H Content-Type: application/json -X POST http://localhost:${PORT}/${INDEX_NAME}/decisiontable -d '{ state : further_details_access_question , max_state_count : 0, execution_order : 0, analyzer : , queries : [ cannot access account , problem access account ], bubble : What seems to be the problem exactly? , action : show_buttons , action_input : { Forgot Password : forgot_password , Account locked : account_locked , Payment problem : payment_problem , Specify your problem : specify_problem , I want to call an operator : call_operator , None of the above : start }, state_data : {}, success_value : eval(show_buttons) , failure_value : dont_understand }' Sample output { created : true, dtype : state , id : further_details_access_question , index : index_getjenny_english_0.state , version : 1 }","title":"201"},{"location":"apis/#delete-decisiontable","text":"Delete a document by ID Output JSON","title":"DELETE /decisiontable"},{"location":"apis/#requirements_12","text":"Index must exists The function requires user credentials with write permissions on the index","title":"Requirements"},{"location":"apis/#return-codes_4","text":"","title":"Return codes"},{"location":"apis/#200_2","text":"Sample call PORT=${1:-8888} INDEX_NAME=${2:-index_getjenny_english_0} curl -v -H Authorization: Basic `echo -n 'test_user:p4ssw0rd' | base64` \\ -H Content-Type: application/json -X DELETE http://localhost:${PORT}/${INDEX_NAME}/decisiontable/further_details_access_question Sample output { dtype : state , version : 7, found : true, id : further_details_access_question , index : index_getjenny_english_0.state } Sample call: delete all PORT=${1:-8888} INDEX_NAME=${2:-index_getjenny_english_0} curl -v -H Authorization: Basic `echo -n 'test_user:p4ssw0rd' | base64` \\ -H Content-Type: application/json -X DELETE http://localhost:${PORT}/${INDEX_NAME}/decisiontable Sample output: delete all { message : delete , deleted : 18 }","title":"200"},{"location":"apis/#post-decisiontable_upload_csv","text":"upload load a csv file on decisiontable Output JSON","title":"POST /decisiontable_upload_csv"},{"location":"apis/#requirements_13","text":"Index must exists The function requires user credentials with write permissions on the index","title":"Requirements"},{"location":"apis/#return-codes_5","text":"","title":"Return codes"},{"location":"apis/#201_2","text":"Sample call PORT=${1:-8888} INDEX_NAME=${2:-'index_getjenny_english_0'} FILENAME=${3:- `readlink -e ../../doc/decision_table_starchat_doc.csv` } curl -v -H Authorization: Basic `echo -n 'test_user:p4ssw0rd' | base64` \\ -X POST --form csv=@${FILENAME} http://localhost:8888/${INDEX_NAME}/decisiontable_upload_csv Sample output { data : [ { index : index_getjenny_english_0.state , id : help , created : true, dtype : state , version : 1 }, { dtype : state , version : 1, created : true, id : further_details_access_question , index : index_getjenny_english_0.state }, { id : contribute , created : true, index : index_getjenny_english_0.state , dtype : state , version : 1 }, { version : 1, dtype : state , index : index_getjenny_english_0.state , created : true, id : quickstart }, { dtype : state , version : 1, index : index_getjenny_english_0.state , created : true, id : docker_install }, { dtype : state , version : 1, index : index_getjenny_english_0.state , id : create_es_indices , created : true }, { dtype : state , version : 1, id : delete_es_indexes , created : true, index : index_getjenny_english_0.state }, { version : 1, dtype : state , index : index_getjenny_english_0.state , created : true, id : create_es_indexes }, { created : true, id : index_data , index : index_getjenny_english_0.state , dtype : state , version : 1 }, { version : 1, dtype : state , id : index_analyzer , created : true, index : index_getjenny_english_0.state }, { index : index_getjenny_english_0.state , id : load_conf_file , created : true, dtype : state , version : 1 }, { dtype : state , version : 1, created : true, id : install , index : index_getjenny_english_0.state }, { index : index_getjenny_english_0.state , id : standalone_install , created : true, dtype : state , version : 1 }, { dtype : state , version : 1, index : index_getjenny_english_0.state , id : code_78 , created : true }, { index : index_getjenny_english_0.state , id : licence , created : true, dtype : state , version : 1 }, { index : index_getjenny_english_0.state , created : true, id : terrible_feedback , version : 1, dtype : state }, { id : call_operator , created : true, index : index_getjenny_english_0.state , dtype : state , version : 1 }, { version : 1, dtype : state , id : any_further , created : true, index : index_getjenny_english_0.state }, { index : index_getjenny_english_0.state , id : dont_understand , created : true, version : 1, dtype : state } ] }","title":"201"},{"location":"apis/#post-decisiontable_search","text":"Update a document Output JSON","title":"POST /decisiontable_search"},{"location":"apis/#requirements_14","text":"Index must exists The function requires user credentials with read permissions on the index","title":"Requirements"},{"location":"apis/#return-codes_6","text":"","title":"Return codes"},{"location":"apis/#200_3","text":"Sample call Q= ${1:-'cannot access my account'} S= ${2:-0.0} B= ${3:-100.0} PORT=${4:-8888} INDEX_NAME=${5:-index_getjenny_english_0} curl -v -H Authorization: Basic `echo -n 'test_user:p4ssw0rd' | base64` \\ -H Content-Type: application/json -X POST http://localhost:${PORT}/${INDEX_NAME}/decisiontable_search -d { \\ queries\\ : \\ ${Q}\\ , \\ min_score\\ : ${S}, \\ boost_exact_match_factor\\ : ${B}, \\ from\\ : 0, \\ size\\ : 10 } Sample response { max_score : 140.38037109375, total : 1, hits : [ { score : 140.38037109375, document : { action : show_buttons , state_data : { verification : did you mean you can't access to your account? }, success_value : eval(show_buttons) , execution_order : 1, bubble : Can you specify which of the following problems you have? [NB works only if buttons can be shown!] , action_input : { None of the above : start , Forgot Password : forgot_password , I want to call an operator : call_operator , Specify your problem : specify_problem , Account locked : account_locked }, queries : [ cannot access account , problem access account ], failure_value : dont_understand , max_state_count : 0, analyzer : or(and(or(keyword(\\ problem.*\\ ),keyword(\\ issue.*\\ ),keyword(\\ trouble.*\\ )),keyword(\\ account\\ ))) , state : further_details_access_question } } ] }","title":"200"},{"location":"apis/#get-decisiontable_analyzer","text":"Get and return the map of analyzer for each state Output JSON","title":"GET /decisiontable_analyzer"},{"location":"apis/#requirements_15","text":"Index must exists The function requires user credentials with read permissions on the index","title":"Requirements"},{"location":"apis/#return-codes_7","text":"","title":"Return codes"},{"location":"apis/#200_4","text":"Sample call PORT=${1:-8888} INDEX_NAME=${2:-index_getjenny_english_0} curl -v -H Authorization: Basic `echo -n 'test_user:p4ssw0rd' | base64` \\ -H Content-Type: application/json -X GET http://localhost:${PORT}/${INDEX_NAME}/decisiontable_analyzer Sample response { analyzer_map : { help : { execution_order : 1, build : true, analyzer : band(keyword(\\ help\\ )) }, contribute : { build : true, analyzer : bor(keyword(\\ contribute\\ )) , execution_order : 1 }, index_analyzer : { analyzer : band(bor(keyword(\\ index\\ ),keyword(\\ load\\ )), keyword(\\ analyzer\\ )) , build : true, execution_order : 1 }, further_details_access_question : { analyzer : or(and(or(keyword(\\ problem.*\\ ),keyword(\\ issue.*\\ ),keyword(\\ trouble.*\\ )),keyword(\\ account\\ ))) , build : true, execution_order : 1 }, create_es_indices : { analyzer : band(keyword(\\ create\\ ), keyword(\\ elastic.*\\ ), bor(keyword(\\ index\\ ), keyword(\\ indices\\ ), keyword(\\ indeces\\ ), keyword(\\ indexes\\ ))) , build : true, execution_order : 1 }, create_es_indexes : { build : true, analyzer : band(keyword(\\ create\\ ), bor(keyword(\\ index.*\\ ), keyword(\\ indic.*\\ ))) , execution_order : 1 }, call_operator : { analyzer : band(bor(keyword(\\ call\\ ),keyword(\\ talk\\ ),keyword(\\ speak\\ )),keyword(\\ operator\\ )) , build : true, execution_order : 1 }, index_data : { execution_order : 1, analyzer : band(keyword(\\ index\\ ), keyword(\\ data\\ )) , build : true }, install : { execution_order : 1, build : true, analyzer : band(bor(keyword(\\ setup\\ ), keyword(\\ install.*\\ )), bnot(bor(keyword(\\ standalone\\ ), keyword(\\ docker\\ )))) }, load_conf_file : { execution_order : 1, analyzer : band(keyword(\\ load.*\\ ), bor(keyword(\\ config.*\\ ), band(keyword(\\ decision\\ ), keyword(\\ table\\ ))), keyword(\\ file.*\\ )) , build : true }, docker_install : { execution_order : 1, analyzer : band(keyword(\\ docker\\ ), keyword(\\ install.*\\ )) , build : true }, delete_es_indexes : { execution_order : 1, build : true, analyzer : band(keyword(\\ delete\\ ), bor(keyword(\\ index.*\\ ), keyword(\\ indic.*\\ ))) }, code_78 : { analyzer : band(keyword(\\ code\\ ),keyword(\\ 78\\ )) , build : true, execution_order : 1 }, terrible_feedback : { execution_order : 1, build : true, analyzer : booleanor(keyword(\\ idiot\\ ), keyword(\\ fuck.*\\ ), keyword(\\ screw\\ ), keyword(\\ damn.*\\ ), keyword(\\ asshole\\ )) }, standalone_install : { analyzer : band(keyword(\\ standal.*\\ ), keyword(\\ install\\ )) , build : true, execution_order : 1 }, quickstart : { execution_order : 1, build : true, analyzer : band(bor(keyword(\\ start\\ ), keyword(\\ quickstart\\ )), keyword(\\ starchat\\ )) }, licence : { build : true, analyzer : bor(band(keyword(\\ open\\ ), keyword(\\ source\\ )), keyword(\\ opensource\\ ), keyword(\\ licence\\ )) , execution_order : 1 } } }","title":"200"},{"location":"apis/#post-decisiontable_analyzer","text":"trigger a syncronous load/reload the analyzers map from ES Output JSON","title":"POST /decisiontable_analyzer"},{"location":"apis/#requirements_16","text":"Index must exists The function requires user credentials with write permissions on the index","title":"Requirements"},{"location":"apis/#return-codes_8","text":"","title":"Return codes"},{"location":"apis/#200_5","text":"Sample call PORT=${1:-8888} INDEX_NAME=${2:-index_getjenny_english_0} curl -v -H Authorization: Basic `echo -n 'test_user:p4ssw0rd' | base64` \\ -H Content-Type: application/json -X POST http://localhost:${PORT}/${INDEX_NAME}/decisiontable_analyzer Sample response { num_of_entries : 17 }","title":"200"},{"location":"apis/#post-decisiontable_async_reload","text":"trigger an asyncronous load/reload the analyzers map from ES Output JSON","title":"POST /decisiontable_async_reload"},{"location":"apis/#requirements_17","text":"Index must exists The function requires user credentials with write permissions on the index","title":"Requirements"},{"location":"apis/#return-codes_9","text":"","title":"Return codes"},{"location":"apis/#200_6","text":"Sample call PORT=${1:-8888} INDEX_NAME=${2:-index_getjenny_english_0} curl -v -H Authorization: Basic `echo -n 'test_user:p4ssw0rd' | base64` \\ -H Content-Type: application/json -X POST https://starchat-cluster-0.getjenny.com/${INDEX_NAME}/decisiontable_async_reload Sample response { timestamp : 1540281692630, indexName : index_getjenny_english_0 }","title":"200"},{"location":"apis/#questionanswer-knowledgebase-priordata-conversationlogs","text":"The following REST endpoints have the same syntax and semantic for KnowledgeBase, PriorData, ConversationLogs. The only difference is the route path component: KnowledgeBase: \"knowledgebase\" Priodata: \"prior_data\" * ConversationLogs: \"conversation_logs\" In the API description we will refer to this path component as","title":"QuestionAnswer (KnowledgeBase, PriorData, ConversationLogs)"},{"location":"apis/#get","text":"Return a document by ID Output JSON","title":"GET /"},{"location":"apis/#requirements_18","text":"Index must exists The function requires user credentials with read permissions on the index","title":"Requirements"},{"location":"apis/#return-codes_10","text":"","title":"Return codes"},{"location":"apis/#200_7","text":"Sample call ID=${1:-0} PORT=${2:-8888} INDEX_NAME=${3:-index_getjenny_english_0} # retrieve one or more entries with given ids; ids can be specified multiple times curl -v -H Authorization: Basic `echo -n 'test_user:p4ssw0rd' | base64` \\ -H Content-Type: application/json http://localhost:${PORT}/${INDEX_NAME}/knowledgebase?ids=${ID} Sample response { max_score : 0, total : 1, hits : [ { score : 0, document : { conversation : id:1000 , id : 0 , status : 0, question_scored_terms : [ [ thank , 1.09 ] ], verified : true, answer : you are welcome! , topics : t1 t2 , doctype : normal , index_in_conversation : 1, question : thank you , question_negative : [ thank you anyway ], state : } } ] }","title":"200"},{"location":"apis/#post","text":"Insert a new document","title":"POST /"},{"location":"apis/#requirements_19","text":"Index must exists The function requires user credentials with write permissions on the index","title":"Requirements"},{"location":"apis/#return-codes_11","text":"","title":"Return codes"},{"location":"apis/#201_3","text":"PORT=${1:-8888} INDEX_NAME=${2:-index_getjenny_english_0} curl -v -H Authorization: Basic `echo -n 'test_user:p4ssw0rd' | base64` \\ -H Content-Type: application/json -X POST http://localhost:${PORT}/${INDEX_NAME}/knowledgebase -d '{ id : 0 , conversation : id:1000 , index_in_conversation : 1, question : thank you , question_negative : [ ok, I will not talk with you anymore , thank you anyway ], answer : you are welcome! , question_scored_terms : [ [ currently , 1.0901874131103333 ], [ installing , 2.11472759638322 ], [ mac , 9.000484252244254 ], [ reset , 4.34483238516225 ], [ app , 1.2219061535961406 ], [ device , 2.1679468390743414E-213 ], [ devices , 4.1987625801077624E-268 ] ], verified : true, topics : t1 t2 , doctype : normal , state : , status : 0 }' Sample response { created : true, dtype : question , version : 1, index : index_getjenny_english_0.question , id : 0 }","title":"201"},{"location":"apis/#delete","text":"Delete a document by ID Output JSON","title":"DELETE /"},{"location":"apis/#requirements_20","text":"Index must exists The function requires user credentials with write permissions on the index","title":"Requirements"},{"location":"apis/#return-codes_12","text":"","title":"Return codes"},{"location":"apis/#200_8","text":"Sample call PORT=${1:-8888} INDEX_NAME=${2:-index_getjenny_english_0} curl -v -H Authorization: Basic `echo -n 'test_user:p4ssw0rd' | base64` \\ -H Content-Type: application/json -X DELETE http://localhost:${PORT}/${INDEX_NAME}/knowledgebase/0 Sample output { dtype : question , version : 5, found : false, id : 0 , index : index_getjenny_english_0.question } Sample call: delete all PORT=${1:-8888} INDEX_NAME=${2:-index_getjenny_english_0} curl -v -H Authorization: Basic `echo -n 'test_user:p4ssw0rd' | base64` \\ -H Content-Type: application/json -X DELETE http://localhost:${PORT}/${INDEX_NAME}/knowledgebase Sample output: delete all { message : delete , deleted : 2 }","title":"200"},{"location":"apis/#put","text":"Update an existing document Output JSON","title":"PUT /"},{"location":"apis/#requirements_21","text":"Index must exists The function requires user credentials with write permissions on the index","title":"Requirements"},{"location":"apis/#return-codes_13","text":"","title":"Return codes"},{"location":"apis/#200_9","text":"Sample call PORT=${1:-8888} INDEX_NAME=${2:-index_getjenny_english_0} curl -v -H Authorization: Basic `echo -n 'test_user:p4ssw0rd' | base64` \\ -H Content-Type: application/json -X PUT http://localhost:${PORT}/${INDEX_NAME}/knowledgebase/0 -d '{ conversation : id:1001 , question : thank you , answer : you are welcome! , verified : true, topics : t1 t2 , doctype : normal , state : , status : 0 }' Sample response { dtype : question , index : index_getjenny_english_0.question , id : 0 , version : 4, created : false }","title":"200"},{"location":"apis/#post-_search","text":"Output JSON","title":"POST /_search"},{"location":"apis/#requirements_22","text":"Index must exists The function requires user credentials with read permissions on the index","title":"Requirements"},{"location":"apis/#return-codes_14","text":"","title":"Return codes"},{"location":"apis/#200_10","text":"Sample call QUERY=${1:- how are you? } PORT=${2:-8888} INDEX_NAME=${3:-index_getjenny_english_0} curl -v -H Authorization: Basic `echo -n 'test_user:p4ssw0rd' | base64` \\ -H Content-Type: application/json -X POST http://localhost:${PORT}/${INDEX_NAME}/knowledgebase_search -d { \\ question\\ : \\ ${QUERY}\\ , \\ doctype\\ : \\ normal\\ , \\ min_score\\ : 0.0 } Sample output { hits : [ { document : { question_scored_terms : [ [ currently , 1.09018741311033 ], [ installing , 2.11472759638322 ], [ mac , 9.00048425224425 ], [ reset , 4.34483238516225 ], [ app , 1.22190615359614 ], [ device , 2.16794683907434e-213 ], [ devices , 4.19876258010776e-268 ] ], question : thank you , id : 0 , state : , conversation : id:1001 , answer : you are welcome! , topics : t1 t2 , index_in_conversation : 1, doctype : normal , status : 0, verified : true, question_negative : [ ok, I will not talk with you anymore , thank you anyway ] }, score : 0.287682086229324 } ], total : 1, max_score : 0.287682086229324 }","title":"200"},{"location":"apis/#get-term_count","text":"Count the occurrence of a term. The endpoint supports the following query arguments: field: can be \"answer\" or \"question\" (optional, default question) stale: represent the max stale time in millis ; 0 means no cache (Optional) * term: the term to count (mandatory) Output JSON","title":"GET /term_count/"},{"location":"apis/#requirements_23","text":"Index must exists The function requires user credentials with read permissions on the index","title":"Requirements"},{"location":"apis/#return-codes_15","text":"","title":"Return codes"},{"location":"apis/#200_11","text":"Sample call TERM=${1:- hello } ROUTE=${2:-knowledgebase} INDEX_NAME=${3:-index_getjenny_english_0} FIELD=${4:- question } PORT=${5:-8888} curl -v -H Authorization: Basic $(echo -n 'test_user:p4ssw0rd' | base64) \\ -H Content-Type: application/json -X GET http://localhost:${PORT}/${INDEX_NAME}/term_count/${ROUTE}?field=${FIELD} term=${TERM} Sample response { numDocs : 994, count : 1037 }","title":"200"},{"location":"apis/#get-dict_size","text":"Measure the dictionary size: number of unique terms on question and answer field The endpoint supports the following query arguments: * stale: represent the max stale time in millis ; 0 means no cache (Optional) Output JSON","title":"GET /dict_size/"},{"location":"apis/#requirements_24","text":"Index must exists The function requires user credentials with read permissions on the index","title":"Requirements"},{"location":"apis/#return-codes_16","text":"","title":"Return codes"},{"location":"apis/#200_12","text":"Sample call PORT=${1:-8888} DATATYPE=${2:-knowledgebase} INDEX_NAME=${3:-index_getjenny_english_0} curl -v -H Authorization: Basic $(echo -n 'test_user:p4ssw0rd' | base64) \\ -H Content-Type: application/json -X GET http://localhost:${PORT}/${INDEX_NAME}/dict_size/${DATATYPE} Sample response { numDocs : 135865, answer : 9171, question : 25200, total : 29258 }","title":"200"},{"location":"apis/#get-total_terms","text":"calculate the total number of terms The endpoint supports the following query arguments: * stale: represent the max stale time in millis ; 0 means no cache (Optional) Output JSON","title":"GET /total_terms/"},{"location":"apis/#requirements_25","text":"Index must exists The function requires user credentials with read permissions on the index","title":"Requirements"},{"location":"apis/#return-codes_17","text":"","title":"Return codes"},{"location":"apis/#200_13","text":"Sample call PORT=${1:-8888} INDEX_NAME=${2:-index_getjenny_english_0} DATATYPE=${3:-knowledgebase} curl -v -H Authorization: Basic $(echo -n 'test_user:p4ssw0rd' | base64) \\ -H Content-Type: application/json -X GET http://localhost:${PORT}/${INDEX_NAME}/total_terms/${DATATYPE} Sample response { question : 821982, numDocs : 135865, answer : 1098490 }","title":"200"},{"location":"apis/#get-cache","text":"return the cache counter parameters and the number of elements in cache Output JSON","title":"GET /cache/"},{"location":"apis/#requirements_26","text":"Index must exists The function requires user credentials with read permissions on the index","title":"Requirements"},{"location":"apis/#return-codes_18","text":"","title":"Return codes"},{"location":"apis/#200_14","text":"Sample call INDEX_NAME=${1:-index_getjenny_english_0} PORT=${2:-8888} ROUTE=${3:-knowledgebase} curl -v -H Authorization: Basic $(echo -n 'admin:adminp4ssw0rd' | base64) \\ -H Content-Type: application/json -X GET http://localhost:${PORT}/${INDEX_NAME}/cache/${ROUTE} Sample response [ { totalTermsCacheMaxSize : 1000, countTermCacheMaxSize : 100000, dictSizeCacheMaxSize : 1000, cacheStealTimeMillis : 43200000 }, { countTermCacheSize : 0, dictSizeCacheSize : 0, totalTermsCacheSize : 0 } ]","title":"200"},{"location":"apis/#post-cache","text":"set the cache counter parameters Output JSON","title":"POST /cache/"},{"location":"apis/#requirements_27","text":"Index must exists The function requires user credentials with read permissions on the index","title":"Requirements"},{"location":"apis/#return-codes_19","text":"","title":"Return codes"},{"location":"apis/#200_15","text":"Sample call INDEX_NAME=${1:-index_getjenny_english_0} PORT=${2:-8888} ROUTE=${3:-knowledgebase} curl -v -H Authorization: Basic $(echo -n 'admin:adminp4ssw0rd' | base64) \\ -H Content-Type: application/json -X POST http://localhost:${PORT}/${INDEX_NAME}/cache/${ROUTE} -d'{ dictSizeCacheMaxSize : 1000, totalTermsCacheMaxSize : 1000, countTermCacheMaxSize : 100000, cacheStealTimeMillis : 43200000 }' Sample response { totalTermsCacheMaxSize : 1000, dictSizeCacheMaxSize : 1000, countTermCacheMaxSize : 100000, cacheStealTimeMillis : 43200000 }","title":"200"},{"location":"apis/#delete-cache","text":"reset the cache for counters Output JSON","title":"DELETE /cache/"},{"location":"apis/#requirements_28","text":"Index must exists The function requires user credentials with read permissions on the index","title":"Requirements"},{"location":"apis/#return-codes_20","text":"","title":"Return codes"},{"location":"apis/#200_16","text":"Sample call INDEX_NAME=${1:-index_getjenny_english_0} PORT=${2:-8888} ROUTE=${3:-knowledgebase} curl -v -H Authorization: Basic $(echo -n 'admin:adminp4ssw0rd' | base64) \\ -H Content-Type: application/json -X DELETE http://localhost:${PORT}/${INDEX_NAME}/cache/${ROUTE} Sample response [ { countTermCacheMaxSize : 100000, totalTermsCacheMaxSize : 1000, dictSizeCacheMaxSize : 1000, cacheStealTimeMillis : 43200000 }, { totalTermsCacheSize : 0, dictSizeCacheSize : 0, countTermCacheSize : 0 } ]","title":"200"},{"location":"apis/#put-updateterms","text":"update the manaus terms for a QuestionAnswer document Output JSON","title":"PUT /updateTerms/"},{"location":"apis/#requirements_29","text":"Index must exists The document to update must exists The function requires user credentials with read permissions on the index","title":"Requirements"},{"location":"apis/#return-codes_21","text":"","title":"Return codes"},{"location":"apis/#200_17","text":"Sample call DOCID=${1:-0} PORT=${2:-8888} INDEX_NAME=${3:-index_getjenny_english_0} ROUTE=${4:-knowledgebase} curl -v -H Authorization: Basic $(echo -n 'test_user:p4ssw0rd' | base64) \\ -H Content-Type: application/json -X PUT http://localhost:${PORT}/${INDEX_NAME}/updateTerms/${ROUTE} -d { \\ id\\ : \\ ${DOCID}\\ } Sample response [ { id : 0 , created : false, dtype : question_answer , version : 2, index : index_getjenny_english_0.question_answer } ]","title":"200"},{"location":"apis/#get-updateterms","text":"update the manaus terms for all the QuestionAnswer documents Output JSON","title":"GET /updateTerms/"},{"location":"apis/#requirements_30","text":"Index must exists The user has stream permissions on the index The function requires user credentials with read permissions on the index","title":"Requirements"},{"location":"apis/#return-codes_22","text":"","title":"Return codes"},{"location":"apis/#200_18","text":"Sample call PORT=${1:-8888} INDEX_NAME=${2:-index_getjenny_english_0} ROUTE=${3:-knowledgebase} curl -v -H Authorization: Basic $(echo -n 'test_user:p4ssw0rd' | base64) \\ -H Content-Type: application/json -X GET http://localhost:${PORT}/${INDEX_NAME}/updateTerms/${ROUTE} -d'{ id : }' Sample response { dtype : question_answer , version :2, id : 3bcafc79400f201bcbb2e9290d60231fb096845d97cd3a83b032eab90a9b6f8f , index : index_getjenny_english_0.question_answer , created :false} { dtype : question_answer , version :2, id : f5239013416fc98c558560659b00ec96e694df243aace574e9dd32166e982ccd , index : index_getjenny_english_0.question_answer , created :false} { dtype : question_answer , version :2, id : 23cb4dc14284b278867b743d6e7387a3ba20e96afb4a34ddf58a8397b173a24f , index : index_getjenny_english_0.question_answer , created :false} { dtype : question_answer , version :2, id : 5f948728fbca7617907ab4ad031020f9da214926f2fbe272295c799d568a3491 , index : index_getjenny_english_0.question_answer , created :false} { dtype : question_answer , version :2, id : cfb544023bcc1378a59695bc6135fb7b71bfcdaba6fb2429e151aba73b2774b8 , index : index_getjenny_english_0.question_answer , created :false} { dtype : question_answer , version :2, id : cce15f6984f473fe7534f9e0f699e5e11a61e39cbe82989818a023d626ea5e1f , index : index_getjenny_english_0.question_answer , created :false} { dtype : question_answer , version :2, id : b37db2bef879f22d3792840efa1a41b1d46cdbee4af5ccb1b935b3c944732544 , index : index_getjenny_english_0.question_answer , created :false}","title":"200"},{"location":"apis/#termsextraction","text":"","title":"TermsExtraction"},{"location":"apis/#post-extractionfrequencies","text":"Extract term frequencies from a sentence The fields of the data structure have the following meaning: commonOrSpecificSearchPrior: specify if the prior_data table is from the common index or is index specific. Values are COMMON or IDXSPECIFIC commonOrSpecificSearchObserved: specify if the knowledgebase table is from the common index or is index specific. Values are COMMON or IDXSPECIFIC observedDataSource: specify which table should be considered for observed data, values are KNOWLEDGEBASE or CONV_LOGS fieldsPrior: specify the fields which must be considered, values are question, answer, all fieldsObserved: specify the fields which must be considered, values are question, answer, all Output JSON","title":"POST /extraction/frequencies"},{"location":"apis/#requirements_31","text":"Index must exists The function requires user credentials with read permissions on the index","title":"Requirements"},{"location":"apis/#return-codes_23","text":"","title":"Return codes"},{"location":"apis/#200_19","text":"Sample call QUERY=${1:- good morning, may I ask you a question? } PORT=${2:-8888} INDEX_NAME=${4:-index_getjenny_english_0} curl -v -H Authorization: Basic $(echo -n 'test_user:p4ssw0rd' | base64) \\ -H Content-Type: application/json -X POST http://localhost:${PORT}/${INDEX_NAME}/extraction/frequencies -d { \\ text\\ : \\ ${QUERY}\\ , \\ commonOrSpecificSearchPrior\\ : \\ COMMON\\ , \\ commonOrSpecificSearchObserved\\ : \\ IDXSPECIFIC\\ , \\ observedDataSource\\ : \\ KNOWLEDGEBASE\\ , \\ fieldsPrior\\ : \\ all\\ , \\ fieldsObserved\\ : \\ all\\ , \\ tokenizer\\ : \\ space_punctuation\\ } Sample output { observedTotalTerms : 1920472, priorTotalTerms : 2311033, tokensFreq : [ { observedFrequency : 1187, token : good , priorFrequency : 7024 }, { priorFrequency : 1228, token : morning , observedFrequency : 246 }, { priorFrequency : 1343, observedFrequency : 4185, token : may }, { observedFrequency : 68554, token : i , priorFrequency : 79384 }, { priorFrequency : 1377, observedFrequency : 471, token : ask }, { priorFrequency : 93571, observedFrequency : 79470, token : you }, { priorFrequency : 47701, token : a , observedFrequency : 25688 }, { observedFrequency : 539, token : question , priorFrequency : 525 } ] }","title":"200"},{"location":"apis/#post-extractionfrequencies_1","text":"Extract manaus terms from a sentence The fields of the data structure have the following meaning: commonOrSpecificSearchPrior: specify if the prior_data table is from the common index or is index specific. Values are COMMON or IDXSPECIFIC commonOrSpecificSearchObserved: specify if the knowledgebase table is from the common index or is index specific. Values are COMMON or IDXSPECIFIC observedDataSource: specify which table should be considered for observed data, values are KNOWLEDGEBASE or CONV_LOGS fieldsPrior: specify the fields which must be considered, values are question, answer, all fieldsObserved: specify the fields which must be considered, values are question, answer, all Output JSON","title":"POST /extraction/frequencies"},{"location":"apis/#requirements_32","text":"Index must exists The function requires user credentials with read permissions on the index","title":"Requirements"},{"location":"apis/#return-codes_24","text":"","title":"Return codes"},{"location":"apis/#200_20","text":"Sample call QUERY=${1:- good morning, may I ask you a question? } PORT=${2:-8888} INDEX_NAME=${4:-index_getjenny_english_0} curl -v -H Authorization: Basic $(echo -n 'test_user:p4ssw0rd' | base64) \\ -H Content-Type: application/json -X POST http://localhost:${PORT}/${INDEX_NAME}/extraction/keywords -d { \\ text\\ : \\ ${QUERY}\\ , \\ commonOrSpecificSearchPrior\\ : \\ COMMON\\ , \\ commonOrSpecificSearchObserved\\ : \\ IDXSPECIFIC\\ , \\ observedDataSource\\ : \\ KNOWLEDGEBASE\\ , \\ fieldsPrior\\ : \\ all\\ , \\ fieldsObserved\\ : \\ all\\ , \\ minWordsPerSentence\\ : 5, \\ pruneTermsThreshold\\ : 100000, \\ misspellMaxOccurrence\\ : 10, \\ activePotentialDecay\\ : 1, \\ activePotential\\ : true, \\ totalInfo\\ : true } Sample output { question : 0.229660917208135 }","title":"200"},{"location":"apis/#post-extractionsynonyms","text":"Tokenize a sentence, extract terms and decorate each term with manaus informations and the possible synonyms using a vector model. The fields of the data structure have the following meaning: text: the text to analyze tokenizer: the tokenizer, default is \"base\" sentencesThreshold: discard sentences if the sentence with the synonym is below the threshold, default us 0.0 synonymsThreshold: discard the synonyms if the distance is below the threshold, default is 0.0 distanceFunction: a distance function values are SUMCOSINE (sum of word vectors) or EMDCOSINE (Earth movers distance) commonOrSpecificSearchTerms: specify if the terms table is from the common index or is index specific. Values are COMMON or IDXSPECIFIC commonOrSpecificSearchPrior: specify if the prior_data table is from the common index or is index specific. Values are COMMON or IDXSPECIFIC commonOrSpecificSearchObserved: specify if the knowledgebase table is from the common index or is index specific. Values are COMMON or IDXSPECIFIC observedDataSource: specify which table should be considered for observed data, values are KNOWLEDGEBASE or CONV_LOGS fieldsPrior: specify the fields which must be considered, values are question, answer, all fieldsObserved: specify the fields which must be considered, values are question, answer, all minWordsPerSentence: manaus parameter, ignore sentences with less than N terms, default is 10 pruneTermsThreshold: manaus parameter, a threshold on the number of terms for trigger pruning, default value is 100000 misspellMaxOccurrence: manaus parameter, discard terms with a frequency below the threshold, default is 5 activePotentialDecay: manaus parameter, a decay value for the active potential activePotential: manaus parameter, tell wether to calculate the active potential or not, default is true minSentenceInfoBit: min number of information bits for the sentence minKeywordInfo: min number of information bits for a word totalInfo: manaus parameter, tell wether to consider the total info or not, default is true Output JSON","title":"POST /extraction/synonyms"},{"location":"apis/#requirements_33","text":"Index must exists The function requires user credentials with read permissions on the index","title":"Requirements"},{"location":"apis/#return-codes_25","text":"","title":"Return codes"},{"location":"apis/#200_21","text":"Sample call QUERY=${1:- good morning, may I ask you a question? } PORT=${2:-8888} INDEX_NAME=${4:-index_getjenny_english_0} curl -v -H Authorization: Basic $(echo -n 'test_user:p4ssw0rd' | base64) \\ -H Content-Type: application/json -X POST http://localhost:${PORT}/${INDEX_NAME}/extraction/synonyms -d { \\ text\\ : \\ ${QUERY}\\ , \\ tokenizer\\ : \\ base\\ , \\ sentencesThreshold\\ : 0.9, \\ synonymsThreshold\\ : 0.3, \\ distanceFunction\\ : \\ EMDCOSINE\\ , \\ commonOrSpecificSearchPrior\\ : \\ COMMON\\ , \\ commonOrSpecificSearchObserved\\ : \\ IDXSPECIFIC\\ , \\ observedDataSource\\ : \\ KNOWLEDGEBASE\\ , \\ fieldsPrior\\ : \\ all\\ , \\ fieldsObserved\\ : \\ all\\ , \\ minWordsPerSentence\\ : 5, \\ pruneTermsThreshold\\ : 100000, \\ misspellMaxOccurrence\\ : 10, \\ activePotentialDecay\\ : 1, \\ activePotential\\ : true, \\ totalInfo\\ : true } Sample output [ { synonymItem : [ { termSimilarityScore : 0.303461623209445, synonym : serious , synonymScore : 0.988391942416316, textDistanceWithSynonym : 0.988391942416316 }, { textDistanceWithSynonym : 0.98686397528116, synonymScore : 0.98686397528116, synonym : safe , termSimilarityScore : 0.310671998517923 }, { textDistanceWithSynonym : 0.986168126185455, synonymScore : 0.986168126185455, synonym : effective , termSimilarityScore : 0.337205437720856 }, { textDistanceWithSynonym : 0.985984970241292, synonymScore : 0.985984970241292, termSimilarityScore : 0.30013467985373, synonym : salutary }, { textDistanceWithSynonym : 0.985895039899644, synonymScore : 0.985895039899644, termSimilarityScore : 0.301306430755499, synonym : dear }, { termSimilarityScore : 0.319592899798586, synonym : estimable , synonymScore : 0.985759252837724, textDistanceWithSynonym : 0.985759252837724 }, { textDistanceWithSynonym : 0.985249380845675, synonymScore : 0.985249380845675, synonym : thoroughly , termSimilarityScore : 0.337964488042003 }, { termSimilarityScore : 0.360057098563907, synonym : right , synonymScore : 0.984778611750602, textDistanceWithSynonym : 0.984778611750602 }, { textDistanceWithSynonym : 0.984227558357218, synonymScore : 0.984227558357218, synonym : adept , termSimilarityScore : 0.330252861229703 }, { termSimilarityScore : 0.360657543519664, synonym : expert , synonymScore : 0.984204967194361, textDistanceWithSynonym : 0.984204967194361 }, { synonymScore : 0.9839801846329, textDistanceWithSynonym : 0.9839801846329, termSimilarityScore : 0.387968844459879, synonym : full }, { synonymScore : 0.983341764529566, textDistanceWithSynonym : 0.983341764529566, termSimilarityScore : 0.307056458999165, synonym : skilful }, { synonym : secure , termSimilarityScore : 0.386750372411043, synonymScore : 0.9828697525105, textDistanceWithSynonym : 0.9828697525105 }, { termSimilarityScore : 0.436633496912848, synonym : near , textDistanceWithSynonym : 0.9823153867721, synonymScore : 0.9823153867721 }, { textDistanceWithSynonym : 0.98229857645758, synonymScore : 0.98229857645758, termSimilarityScore : 0.387852275460498, synonym : soundly }, { textDistanceWithSynonym : 0.981854513089778, synonymScore : 0.981854513089778, termSimilarityScore : 0.375971735071977, synonym : sound }, { textDistanceWithSynonym : 0.981012225642823, synonymScore : 0.981012225642823, termSimilarityScore : 0.349548530861366, synonym : unspoiled }, { textDistanceWithSynonym : 0.980134947418645, synonymScore : 0.980134947418645, synonym : honorable , termSimilarityScore : 0.36656103347195 }, { synonym : ripe , termSimilarityScore : 0.361927513363036, synonymScore : 0.979828029318668, textDistanceWithSynonym : 0.979828029318668 }, { termSimilarityScore : 0.354594107764147, synonym : proficient , synonymScore : 0.97897497858666, textDistanceWithSynonym : 0.97897497858666 }, { synonym : commodity , termSimilarityScore : 0.400576579081682, synonymScore : 0.978353047238428, textDistanceWithSynonym : 0.978353047238428 }, { textDistanceWithSynonym : 0.978097513490299, synonymScore : 0.978097513490299, synonym : practiced , termSimilarityScore : 0.417713639606198 }, { synonym : unspoilt , termSimilarityScore : 0.344935826089365, textDistanceWithSynonym : 0.977965860781802, synonymScore : 0.977965860781802 }, { textDistanceWithSynonym : 0.977574200871494, synonymScore : 0.977574200871494, termSimilarityScore : 0.368691045104583, synonym : upright } ], isKeywordToken : false, keywordExtractionScore : 0, token : { position : 0, token : good , token_type : ALPHANUM , start_offset : 0, end_offset : 4 } }, { keywordExtractionScore : 0, token : { position : 1, end_offset : 12, token : morning , token_type : ALPHANUM , start_offset : 5 }, synonymItem : [ { synonymScore : 0.982435251017214, textDistanceWithSynonym : 0.982435251017214, termSimilarityScore : 0.328796456566772, synonym : dawning }, { termSimilarityScore : 0.320363553861273, synonym : sunup , textDistanceWithSynonym : 0.981187446721127, synonymScore : 0.981187446721127 }, { synonymScore : 0.980827133578433, textDistanceWithSynonym : 0.980827133578433, termSimilarityScore : 0.351556981730201, synonym : cockcrow }, { synonym : dayspring , termSimilarityScore : 0.348148650582253, textDistanceWithSynonym : 0.98000434808506, synonymScore : 0.98000434808506 }, { synonym : morn , termSimilarityScore : 0.310762418953851, textDistanceWithSynonym : 0.979694497080588, synonymScore : 0.979694497080588 }, { synonymScore : 0.975365086887233, textDistanceWithSynonym : 0.975365086887233, synonym : aurora , termSimilarityScore : 0.403555992661807 }, { synonym : first_light , termSimilarityScore : 0.389117497640442, synonymScore : 0.973279032352032, textDistanceWithSynonym : 0.973279032352032 } ], isKeywordToken : false }, { keywordExtractionScore : 0, token : { position : 2, end_offset : 17, token : may , token_type : ALPHANUM , start_offset : 14 }, synonymItem : [ { textDistanceWithSynonym : 0.977735408571704, synonymScore : 0.977735408571704, termSimilarityScore : 0.430110506850729, synonym : whitethorn } ], isKeywordToken : false }, { keywordExtractionScore : 0, token : { position : 3, end_offset : 19, token_type : ALPHANUM , start_offset : 18, token : i }, synonymItem : [ { synonymScore : 0.990079660169983, textDistanceWithSynonym : 0.990079660169983, termSimilarityScore : 0.33685060765497, synonym : one }, { termSimilarityScore : 0.402164830285073, synonym : single , textDistanceWithSynonym : 0.982443662914587, synonymScore : 0.982443662914587 }, { synonymScore : 0.978915403087889, textDistanceWithSynonym : 0.978915403087889, termSimilarityScore : 0.421938029658631, synonym : unity }, { synonymScore : 0.976796274715053, textDistanceWithSynonym : 0.976796274715053, termSimilarityScore : 0.411104820586555, synonym : ace }, { termSimilarityScore : 0.409793052227205, synonym : iodine , synonymScore : 0.971809310282386, textDistanceWithSynonym : 0.971809310282386 }, { synonymScore : 0.970492090788282, textDistanceWithSynonym : 0.970492090788282, synonym : ane , termSimilarityScore : 0.426139287692068 } ], isKeywordToken : false }, { isKeywordToken : false, synonymItem : [ { termSimilarityScore : 0.344875478792656, synonym : involve , synonymScore : 0.985084402822893, textDistanceWithSynonym : 0.985084402822893 }, { synonym : require , termSimilarityScore : 0.313982723187962, synonymScore : 0.985048997600635, textDistanceWithSynonym : 0.985048997600635 }, { synonym : demand , termSimilarityScore : 0.340885896054422, textDistanceWithSynonym : 0.984973652020142, synonymScore : 0.984973652020142 }, { textDistanceWithSynonym : 0.984179229975704, synonymScore : 0.984179229975704, termSimilarityScore : 0.348080045767017, synonym : necessitate }, { termSimilarityScore : 0.363270794438576, synonym : postulate , synonymScore : 0.980113837090212, textDistanceWithSynonym : 0.980113837090212 } ], keywordExtractionScore : 0, token : { position : 4, end_offset : 23, token : ask , start_offset : 20, token_type : ALPHANUM } }, { token : { position : 5, end_offset : 27, token : you , token_type : ALPHANUM , start_offset : 24 }, keywordExtractionScore : 0, synonymItem : [], isKeywordToken : false }, { isKeywordToken : false, synonymItem : [ { synonym : angstrom , termSimilarityScore : 0.389515130731534, synonymScore : 0.981827876880409, textDistanceWithSynonym : 0.981827876880409 }, { synonym : amp , termSimilarityScore : 0.410951525810052, synonymScore : 0.978805416352854, textDistanceWithSynonym : 0.978805416352854 }, { termSimilarityScore : 0.399132821680172, synonym : ampere , synonymScore : 0.978184525582464, textDistanceWithSynonym : 0.978184525582464 }, { textDistanceWithSynonym : 0.970833723014969, synonymScore : 0.970833723014969, synonym : adenine , termSimilarityScore : 0.417303913993053 } ], keywordExtractionScore : 0, token : { end_offset : 29, start_offset : 28, token_type : ALPHANUM , token : a , position : 6 } }, { token : { token_type : ALPHANUM , start_offset : 30, token : question , end_offset : 38, position : 7 }, keywordExtractionScore : 0, isKeywordToken : false, synonymItem : [ { termSimilarityScore : 0.302928140147459, synonym : doubtfulness , textDistanceWithSynonym : 0.986332041308894, synonymScore : 0.986332041308894 }, { textDistanceWithSynonym : 0.984752050785226, synonymScore : 0.984752050785226, synonym : interview , termSimilarityScore : 0.337223120697986 }, { synonym : enquiry , termSimilarityScore : 0.30268890030876, textDistanceWithSynonym : 0.983960314458422, synonymScore : 0.983960314458422 }, { synonym : interrogate , termSimilarityScore : 0.347190376576428, synonymScore : 0.982717754194259, textDistanceWithSynonym : 0.982717754194259 }, { termSimilarityScore : 0.402127027019405, synonym : head , textDistanceWithSynonym : 0.981584262241235, synonymScore : 0.981584262241235 }, { termSimilarityScore : 0.353450470156032, synonym : interrogation , textDistanceWithSynonym : 0.980529096104673, synonymScore : 0.980529096104673 }, { termSimilarityScore : 0.386000200471808, synonym : motion , textDistanceWithSynonym : 0.978495629389701, synonymScore : 0.978495629389701 }, { synonym : inquiry , termSimilarityScore : 0.314067668506634, textDistanceWithSynonym : 0.977996268442931, synonymScore : 0.977996268442931 } ] } ]","title":"200"},{"location":"apis/#languageguesser","text":"","title":"LanguageGuesser"},{"location":"apis/#post-language_guesser","text":"Output JSON","title":"POST /language_guesser"},{"location":"apis/#requirements_34","text":"Index must exists The function requires user credentials with read permissions on the index","title":"Requirements"},{"location":"apis/#return-codes_26","text":"","title":"Return codes"},{"location":"apis/#200_22","text":"Sample call QUERY=${1:- good morning, may I ask you a question? } PORT=${2:-8888} INDEX_NAME=${3:-index_getjenny_english_0} curl -v -H Authorization: Basic `echo -n 'test_user:p4ssw0rd' | base64` \\ -H Content-Type: application/json -X POST http://localhost:${PORT}/${INDEX_NAME}/language_guesser -d { \\ input_text\\ : \\ ${QUERY}\\ } Sample output { enhough_text : false, language : en , confidence : MEDIUM , score : 0.571426689624786 }","title":"200"},{"location":"apis/#get-language_guesser","text":"Check if a language is recognizable by the guesser Output JSON","title":"GET /language_guesser"},{"location":"apis/#requirements_35","text":"Index must exists The function requires user credentials with read permissions on the index","title":"Requirements"},{"location":"apis/#return-codes_27","text":"","title":"Return codes"},{"location":"apis/#200_23","text":"Sample call LANG=${1:-en} PORT=${2:-8888} INDEX_NAME=${3:-index_getjenny_english_0} curl -v -H Authorization: Basic `echo -n 'test_user:p4ssw0rd' | base64` \\ -H Content-Type: application/json -X GET http://localhost:${PORT}/${INDEX_NAME}/language_guesser/${LANG} Sample output { supported_languages : { languages : { en : true } } }","title":"200"},{"location":"apis/#indexmanagement","text":"","title":"IndexManagement"},{"location":"apis/#post-index_managementcreate","text":"Output JSON","title":"POST /index_management/create"},{"location":"apis/#requirements_36","text":"Index name must start with the \"index_\" prefix followed by a language, and a sequence of alphanumeric characters separated by underscore e.g. index_ _ The function requires \"admin\" credentials","title":"Requirements"},{"location":"apis/#return-codes_28","text":"","title":"Return codes"},{"location":"apis/#200_24","text":"Sample call PORT=${1:-8888} INDEX_NAME=${2:-index_getjenny_english_0} curl -v -H Authorization: Basic `echo -n 'admin:adminp4ssw0rd' | base64` \\ -H Content-Type: application/json -X POST http://localhost:${PORT}/${INDEX_NAME}/index_management/create Sample output { message : IndexCreation: state(index_getjenny_english_0.state, true) question(index_getjenny_english_0.question, true) term(index_getjenny_english_0.term, true) }","title":"200"},{"location":"apis/#post-index_managementrefresh","text":"Output JSON","title":"POST /index_management/refresh"},{"location":"apis/#requirements_37","text":"The index must exists The function requires user credentials with write permissions on the index","title":"Requirements"},{"location":"apis/#return-codes_29","text":"","title":"Return codes"},{"location":"apis/#200_25","text":"Sample call PORT=${1:-8888} INDEX_NAME=${2:-index_getjenny_english_0} curl -v -H Authorization: Basic `echo -n 'test_user:p4ssw0rd' | base64` \\ -H Content-Type: application/json -X POST http://localhost:${PORT}/${INDEX_NAME}/index_management/refresh Sample output { results : [ { failed_shards : [], successful_shards_n : 5, failed_shards_n : 0, index_name : index_getjenny_english_0.state , total_shards_n : 10 }, { failed_shards : [], total_shards_n : 10, index_name : index_getjenny_english_0.question , failed_shards_n : 0, successful_shards_n : 5 }, { failed_shards : [], successful_shards_n : 5, index_name : index_getjenny_english_0.term , failed_shards_n : 0, total_shards_n : 10 } ] }","title":"200"},{"location":"apis/#get-index_management","text":"Output JSON","title":"GET /index_management"},{"location":"apis/#requirements_38","text":"The index must exists The function requires user credentials with read permissions on the index","title":"Requirements"},{"location":"apis/#return-codes_30","text":"","title":"Return codes"},{"location":"apis/#200_26","text":"Sample call PORT=${1:-8888} INDEX_NAME=${2:-index_getjenny_english_0} curl -v -H Authorization: Basic `echo -n 'test_user:p4ssw0rd' | base64` \\ -H Content-Type: application/json -X GET http://localhost:${PORT}/${INDEX_NAME}/index_management Sample output { message : IndexCheck: state(index_getjenny_english_0.state, true) question(index_getjenny_english_0.question, true) term(index_getjenny_english_0.term, true) }","title":"200"},{"location":"apis/#put-index_management","text":"Output JSON","title":"PUT /index_management"},{"location":"apis/#requirements_39","text":"Index must exists The function requires \"admin\" credentials","title":"Requirements"},{"location":"apis/#return-codes_31","text":"","title":"Return codes"},{"location":"apis/#200_27","text":"Sample call PORT=${1:-8888} INDEX_NAME=${2:-index_getjenny_english_0} LANGUAGE=${3:-english} curl -v -H Authorization: Basic `echo -n 'admin:adminp4ssw0rd' | base64` \\ -H Content-Type: application/json -X PUT http://localhost:${PORT}/${INDEX_NAME}/${LANGUAGE}/index_management Sample output { message : IndexCheck: state(index_getjenny_english_0.state, true) question(index_getjenny_english_0.question, true) term(index_getjenny_english_0.term, true) }","title":"200"},{"location":"apis/#delete-index_management","text":"Output JSON","title":"DELETE /index_management"},{"location":"apis/#requirements_40","text":"The index must exists The function requires admin credentials","title":"Requirements"},{"location":"apis/#return-codes_32","text":"","title":"Return codes"},{"location":"apis/#200_28","text":"Sample call PORT=${1:-8888} INDEX_NAME=${2:-index_getjenny_english_0} curl -v -H Authorization: Basic `echo -n 'admin:adminp4ssw0rd' | base64` \\ -H Content-Type: application/json -X DELETE http://localhost:${PORT}/${INDEX_NAME}/index_management Sample output { message : IndexDeletion: state(index_getjenny_english_0.state, true) question(index_getjenny_english_0.question, true) term(index_getjenny_english_0.term, true) }","title":"200"},{"location":"apis/#term","text":"","title":"Term"},{"location":"apis/#post-termindex","text":"Index the term as indicated in the JSON.","title":"POST /term/index"},{"location":"apis/#requirements_41","text":"The index must exists The function requires user credentials with write permissions on the index","title":"Requirements"},{"location":"apis/#return-codes_33","text":"","title":"Return codes"},{"location":"apis/#200_29","text":"Sample call PORT=${1:-8888} INDEX_NAME=${2:-index_getjenny_english_0} curl -v -H Authorization: Basic `echo -n 'test_user:p4ssw0rd' | base64` \\ -H Content-Type: application/json -X POST http://localhost:${PORT}/${INDEX_NAME}/term/index -d '{ terms : [ { term : \u092e\u0930\u093e\u0920\u0940 , frequency_base : 1.0, frequency_stem : 1.0, vector : [1.0, 2.0, 3.0], synonyms : { bla1 : 0.1, bla2 : 0.2 }, antonyms : { bla3 : 0.1, bla4 : 0.2 }, tags : tag1 tag2 , features : { NUM : S , GEN : M } }, { term : term2 , frequency_base : 1.0, frequency_stem : 1.0, vector : [1.0, 2.0, 3.0], synonyms : { bla1 : 0.1, bla2 : 0.2 }, antonyms : { bla3 : 0.1, bla4 : 0.2 }, tags : tag1 tag2 , features : { NUM : P , GEN : F } } ] }' Sample output { data : [ { version : 1, created : true, dtype : term , index : jenny-en-0 , id : \u092e\u0930\u093e\u0920\u0940 }, { dtype : term , created : true, version : 1, id : term2 , index : jenny-en-0 } ] }","title":"200"},{"location":"apis/#post-termindex_default_synonyms","text":"Index a set of default synonyms provided with starchat.","title":"POST /term/index_default_synonyms"},{"location":"apis/#requirements_42","text":"The index must exists The function requires user credentials with write permissions on the index","title":"Requirements"},{"location":"apis/#return-codes_34","text":"","title":"Return codes"},{"location":"apis/#200_30","text":"Sample call PORT=${1:-8888} INDEX_NAME=${2:-index_getjenny_english_0} GROUP_SIZE=${3:-1000} curl --max-time 600 -v -H Authorization: Basic $(echo -n 'admin:adminp4ssw0rd' | base64) \\ -H Content-Type: application/json -X POST http://localhost:${PORT}/${INDEX_NAME}/term/index_default_synonyms?groupsize=${GROUP_SIZE} Sample output { message : Indexed synonyms, blocks of 1000 items = success(124) failures(0) , code : 100 }","title":"200"},{"location":"apis/#post-termget","text":"Get one or more terms entry.","title":"POST /term/get"},{"location":"apis/#requirements_43","text":"The index must exists The function requires user credentials with read permissions on the index","title":"Requirements"},{"location":"apis/#return-codes_35","text":"","title":"Return codes"},{"location":"apis/#200_31","text":"Sample call QUERY=${1:- \\ term\\ } PORT=${2:-8888} INDEX_NAME=${3:-index_getjenny_english_0} curl -v -H Authorization: Basic `echo -n 'test_user:p4ssw0rd' | base64` \\ -H Content-Type: application/json -X POST http://localhost:${PORT}/${INDEX_NAME}/term/get -d { \\ ids\\ : [${QUERY}] } Sample output { terms : [ { vector : [ 1, 2, 3 ], frequency_base : 1.0, frequency_stem : 1.0, term : \u092e\u0930\u093e\u0920\u0940 , antonyms : { bla4 : 0.2, bla3 : 0.1 }, features : { NUM : S , GEN : M }, synonyms : { bla2 : 0.2, bla1 : 0.1 }, tags : tag1 tag2 }, { antonyms : { bla3 : 0.1, bla4 : 0.2 }, features : { NUM : P , GEN : F }, term : term2 , frequency_base : 1.0, frequency_stem : 1.0, vector : [ 1, 2, 3 ], synonyms : { bla1 : 0.1, bla2 : 0.2 }, tags : tag1 tag2 } ] }","title":"200"},{"location":"apis/#delete-term","text":"Delete the term.","title":"DELETE /term"},{"location":"apis/#requirements_44","text":"The index must exists The function requires user credentials with write permissions on the index","title":"Requirements"},{"location":"apis/#return-codes_36","text":"","title":"Return codes"},{"location":"apis/#200_32","text":"Sample call PORT=${1:-8888} INDEX_NAME=${2:-index_getjenny_english_0} curl -v -H Authorization: Basic `echo -n 'test_user:p4ssw0rd' | base64` \\ -H Content-Type: application/json -X DELETE http://localhost:${PORT}/${INDEX_NAME}/term -d '{ ids : [ \u092e\u0930\u093e\u0920\u0940 , term2 ] }' Sample output { data : [ { dtype : term , version : 2, id : \u092e\u0930\u093e\u0920\u0940 , index : jenny-en-0 , found : true }, { dtype : term , id : term2 , version : 2, found : true, index : jenny-en-0 } ] } Sample call: delete all PORT=${1:-8888} INDEX_NAME=${2:-index_getjenny_english_0} curl -v -H Authorization: Basic `echo -n 'test_user:p4ssw0rd' | base64` \\ -H Content-Type: application/json -X DELETE http://localhost:${PORT}/${INDEX_NAME}/term -d'{ ids : [] }' Sample call: delete all { message : delete , deleted :2 }","title":"200"},{"location":"apis/#put-term","text":"Update the entry.","title":"PUT /term"},{"location":"apis/#requirements_45","text":"The index must exists The function requires user credentials with write permissions on the index","title":"Requirements"},{"location":"apis/#return-codes_37","text":"","title":"Return codes"},{"location":"apis/#200_33","text":"Sample call PORT=${1:-8888} INDEX_NAME=${2:-index_getjenny_english_0} curl -v -H Authorization: Basic `echo -n 'test_user:p4ssw0rd' | base64` \\ -H Content-Type: application/json -X PUT http://localhost:${PORT}/${INDEX_NAME}/term -d '{ terms : [ { term : \u092e\u0930\u093e\u0920\u0940 , frequency_base : 1.0, frequency_stem : 1.0, vector : [1.2, 2.3, 3.4, 4.5], synonyms : { bla1 : 0.1, bla2 : 0.2 }, antonyms : { term2 : 0.1, bla4 : 0.2 }, tags : tag1 tag2 , features : { FEATURE_NEW1 : V , GEN : M } }, { term : term2 , frequency_base : 1.0, frequency_stem : 1.0, vector : [1.6, 2.7, 3.8, 5.9], synonyms : { bla1 : 0.1, bla2 : 0.2 }, antonyms : { bla3 : 0.1, bla4 : 0.2 }, tags : tag1 tag2 , features : { FEATURE_NEW1 : N , GEN : F } } ] }' Sample output { data : [ { version : 2, id : \u092e\u0930\u093e\u0920\u0940 , index : jenny-en-0 , created : false, dtype : term }, { index : jenny-en-0 , id : term2 , version : 2, dtype : term , created : false } ] }","title":"200"},{"location":"apis/#get-termterm","text":"Search for term (using Elasticsearch).","title":"GET /term/term"},{"location":"apis/#requirements_46","text":"The index must exists The function requires user credentials with read permissions on the index","title":"Requirements"},{"location":"apis/#return-codes_38","text":"","title":"Return codes"},{"location":"apis/#200_34","text":"Sample call QUERY=${1:- term2 } PORT=${2:-8888} INDEX_NAME=${3:-index_getjenny_english_0} curl -v -H Authorization: Basic `echo -n 'test_user:p4ssw0rd' | base64` \\ -H Content-Type: application/json -X GET http://localhost:${PORT}/${INDEX_NAME}/term/term -d { \\ term\\ : \\ ${QUERY}\\ } Sample output { hits : { terms : [ { vector : [ 1.2, 2.3, 3.4, 4.5 ], antonyms : { bla4 : 0.2, term2 : 0.1 }, frequency_base : 1.0, frequency_stem : 1.0, features : { FEATURE_NEW1 : V , GEN : M }, score : 0.6931471824646, tags : tag1 tag2 , term : \u092e\u0930\u093e\u0920\u0940 , synonyms : { bla2 : 0.2, bla1 : 0.1 } } ] }, total : 1, max_score : 0.6931471824646 }","title":"200"},{"location":"apis/#get-termtext","text":"Search for all the terms in the text and return the entries.","title":"GET /term/text"},{"location":"apis/#requirements_47","text":"The index must exists The function requires user credentials with read permissions on the index","title":"Requirements"},{"location":"apis/#return-codes_39","text":"","title":"Return codes"},{"location":"apis/#200_35","text":"Sample call PORT=${1:-8888} INDEX_NAME=${2:-index_getjenny_english_0} curl -v -H Authorization: Basic `echo -n 'test_user:p4ssw0rd' | base64` \\ -H Content-Type: application/json -X GET http://localhost:${PORT}/${INDEX_NAME}/term/text -d 'term2 \u092e\u0930\u093e\u0920\u0940' Sample output { max_score : 0.6931471824646, hits : { terms : [ { term : \u092e\u0930\u093e\u0920\u0940 , score : 0.6931471824646, tags : tag1 tag2 , vector : [ 1.2, 2.3, 3.4, 4.5 ], features : { GEN : M , FEATURE_NEW1 : V }, antonyms : { bla4 : 0.2, term2 : 0.1 }, synonyms : { bla2 : 0.2, bla1 : 0.1 }, frequency_base : 1.0, frequency_stem : 1.0 }, { term : term2 , tags : tag1 tag2 , score : 0.6931471824646, features : { FEATURE_NEW1 : N , GEN : F }, vector : [ 1.6, 2.7, 3.8, 5.9 ], antonyms : { bla3 : 0.1, bla4 : 0.2 }, frequency_base : 1.0, frequency_stem : 1.0, synonyms : { bla1 : 0.1, bla2 : 0.2 } } ] }, total : 2 }","title":"200"},{"location":"apis/#tokenizers","text":"","title":"Tokenizers"},{"location":"apis/#get-tokenizers","text":"Show a list of supported methods for tokenization and stemming","title":"GET /tokenizers"},{"location":"apis/#requirements_48","text":"The index must exists The function requires user credentials with read permissions on the index","title":"Requirements"},{"location":"apis/#return-codes_40","text":"","title":"Return codes"},{"location":"apis/#200_36","text":"Sample call PORT=${1:-8888} INDEX_NAME=${2:-index_getjenny_english_0} curl -v -H Authorization: Basic `echo -n 'test_user:p4ssw0rd' | base64` \\ -H Content-Type: application/json -X GET http://localhost:${PORT}/${INDEX_NAME}/tokenizers Sample output { shingles2 : 2 words shingles , shingles3 : 3 words shingles , shingles2_10 : from 2 to 10 shingles , base_stem : lowercase + stemming , base : lowercase , stop : lowercase + stopwords elimination , shingles4 : 4 words shingles , stop_stem : lowercase + stopwords elimination + stemming }","title":"200"},{"location":"apis/#post-tokenizers","text":"get a list of token using the selected analyzer","title":"POST /tokenizers"},{"location":"apis/#requirements_49","text":"The index must exists The function requires user credentials with read permissions on the index","title":"Requirements"},{"location":"apis/#return-codes_41","text":"","title":"Return codes"},{"location":"apis/#200_37","text":"Sample call ANALYZER=${1:- stop } QUERY=${2:- good morning, may I ask you a question? } PORT=${3:-8888} INDEX_NAME=${4:-index_getjenny_english_0} curl -v -H Authorization: Basic `echo -n 'test_user:p4ssw0rd' | base64` \\ -H Content-Type: application/json -X POST http://localhost:${PORT}/${INDEX_NAME}/tokenizers -d { \\ text\\ : \\ ${QUERY}\\ , \\ tokenizer\\ : \\ ${ANALYZER}\\ } Sample output { tokens : [ { start_offset : 0, end_offset : 4, token_type : word , token : good , position : 0 }, { token : morning , position : 1, token_type : word , end_offset : 12, start_offset : 5 }, { start_offset : 14, end_offset : 17, token_type : word , token : may , position : 2 }, { token_type : word , token : i , position : 3, start_offset : 18, end_offset : 19 }, { end_offset : 23, start_offset : 20, position : 4, token : ask , token_type : word }, { end_offset : 27, start_offset : 24, position : 5, token : you , token_type : word }, { end_offset : 38, start_offset : 30, token : question , position : 7, token_type : word } ] }","title":"200"},{"location":"apis/#analyzersplayground","text":"","title":"AnalyzersPlayground"},{"location":"apis/#post-analyzers_playground","text":"used to test analyzers on the fly","title":"POST /analyzers_playground"},{"location":"apis/#requirements_50","text":"The index must exists The function requires user credentials with read permissions on the index","title":"Requirements"},{"location":"apis/#return-codes_42","text":"","title":"Return codes"},{"location":"apis/#200_38","text":"Sample call keyword ANALYZER=${1:- keyword(\\\\\\ test\\\\\\ ) } QUERY=${2:- this is a test } DATA=${3:- {\\ traversed_states\\ : [], \\ extracted_variables\\ :{}} } PORT=${4:-8888} INDEX_NAME=${5:-index_getjenny_english_0} curl -H Authorization: Basic `echo -n 'test_user:p4ssw0rd' | base64` \\ -H Content-Type: application/json -X POST http://localhost:${PORT}/${INDEX_NAME}/analyzers_playground -d { \\ analyzer\\ : \\ ${ANALYZER}\\ , \\ query\\ : \\ ${QUERY}\\ , \\ data\\ : ${DATA} } Sample output keyword { build_message : success , build : true, value : 0.25 } Sample states analyzers curl -H Authorization: Basic `echo -n 'test_user:p4ssw0rd' | base64` \\ -H 'Content-Type: application/json' -X POST http://localhost:${PORT}/${INDEX_NAME}/analyzers_playground -d ' { analyzer : hasTravState(\\ one\\ ) , query : query , data : { traversed_states : [ one , two ], extracted_variables :{}} } ' Sample output states analyzers { build_message : success , build : true, value : 1 } Sample of pattern extraction through analyzers curl -H Authorization: Basic `echo -n 'test_user:p4ssw0rd' | base64` \\ -H 'Content-Type: application/json' -X POST http://localhost:${PORT}/${INDEX_NAME}/analyzers_playground -d ' { analyzer : band(keyword(\\ on\\ ), matchPatternRegex(\\ [day,month,year](?:(0[1-9]|[12][0-9]|3[01])(?:[- \\\\\\/\\\\.])(0[1-9]|1[012])(?:[- \\\\\\/\\\\.])((?:19|20)\\\\d\\\\d))\\ )) , query : on 31-11-1900 }' Sample output { build_message : success , data : { traversed_states : [], extracted_variables : { month.0 : 11 , year.0 : 1900 , day.0 : 31 } }, value : 1, build : true }","title":"200"},{"location":"apis/#spellcheck","text":"","title":"SpellCheck"},{"location":"apis/#post-spellcheckterms","text":"terms spellchecker based on knowledgebase text","title":"POST /spellcheck/terms"},{"location":"apis/#requirements_51","text":"The index must exists The function requires user credentials with read permissions on the index the knowledge base must contain data","title":"Requirements"},{"location":"apis/#return-codes_43","text":"","title":"Return codes"},{"location":"apis/#200_39","text":"Sample call QUERY=${1:- this is a tes for splellchecker } PORT=${2:-8888} INDEX_NAME=${3:-index_getjenny_english_0} curl -v -H Authorization: Basic `echo -n 'test_user:p4ssw0rd' | base64` \\ -H Content-Type: application/json -X POST http://localhost:${PORT}/${INDEX_NAME}/spellcheck/terms -d { \\ text\\ : \\ ${QUERY}\\ , \\ prefix_length\\ : 3, \\ min_doc_freq\\ : 1 } { tokens : [ { offset : 0, options : [ { freq : 1284, score : 0.800000011920929, text : hello }, { text : hella , score : 0.800000011920929, freq : 2 }, { freq : 2, score : 0.800000011920929, text : helle }, { text : help , score : 0.75, freq : 35395 }, { score : 0.75, freq : 5, text : hell } ], length : 5, text : hellp }, { length : 4, options : [], offset : 7, text : this }, { length : 2, options : [], offset : 12, text : is }, { length : 1, offset : 15, options : [], text : a }, { length : 4, offset : 17, options : [ { text : test , score : 0.75, freq : 191 }, { freq : 10, score : 0.5, text : tessa }, { text : tesco , score : 0.5, freq : 9 }, { text : tesia , score : 0.5, freq : 2 }, { freq : 2, score : 0.5, text : tester } ], text : tesr } ] }","title":"200"}]}